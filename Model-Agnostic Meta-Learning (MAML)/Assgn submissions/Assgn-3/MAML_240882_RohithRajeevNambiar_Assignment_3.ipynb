{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š Assignment: Transfer Learning & The Power of Initialization\n",
        "## Building Intuition for MAML\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Understand why initialization matters for few-shot learning\n",
        "- Experience the difference between various pre-training strategies\n",
        "- Develop intuition for what MAML tries to optimize"
      ],
      "metadata": {
        "id": "GVBnQU7-LWJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advice on using LLM's**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Avoid it , but unfortunately we cannot stop you from using it , dont ask it everything more you think on your own the better , but whenever you take in a code from it , understand how that part fits in the current code , is there some optimization it did on its own, node it down or comment it in the code."
      ],
      "metadata": {
        "id": "MGwIvFz-OBQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision matplotlib numpy\n",
        "\n",
        "#Understand what does each of this import do , see what all functions this hold\n",
        "#whenever you want to implement something think which of this would you use and refer to its doc for the syntax\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "print(\"âœ… Setup complete!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "iU4HQdjfLjpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614ed74e-d44d-4a10-a957-97bd416b52e7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Setup complete!\n",
            "PyTorch version: 2.9.0+cpu\n",
            "CUDA available: False\n",
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š Part A: Dataset Preparation\n",
        "\n",
        "We'll use **MNIST** for simplicity (or you can use Omniglot if you prefer).\n",
        "\n",
        "**Your Task:**\n",
        "- Split MNIST into 5 tasks (Tasks A-E), each with 2 digit classes\n",
        "- For example: Task A = {0, 1}, Task B = {2, 3}, etc."
      ],
      "metadata": {
        "id": "Jpe4MlEpLnRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "# we get a special parameter while loading which is 'background'\n",
        "#refer to document for what it means and how to use it\n",
        "\n",
        "print(f\"âœ… MNIST loaded: {len(train_dataset)} train, {len(test_dataset)} test images\")\n",
        "\n",
        "# TODO: Define your task structure\n",
        "# We'll split 10 digits into 5 tasks, each with 2 classes\n"
      ],
      "metadata": {
        "id": "CRoLfdMfMgFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40966b43-0399-49c8-abd1-45008b062235"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… MNIST loaded: 60000 train, 10000 test images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define your task structure\n",
        "# We'll split 10 digits into 5 tasks, each with 2 classes\n",
        "\n",
        "task_definitions = {\n",
        "    \"A\": [0, 1],\n",
        "    \"B\": [2, 3],\n",
        "    \"C\": [4, 5],\n",
        "    \"D\": [6, 7],\n",
        "    \"E\": [8, 9],\n",
        "}\n",
        "\n",
        "#Below function should take the given inputs and split the main dataset with the given input classes into train,support and query.\n",
        "def create_task_datasets(dataset, task_classes, n_train=15, n_support=5, n_query=10):\n",
        "    train_data = []\n",
        "    support_data = []\n",
        "    query_data = []\n",
        "\n",
        "    class_to_indices = defaultdict(list)\n",
        "\n",
        "    for idx in range(len(dataset)):\n",
        "        _, label = dataset[idx]\n",
        "        if label in task_classes:\n",
        "            class_to_indices[label].append(idx)\n",
        "\n",
        "    for cls in task_classes:\n",
        "        indices = class_to_indices[cls][:]\n",
        "        random.shuffle(indices)\n",
        "\n",
        "        splits = {\n",
        "            \"train\": indices[:n_train],\n",
        "            \"support\": indices[n_train:n_train + n_support],\n",
        "            \"query\": indices[n_train + n_support:n_train + n_support + n_query],\n",
        "        }\n",
        "\n",
        "        new_label = task_classes.index(cls)\n",
        "\n",
        "        for i in splits[\"train\"]:\n",
        "            img, _ = dataset[i]\n",
        "            train_data.append((img, new_label))\n",
        "\n",
        "        for i in splits[\"support\"]:\n",
        "            img, _ = dataset[i]\n",
        "            support_data.append((img, new_label))\n",
        "\n",
        "        for i in splits[\"query\"]:\n",
        "            img, _ = dataset[i]\n",
        "            query_data.append((img, new_label))\n",
        "\n",
        "    return train_data, support_data, query_data\n",
        "    \"\"\"\n",
        "    Create train, support, and query sets for a specific task.\n",
        "\n",
        "    Args:\n",
        "        dataset: Full MNIST dataset\n",
        "        task_classes: List of class labels for this task [e.g., [0, 1]]\n",
        "        n_train: Number of training examples per class\n",
        "        n_support: Number of support examples per class (for fine-tuning)\n",
        "        n_query: Number of query examples per class (for testing)\n",
        "\n",
        "    Returns:\n",
        "        train_data, support_data, query_data (each is list of (image, label) tuples\n",
        "    \"\"\"\n",
        "# TODO: Implement this function\n",
        "# HINT: Filter dataset to only include examples from task_classes\n",
        "# HINT: Split into train/support/query sets\n"
      ],
      "metadata": {
        "id": "qFKxWXDCMqZg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "\n",
        "train_A, support_A, query_A = create_task_datasets(train_dataset, task_definitions['A'])\n",
        "print(f\"Task A - Train: {len(train_A)}, Support: {len(support_A)}, Query: {len(query_A)}\")"
      ],
      "metadata": {
        "id": "xGdk_eqzNuh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f832ed-3ec0-4203-a4a5-b51933718c84"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task A - Train: 30, Support: 10, Query: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part A (continued): **Build Your Model**\n",
        "\n",
        "**TODO:** Design a simple CNN for digit classification"
      ],
      "metadata": {
        "id": "49q6LHJ1O1wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# think on the architecture of the model as discussed in class\n",
        "#general flow -> convolution->relu->maxpooling and so on , in the end some fully connected layers then final classification\n",
        "# Refer to the 60 minute pytorch implementation section of 'neural networks'\n",
        "\n",
        "\n",
        "#Implement the class or the model here\n",
        "#fill in the objects(layers) and methods(forward pass)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "fhsb9ffDO-Xa"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now since the model is ready we decide how do we want to train it :\n",
        "\n",
        "First Do normal classification on large dataset of Task A - 0 & 1.\n",
        "\n",
        "The we will do fine tuning\n",
        "\n",
        "1.   Random Initialisation and then fine tune using support dataset, say we do this for task A which were 0 & 1 digits (save this)\n",
        "2.   Take the above model weights and fine tune it on the support dataset for some other task , say B(2's & 3's)\n",
        "3.   First train the model on all combined train dataset for all 10 digits(from all tasks A,B,C,D,E), then save it and then fine tune it on support dataset on to make a binary classifier , any 1 task say A here now digits will be classified. 0 class->0 digit , 1->1.\n",
        "\n",
        "While moving from one model to other , think what layers do i need to keep and what do i need to remove.\n",
        "\n"
      ],
      "metadata": {
        "id": "KVpBklwxPpj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = list(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.data[idx]\n",
        "        return x, y\n",
        "\n",
        "\n",
        "def train_model(model, dataloader, epochs=10, lr=1e-3):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            x, y = batch\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return losses\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            x, y = batch\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            preds = torch.argmax(model(x), dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "Hee_D_lBMroV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 1 - Fully Trained Binary Classifier on Task A\n",
        "train_A, support_A, query_A = create_task_datasets(\n",
        "    train_dataset, task_definitions['A']\n",
        ")\n",
        "\n",
        "model_A = SimpleCNN(num_classes=2).to(device)\n",
        "\n",
        "train_loader_A = DataLoader(\n",
        "    SimpleDataset(train_A),\n",
        "    batch_size=8,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "query_loader_A = DataLoader(\n",
        "    SimpleDataset(query_A),\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss_A = train_model(\n",
        "    model_A,\n",
        "    train_loader_A,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "acc_A = evaluate_model(\n",
        "    model_A,\n",
        "    query_loader_A\n",
        ")\n",
        "\n",
        "print(f\"Accuracy : {acc_A}\")\n"
      ],
      "metadata": {
        "id": "nCVBCeVxXFQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2658826b-171b-4724-be53-2300854e8a80"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] Loss: 0.6575\n",
            "Epoch [2/20] Loss: 0.3682\n",
            "Epoch [3/20] Loss: 0.1362\n",
            "Epoch [4/20] Loss: 0.0354\n",
            "Epoch [5/20] Loss: 0.0064\n",
            "Epoch [6/20] Loss: 0.0029\n",
            "Epoch [7/20] Loss: 0.0012\n",
            "Epoch [8/20] Loss: 0.0003\n",
            "Epoch [9/20] Loss: 0.0001\n",
            "Epoch [10/20] Loss: 0.0001\n",
            "Epoch [11/20] Loss: 0.0000\n",
            "Epoch [12/20] Loss: 0.0000\n",
            "Epoch [13/20] Loss: 0.0000\n",
            "Epoch [14/20] Loss: 0.0000\n",
            "Epoch [15/20] Loss: 0.0000\n",
            "Epoch [16/20] Loss: 0.0000\n",
            "Epoch [17/20] Loss: 0.0000\n",
            "Epoch [18/20] Loss: 0.0000\n",
            "Epoch [19/20] Loss: 0.0000\n",
            "Epoch [20/20] Loss: 0.0000\n",
            "Accuracy : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 2 - Fine Tuning all 3 methods\n",
        "\n",
        "#1 Randomly initialized model fine-tuned using Task A support set\n",
        "\n",
        "model_random_A = SimpleCNN(num_classes=2).to(device)\n",
        "\n",
        "support_loader_A = DataLoader(\n",
        "    SimpleDataset(support_A),\n",
        "    batch_size=4,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "loss_rand_A = train_model(\n",
        "    model_random_A,\n",
        "    support_loader_A,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "acc_rand_A = evaluate_model(\n",
        "    model_random_A,\n",
        "    query_loader_A\n",
        ")\n",
        "\n",
        "print(\"(Random initialization of task A support set) Accuracy:\", acc_rand_A)\n"
      ],
      "metadata": {
        "id": "LpzPYTkkXH9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2755c88-a4c7-423b-9492-2fccf38fd240"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.6479\n",
            "Epoch [2/10] Loss: 0.4188\n",
            "Epoch [3/10] Loss: 0.2044\n",
            "Epoch [4/10] Loss: 0.0706\n",
            "Epoch [5/10] Loss: 0.0139\n",
            "Epoch [6/10] Loss: 0.0039\n",
            "Epoch [7/10] Loss: 0.0010\n",
            "Epoch [8/10] Loss: 0.0002\n",
            "Epoch [9/10] Loss: 0.0001\n",
            "Epoch [10/10] Loss: 0.0000\n",
            "(Random initialization of task A support set) Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Fine tuning on task B after training on A\n",
        "model_taskA = SimpleCNN(num_classes=2).to(device)\n",
        "\n",
        "train_model(\n",
        "    model_taskA,\n",
        "    train_loader_A,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "train_B, support_B, query_B = create_task_datasets(\n",
        "    train_dataset,\n",
        "    task_definitions['B']\n",
        ")\n",
        "\n",
        "support_loader_B = DataLoader(\n",
        "    SimpleDataset(support_B),\n",
        "    batch_size=4,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "query_loader_B = DataLoader(\n",
        "    SimpleDataset(query_B),\n",
        "    batch_size=4,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss_A_to_B = train_model(\n",
        "    model_taskA,\n",
        "    support_loader_B,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "acc_A_to_B = evaluate_model(\n",
        "    model_taskA,\n",
        "    query_loader_B\n",
        ")\n",
        "\n",
        "print(\"Task A â†’ Fine-tune Task B Accuracy:\", acc_A_to_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnr_7dzeRjrn",
        "outputId": "8bac713d-41b4-4dfc-9038-e1e190ecfabb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] Loss: 0.6652\n",
            "Epoch [2/20] Loss: 0.4480\n",
            "Epoch [3/20] Loss: 0.2170\n",
            "Epoch [4/20] Loss: 0.0737\n",
            "Epoch [5/20] Loss: 0.0223\n",
            "Epoch [6/20] Loss: 0.0045\n",
            "Epoch [7/20] Loss: 0.0022\n",
            "Epoch [8/20] Loss: 0.0010\n",
            "Epoch [9/20] Loss: 0.0004\n",
            "Epoch [10/20] Loss: 0.0002\n",
            "Epoch [11/20] Loss: 0.0001\n",
            "Epoch [12/20] Loss: 0.0001\n",
            "Epoch [13/20] Loss: 0.0001\n",
            "Epoch [14/20] Loss: 0.0001\n",
            "Epoch [15/20] Loss: 0.0001\n",
            "Epoch [16/20] Loss: 0.0001\n",
            "Epoch [17/20] Loss: 0.0000\n",
            "Epoch [18/20] Loss: 0.0000\n",
            "Epoch [19/20] Loss: 0.0000\n",
            "Epoch [20/20] Loss: 0.0000\n",
            "Epoch [1/10] Loss: 2.2164\n",
            "Epoch [2/10] Loss: 1.1016\n",
            "Epoch [3/10] Loss: 0.4543\n",
            "Epoch [4/10] Loss: 0.0814\n",
            "Epoch [5/10] Loss: 0.0919\n",
            "Epoch [6/10] Loss: 0.1039\n",
            "Epoch [7/10] Loss: 0.0465\n",
            "Epoch [8/10] Loss: 0.0262\n",
            "Epoch [9/10] Loss: 0.0267\n",
            "Epoch [10/10] Loss: 0.0313\n",
            "Task A â†’ Fine-tune Task B Accuracy: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Fine tuning on A after pretraining all digits\n",
        "model_pretrain = SimpleCNN(num_classes=10).to(device)\n",
        "\n",
        "full_train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "train_model(\n",
        "    model_pretrain,\n",
        "    full_train_loader,\n",
        "    epochs=3\n",
        ")\n",
        "\n",
        "model_pretrain.fc_layers[-1] = nn.Linear(128, 2)\n",
        "model_pretrain = model_pretrain.to(device)\n",
        "\n",
        "loss_pretrain_A = train_model(\n",
        "    model_pretrain,\n",
        "    support_loader_A,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "acc_pretrain_A = evaluate_model(\n",
        "    model_pretrain,\n",
        "    query_loader_A\n",
        ")\n",
        "\n",
        "print(\"Pretrained â†’ A Accuracy:\", acc_pretrain_A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCaY1f-QSSOC",
        "outputId": "9dd289fd-e6ce-4734-df48-594ec38fba5f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3] Loss: 0.1849\n",
            "Epoch [2/3] Loss: 0.0499\n",
            "Epoch [3/3] Loss: 0.0341\n",
            "Epoch [1/10] Loss: 1.9652\n",
            "Epoch [2/10] Loss: 0.4662\n",
            "Epoch [3/10] Loss: 0.0473\n",
            "Epoch [4/10] Loss: 0.0106\n",
            "Epoch [5/10] Loss: 0.0029\n",
            "Epoch [6/10] Loss: 0.0012\n",
            "Epoch [7/10] Loss: 0.0005\n",
            "Epoch [8/10] Loss: 0.0003\n",
            "Epoch [9/10] Loss: 0.0002\n",
            "Epoch [10/10] Loss: 0.0002\n",
            "Pretrained â†’ A Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end compare performance of all this models and methods using the Query Set.\n",
        "\n",
        "Also plot the learning curve vs epoch for all the methods\n",
        "\n",
        "Make a table and fill in the values of different evaluation metrics you learned in previous lectures."
      ],
      "metadata": {
        "id": "68yPic0PXeR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis and Plots\n",
        "plt.plot(loss_A)\n",
        "plt.plot(loss_rand_A)\n",
        "plt.plot(loss_A_to_B)\n",
        "plt.plot(loss_pretrain_A)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Analysis\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k42bvzgsaHSG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "0553bc19-ec8d-477a-9d28-f339ff2d9a31"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3368118641.py:8: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  plt.legend()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    TP = FP = TN = FN = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x).argmax(dim=1)\n",
        "\n",
        "            TP += ((preds == 1) & (y == 1)).sum().item()\n",
        "            TN += ((preds == 0) & (y == 0)).sum().item()\n",
        "            FP += ((preds == 1) & (y == 0)).sum().item()\n",
        "            FN += ((preds == 0) & (y == 1)).sum().item()\n",
        "\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)\n",
        "    precision = TP / (TP + FP + 1e-8)\n",
        "    recall = TP / (TP + FN + 1e-8)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "results = {}\n",
        "\n",
        "results[\"Scratch Task A\"] = compute_metrics(model_A, query_loader_A)\n",
        "results[\"Random Init â†’ Support A\"] = compute_metrics(model_random_A, query_loader_A)\n",
        "results[\"Task A â†’ Task B\"] = compute_metrics(model_taskA, query_loader_B)\n",
        "results[\"Pretrain All â†’ Support A\"] = compute_metrics(model_pretrain, query_loader_A)\n",
        "\n",
        "header = f\"{'Method':30s} | {'Accuracy':8s} | {'Precision':9s} | {'Recall':7s} | {'F1':6s}\"\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "for method, (acc, prec, rec, f1) in results.items():\n",
        "    print(\n",
        "        f\"{method:30s} | \"\n",
        "        f\"{acc:.3f}     | \"\n",
        "        f\"{prec:.3f}      | \"\n",
        "        f\"{rec:.3f}    | \"\n",
        "        f\"{f1:.3f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcRzVYIPOMIO",
        "outputId": "ecf1d140-ce1b-49f5-de5c-7b6775e9a7d9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method                         | Accuracy | Precision | Recall  | F1    \n",
            "------------------------------------------------------------------------\n",
            "Scratch Task A                 | 1.000     | 1.000      | 1.000    | 1.000\n",
            "Random Init â†’ Support A        | 0.950     | 0.909      | 1.000    | 0.952\n",
            "Task A â†’ Task B                | 0.650     | 0.615      | 0.800    | 0.696\n",
            "Pretrain All â†’ Support A       | 1.000     | 1.000      | 1.000    | 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Theoritical Questions :\n",
        "\n",
        "1.   Which strategy in Method 2 works best and why do you feel so ?\n",
        "2.   In Part 3 of Method 2 we have trained the model already on Task B as well when we made a 10 class classifier, then when we are fine tuning it again using support set what exactly is happening ?\n",
        "3.   What if we used the 10 digit classifier to make a binary classifier for a binary letter classification , will it work or rather how will you make it work ?\n",
        "4.   Where exactly have we used Meta Learning, in which approach? Have we even used it ?\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Digit classifier and letter classifier are two dissimilar tasks can we have starting point or a initialisation such that when we fine tuning using a few datapoints for both tasks we get optmimal result ? This is what we will try to do in MAML ?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Think on them sincerely , would love to read your answers!\n",
        "\n"
      ],
      "metadata": {
        "id": "j7DID45NYPVe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pALhRm9KOV_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretraining on all digits followed by fine tuning on the support set works best. The model learns features like edges, strokes and shapes during pretraining, which transfer well to new binary tasks.\n",
        "\n",
        "Fine tuning mainly adapts the classifier head and slightly adjusts features, requiring fewer samples to achieve high performance."
      ],
      "metadata": {
        "id": "Rm3AhGgTTTL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Though the model has seen Task B during 10-class pretraining, we aim to do binary classification by fine tuning. Fine tuning reshapes the decision boundary and adjusts the learned features with the new task specific labels, rather than relearning features from scratch."
      ],
      "metadata": {
        "id": "-kTx7RFFTWMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would not work directly due to domain mismatch between digits and letters."
      ],
      "metadata": {
        "id": "q7b4VDe-TYNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meta learning is not used as such in this assignment. We have used forms of transfer learning and fine tuning only here."
      ],
      "metadata": {
        "id": "972E5BjhTeng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. MAML is based on the idea that instead of training a model to solve one specific problem, we should train it so that it can learn new problems quickly. The main goal is to make the model good at learning, not just good at one task.\n",
        "\n",
        "In MAML, the model is trained in such a way that when it sees a new problem, it does not need a lot of data or long training. Even with just a few examples and a few training steps, the model can adapt and start performing well. This is useful when new tasks keep changing or when collecting a large dataset for every new problem is difficult.\n",
        "\n",
        "Because of this training style, the same model can be reused for very different problems, such as recognizing digits first and then learning to recognize letters. MAML helps the model adjust quickly instead of starting from scratch each time."
      ],
      "metadata": {
        "id": "IvMlZNBIThIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALL THE BEST !"
      ],
      "metadata": {
        "id": "TVWntvGLXtZi"
      }
    }
  ]
}