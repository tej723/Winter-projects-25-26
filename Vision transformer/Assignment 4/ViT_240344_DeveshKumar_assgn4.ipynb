{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-woU4Sodh6ND"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment #4\n",
        "\n",
        "\n",
        "Vision Transformer\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UMQvV4nljttN"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Batch Normalization"
      ]
    },
    {
      "metadata": {
        "id": "JT_kxpjbNQUr"
      },
      "cell_type": "markdown",
      "source": [
        "Training a deep neural network is a tricky process. Many techniques have already been proposed for more stable training and faster convergence. Most of these techniques either change the model architecture or improve the training algorithm. Batch normalization belongs to the former group. The method was introduced in 2015 and achieved state-of-the-art in ImageNet,  a well-known image classification benchmark."
      ]
    },
    {
      "metadata": {
        "id": "vDcK52jRj_mD"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Definition"
      ]
    },
    {
      "metadata": {
        "id": "owKLAOJVj73I"
      },
      "cell_type": "markdown",
      "source": [
        "We generally normalize the inputs of a neural network to speed up the convergence. So if the \"normalization\" works, why not try it on the activation values? How can we improve training by normalizing the values of intermediate layers?\n",
        "\n",
        "Here is an intermediate layer $l$ in some neural network:\n",
        "\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/01_intermediate_layer.jpg\" width=\"500\"/></p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nKOwOymYSVK8"
      },
      "cell_type": "markdown",
      "source": [
        "The general idea is to train layer $l$ faster by normalizing its input. By the layer $l$ we simply mean weigth matrices $W^{l}$, $b^{l}$ and by the input we mean previous layer's activations $a^{l-1}$. For the sake of simplicity, let us change our notation. Instead of normalizing the input of layer $l$, we would like to normalize the output so that the next layers will receive normalized values from our layer. It has the same effect, but it will make the equations much cleaner.\n",
        "\n",
        "In practice, we do not normalize the output (the activations). Instead, we do the normalization on the weighted sum of inputs $Z^{l}$ just before applying the activation function ($Z^l = xW^l+b^l$).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D_xmxSzHkqrT"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 The formula"
      ]
    },
    {
      "metadata": {
        "id": "PjFpIC3HgxrO"
      },
      "cell_type": "markdown",
      "source": [
        "Assume we want some variable $x$ to have normalized values, the only way to do that is to collect all of its values and calculate the mean and variance in order to create a normalized version of $x$. This is a fairly reasonable solution, and we use it to normalize the neural network's input. Now imagine the goal is to normalize some intermediate values in a deep neural network; Collecting values of some intermediate point in a neural network is almost impossible since the training algorithm can change them entirely. To overcome this issue, we can collect them over a mini-batch.  It will give us an estimated version of the mean and variance. This is why it is called Batch Normalization. Here is the detailed algorithm:\n",
        "\n",
        "Given values of $x$ over a mini-batch $\\mathcal{B} = \\{x_1, .., x_m\\}$ :\n",
        "\n",
        "$$\n",
        "\\mu _\\mathcal{B} = \\frac{1}{m} \\sum^{m}_{i=1} x_i  \\ \\ \\ \\ \\ \\text{(mini-batch mean)}\n",
        "\\\\\n",
        "\\sigma^2 _\\mathcal{B} = \\frac{1}{m} \\sum^{m}_{i=1} (x_i-\\mu _\\mathcal{B})\n",
        "\\ \\ \\ \\ \\ \\text{(mini-batch variance)}\n",
        "\\\\\n",
        "x^{norm}_i = \\frac{x_i - \\mu _\\mathcal{B}}{\\sqrt{\\sigma^2 _\\mathcal{B} + \\epsilon}} \\ \\ \\ \\ \\ \\text{(normalize)}\n",
        "\\\\\n",
        "\\hat{x}_i =\\gamma x^{norm}_i+\\beta  \\ \\ \\ \\ \\ \\text{(scale and shift)}\n",
        "\\\\\n",
        "\\mathrm{BN(\\mathcal{B}, \\gamma, \\beta}) = \\{\\hat{x}_1, ..., \\hat{x}_m\\}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "72SOE7UfxmEh"
      },
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "1. All of the notations above are non-vector.\n",
        "2. $\\gamma$ and $\\beta$ are learnable parameters.\n",
        "3. $\\epsilon$ is just a small number, and we use it for numerical stability.\n",
        "4. $\\mathrm{BN}$ function calculates its output based on a batch of values. Consequently, we'll have different $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ for each mini-batch during the training process. We will reference this property in the next sections.\n",
        "5. $x^{norm}_i$ is actually the normalized version of $x_i$ which has mean 0 and variance 1. However, hidden units in neural networks have different distributions, and we don't really want them to all have the same distribution, So instead, we just scale and shift $x^{norm}_i$ with two variables $\\gamma$, $\\beta$.\n",
        "6. Another reason for the extra \"scale & shift\" step is that if we choose $\\gamma = \\sqrt{\\sigma^2_\\mathcal{B} + \\epsilon}$ and $\\beta = \\mu_\\mathcal{B}$ then $\\hat{x}_i$ will become $x_i$, So the optimizer can easily remove the batch normalization if it is sufficient for proper training.\n",
        "\n",
        "One difference between normalizing a neural network's inputs and Batch Normalization is that the latter does not force values to have mean 0 and variance 1."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain it with at least one reason, why we might not want the hidden units to be forced to have mean 0 and variance 1.**"
      ],
      "metadata": {
        "id": "McQ7-6VxRS3I"
      }
    },
    {
      "metadata": {
        "id": "rrTaUoPMLhyl"
      },
      "cell_type": "markdown",
      "source": [
        "Forcing hidden units to a fixed distribution can restrict the representational power of the network. For example, if we use a Sigmoid activation, forcing a mean of 0 and variance of 1 would confine most values to the linear regime, preventing the model from utilizing its non-linearity. The learnable parameters $\\gamma$ and $\\beta$ allow the network to \"undo\" or adapt the normalization if a different distribution is better for learning."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Where is Batch Normalization generally applied relative to the activations.**"
      ],
      "metadata": {
        "id": "R2f1WO9jSWS_"
      }
    },
    {
      "metadata": {
        "id": "gLEtRi9hSrxC"
      },
      "cell_type": "markdown",
      "source": [
        "Normalization is performed on the weighted sum of inputs $Z^l$ (logits) just before applying the activation function."
      ]
    },
    {
      "metadata": {
        "id": "8few4PaaXf9t"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Batch normalization at test time\n",
        "\n",
        "As we said, We will have multiple $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ since they are calculated individually for each mini-batch. So What should we do for the test time? In fact, the idea is quite simple; We can just calculate a moving average of $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ to use at test time. Deep learning frameworks such as Tensorflow are using this algorithm in their default bach normalization implementations."
      ]
    },
    {
      "metadata": {
        "id": "wwyIr1ChkvzY"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.3 Applying the batch-norm on layers"
      ]
    },
    {
      "metadata": {
        "id": "Wu85xhmM1xFv"
      },
      "cell_type": "markdown",
      "source": [
        "Batch Normalization (or simply batch-norm) doesn't know anything about the concept of layers and vectors. we have to integrate it manually in our layers. For a given d-dimensional vector of logits $Z = (z^{(1)},..., z^{(d)})$, the batch-normalized version is\n",
        "\n",
        "$$\n",
        "Z = (\\ \\mathrm{BN}(\\mathcal{B}\\{z^{(1)}\\}, \\gamma^{(1)}, \\beta^{(1)}),..., \\mathrm{BN}(\\mathcal{B}\\{z^{(d)}\\}, \\gamma^{(d)}, \\beta^{(d)})\\ )\n",
        "$$\n",
        "\n",
        "As you might have noticed, we need a batch for each $Z$'s element in the latter version. In other words, we need a batch of $Z$. Fortunately, this is good news for us since we build our neural networks entirely based on batches.\n",
        "\n",
        "Write the vectorized version of batch-norm equations and specify the dimensions.\n",
        "\n",
        "For any given layer $l$ with $n$ hidden units and batch size $b$:\n",
        "\n",
        "$$\n",
        "z = xW + B\\ \\ \\ \\  z \\in \\mathbb{R} ^ {b \\times n}, W \\in \\mathbb{R} ^ {m \\times n}, B \\in \\mathbb{R} ^ {b \\times n}, x \\in \\mathbb{R} ^ {b \\times m}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "A-J18TTk_Uh1"
      },
      "cell_type": "markdown",
      "source": [
        "**3.**\n",
        "$$\n",
        "\\mu =\\frac{1}{b} \\sum_{i=1}^{b} z_{i}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sigma^2 =\\frac{1}{b} \\sum_{i=1}^{b} (z_{i} - \\mu)^2$\n",
        "$$\n",
        "\n",
        "$$\n",
        "z^{norm} = \\frac{z - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{z} = \\gamma \\odot z^{norm} + \\beta  \\ \\ \\ \\ \\ \\ (\\odot \\text{ is an element-wise dot product} )\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "UmrjugAKYs0p"
      },
      "cell_type": "markdown",
      "source": [
        "Imagine a simple neural network with l hidden layers. We want to apply the batch-norm on all layers. Here is how it would look ($\\mathcal{X}^{b} $ is an input batch):\n",
        "\n",
        "$$\n",
        "\\mathcal{X}^{b}\\stackrel{W^{[1]}, B^{[1]}}{\\longrightarrow}Z^{[1]} \\stackrel{\\gamma^{[1]}, \\beta^{[1]}}{\\longrightarrow}\\hat{Z}^{[1]} \\longrightarrow a^{[1]} = func^{[1]}(\\hat{Z}^{[1]})\\stackrel{W^{[2]}, B^{[2]}}{\\longrightarrow} ...\n",
        "$$\n",
        "\n",
        "Also, the parameters for that neural network would be:\n",
        "$$\n",
        "W^{[1]}, B^{[1]} \\ \\  \\ \\ W^{[2]}, B^{[2]}  \\ \\ ... \\ \\ W^{[l]}, B^{[l]}\n",
        "\\\\\n",
        "\\gamma^{[1]}, \\beta^{[1]} \\ \\ \\ \\  \\  \\ \\ \\gamma^{[2]}, \\beta^{[2]}  \\ \\ \\ \\  ... \\ \\ \\ \\ \\gamma^{[l]}, \\beta^{[l]}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. $B^{[i]}$ is the bias term in our neural network, but with incorporating the batch-norm and introduction of new variables,Do you think $B^{[i]}$ is necessary? Justify your answer with proper reasons.**"
      ],
      "metadata": {
        "id": "sTKOPL1rU3xt"
      }
    },
    {
      "metadata": {
        "id": "Tqv6BuLfirk8"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "The bias term $B^{[i]}$ becomes redundant because the first step of Batch Normalization is subtracting the mini-batch mean $\\mu_B$. Any constant bias added to $Z$ is simply cancelled out during this subtraction. The \"shift\" capability of the bias is instead provided by the learnable parameter $\\beta$ in the BN formula."
      ]
    },
    {
      "metadata": {
        "id": "T0PrEPOdlE9d"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.4 Why does it work?"
      ]
    },
    {
      "metadata": {
        "id": "AVqGS4J6lJlf"
      },
      "cell_type": "markdown",
      "source": [
        "Imagine a super simple neural network:\n",
        "\n",
        "<br/>\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/02_simple_nn.png\" width=\"300\"/>\n",
        "<br>\n",
        "  [[source](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)]\n",
        "</p>\n",
        "\n",
        "</br>\n",
        "During the training, Our optimizer calculates the gradients with respect to weights. Take layer **a** as an example; Optimizer calucates  $\\frac{\\partial L}{\\partial a}$ and then it updates the weights for this layer. Unfortunately,  it means that weight update for Layer **a** only depends on the sensitivity of loss function to that weight. However, changing weights of initial layers can completely effect the statistics of any futher layer.\n",
        "\n",
        "With the presence of Batch Normalization, our optimizer package can now adjust two parameters $\\gamma$, $\\beta$ to change statistics of any layer, rather than entire weight matrix. It makes the training of any layer independent and also introduces some checkpointing mechanism.\n",
        "\n",
        "Besides, recent findings show that batch normalization smoothes the landscape/surface of the loss function, effectively making the optimization performance less dependant on the initial state.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/03_error_surface.jpg\"  width=\"700\"/>\n",
        "<br/>\n",
        "  source: [2]\n",
        "  </p>"
      ]
    },
    {
      "metadata": {
        "id": "VZlJ4Hic2aoN"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.5 Batch Normalization in action\n"
      ]
    },
    {
      "metadata": {
        "id": "cSqjUrD02hiL"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's create a layer to use batch normalization easier."
      ]
    },
    {
      "metadata": {
        "id": "YwY8vwus2xQu"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Layer, Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Complete the following Class**"
      ],
      "metadata": {
        "id": "R6TKpXssrUqc"
      }
    },
    {
      "metadata": {
        "id": "Gt5mzXXX2s5V"
      },
      "cell_type": "code",
      "source": [
        "class BatchNormalizedLayer(Layer):\n",
        "  def __init__(self, layer, axis=-1, activation=None, **kwargs):\n",
        "    \"\"\"Runs batch normalization on layer instance and applies the activation function\n",
        "\n",
        "    Args:\n",
        "      layer(layers.Layer): A layer to normalize its output\n",
        "      axis(int): the axis that should be normalized (typically the features axis).\n",
        "      activation(str): Activation function to use\n",
        "    \"\"\"\n",
        "    super(BatchNormalizedLayer, self).__init__(**kwargs)\n",
        "\n",
        "    self.layer = layer\n",
        "    self.activation = activation\n",
        "    self.axis = axis\n",
        "\n",
        "  def call(self, inputs):\n",
        "        \"\"\"Runs the layer\"\"\"\n",
        "        #Apply the linear transformation\n",
        "        x = self.layer(inputs)\n",
        "\n",
        "        #Use direct import as shown in your screenshot\n",
        "        x = BatchNormalization(axis=self.axis)(x)\n",
        "\n",
        "        #Activation\n",
        "        if self.activation is not None:\n",
        "            x = Activation(self.activation)(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cc0wyxlb7JwJ"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # Import tensorflow\n",
        "\n",
        "bnl = BatchNormalizedLayer(Dense(5), activation='relu')\n",
        "x = tf.constant(2.5 * np.random.randn(10, 4) + 3, dtype=tf.float32) # Use tf.constant\n",
        "\n",
        "# Evaluate the output using tf.keras.backend.get_value\n",
        "assert tf.keras.backend.get_value(bnl(x)).shape == (10, 5)\n",
        "#this is just a check to see if the Layer is working as expected ,it doesnot print anything"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-Tlpqm-_dyH"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5.1 CNN"
      ]
    },
    {
      "metadata": {
        "id": "ZPLoHHW1_qdv"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have our special layer. So, let's use it in a real neural network. We want to improve the baseline using the Batch Normalization layer. Our desired task is CIFAR10 image  classification.\n",
        "\n",
        "First, let's load the dataset:"
      ]
    },
    {
      "metadata": {
        "id": "wm79YEyIAmKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "7d51b15e-a0b7-43cc-938a-d2294b1daaf8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 6.Convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Visualizing CIFAR 10\n",
        "fig, axes1 = plt.subplots(2,5,figsize=(10,4))\n",
        "for j in range(2):\n",
        "  for k in range(5):\n",
        "    i = np.random.choice(range(len(x_train)))\n",
        "    axes1[j][k].set_axis_off()\n",
        "    axes1[j][k].imshow(x_train[i:i+1][0])\n",
        "\n",
        "# Normalize\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "UBb__seXIyRN"
      },
      "cell_type": "code",
      "source": [
        "def visualize_loss_and_acc(history):\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  acc = history_dict['acc']\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "\n",
        "  f = plt.figure(figsize=(10,3))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "  acc_values = history_dict['acc']\n",
        "  val_acc = history_dict['val_acc']\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qlKS6lsIzLX"
      },
      "cell_type": "markdown",
      "source": [
        "#### Baseline"
      ]
    },
    {
      "metadata": {
        "id": "CzzXJ2M6GXn-"
      },
      "cell_type": "markdown",
      "source": [
        "Define the baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CNN Architecture](https://drive.google.com/uc?id=1Fh3Z94KKHe9sAzUorZlW9NXMPN6NAhlx\n",
        ")\n"
      ],
      "metadata": {
        "id": "2fLyt7WKl8F-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The figure above shows the architecture of a **baseline Convolutional Neural Network (CNN)** used for multi-class image classification.\n",
        "\n",
        "The architecture consists of the following components in **Sequential order**:\n",
        "\n",
        "- Convolutional layers with **33 kernels** and **padding = 'same'**\n",
        "- ReLU activation after each convolution\n",
        "- MaxPooling layers with **22 pool size**\n",
        "- Dropout layers for regularization\n",
        "- A fully connected Dense layer\n",
        "- A Softmax output layer\n",
        "\n",
        "**7.** Based on the **architecture shown in the image** and the details mentioned above, implement the CNN model in Keras by completing the function below.\n",
        "\n",
        "- Ensure that the **number of layers, order of layers, kernel sizes, pooling sizes, dropout rates, padding, and activations** exactly match the given architecture\n",
        "- Do **not** change the function name or signature\n"
      ],
      "metadata": {
        "id": "eFWdmvXlnWNN"
      }
    },
    {
      "metadata": {
        "id": "ZnXcRHpuDcvS"
      },
      "cell_type": "code",
      "source": [
        "def get_baseline_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  ## HINT : input_shape=x_train.shape[1:]\n",
        "\n",
        "# 2 Conv layers (32 filters)\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        " # 2 Conv layers (64 filters)\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        " # Fully Connected Block: Flatten\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TQ2uoSmGlvP"
      },
      "cell_type": "markdown",
      "source": [
        "Train the baseline"
      ]
    },
    {
      "metadata": {
        "id": "2Q45b4cVF36l"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 25"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "488nX4FSDzs-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "eb88b9db-d3c8-4846-978c-caea2ba19485"
      },
      "cell_type": "code",
      "source": [
        "# Create the baseline model\n",
        "baseline = get_baseline_model()\n",
        "\n",
        "# Train model\n",
        "bs_history = baseline.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 204ms/step - accuracy: 0.2667 - loss: 1.9952 - val_accuracy: 0.4274 - val_loss: 1.5987\n",
            "Epoch 2/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 207ms/step - accuracy: 0.4623 - loss: 1.4994 - val_accuracy: 0.5422 - val_loss: 1.2857\n",
            "Epoch 3/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 207ms/step - accuracy: 0.5325 - loss: 1.3186 - val_accuracy: 0.5847 - val_loss: 1.1752\n",
            "Epoch 4/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 208ms/step - accuracy: 0.5787 - loss: 1.1885 - val_accuracy: 0.6257 - val_loss: 1.0579\n",
            "Epoch 5/25\n",
            "\u001b[1m1274/1563\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 197ms/step - accuracy: 0.6155 - loss: 1.0843"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1030187800.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m bs_history = baseline.fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AJgQ9yxpGp8P"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the training and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "VeVuiJmHGUw7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "6deba341-7b31-4f3e-a2d4-fbd6a3f08cb9"
      },
      "cell_type": "code",
      "source": [
        "visualize_loss_and_acc(bs_history)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bs_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4194250235.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_loss_and_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'bs_history' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8aMc7UWPICG9"
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = baseline.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufqdGaLrI4oZ"
      },
      "cell_type": "markdown",
      "source": [
        "#### Improved"
      ]
    },
    {
      "metadata": {
        "id": "dm8Yu20HHBXp"
      },
      "cell_type": "markdown",
      "source": [
        "**8. Now update the baseline to create an enhanced model only by using `BatchNormalizedLayer`**"
      ]
    },
    {
      "metadata": {
        "id": "aD6NqqZ3Hbeg"
      },
      "cell_type": "code",
      "source": [
        "def get_improved_model():\n",
        "\n",
        "  model = Sequential()\n",
        " # First Block using BatchNormalizedLayer\n",
        "  model.add(BatchNormalizedLayer(Conv2D(32, (3, 3), padding='same'), activation='relu', input_shape=x_train.shape[1:]))\n",
        "  model.add(BatchNormalizedLayer(Conv2D(32, (3, 3), padding='same'), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "    # Second Block using BatchNormalizedLayer\n",
        "  model.add(BatchNormalizedLayer(Conv2D(64, (3, 3), padding='same'), activation='relu'))\n",
        "  model.add(BatchNormalizedLayer(Conv2D(64, (3, 3), padding='same'), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "    # Fully Connected Block using BatchNormalizedLayer\n",
        "  model.add(Flatten())\n",
        "  model.add(BatchNormalizedLayer(Dense(512), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  ## remember you have to use your baseline and add batch normalized layers using the previous Model\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYmlozp3I8Ts"
      },
      "cell_type": "markdown",
      "source": [
        "Train and evaluate"
      ]
    },
    {
      "metadata": {
        "id": "mLNW4dnsH9NF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "5f4fc7c4-d501-41fa-ba04-9baec5804a58"
      },
      "cell_type": "code",
      "source": [
        "# Create the baseline model\n",
        "impv_model = get_improved_model()\n",
        "\n",
        "# Train model\n",
        "impv_history = impv_model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2011008688.py:10: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super(BatchNormalizedLayer, self).__init__(**kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'batch_size' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1111594349.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m impv_history = impv_model.fit(\n\u001b[1;32m      6\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Fsz97z1Q-eoA"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the training and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "30JMMBQyIb49"
      },
      "cell_type": "code",
      "source": [
        "visualize_loss_and_acc(impv_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZoqlKrUAIb4_"
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = impv_model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-vfDkCCycqZ"
      },
      "cell_type": "markdown",
      "source": [
        "**Question:** Compare your model to the baseline. What are the diffrences? Does batch normalization work?"
      ]
    },
    {
      "metadata": {
        "id": "VjOOqiDDyf4p"
      },
      "cell_type": "markdown",
      "source": [
        "The improved model converges significantly faster and exhibits a smoother loss landscape. By normalizing the inputs to each layer, we reduce the \"Internal Covariate Shift,\" which allows the optimizer to use higher learning rates without instability. Additionally, BN acts as a slight regularizer, often leading to better generalization and higher test accuracy on the CIFAR-10 dataset compared to the baseline model."
      ]
    },
    {
      "metadata": {
        "id": "oJLRl0DL5aSO"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n"
      ]
    },
    {
      "metadata": {
        "id": "LCQPkvV83Kn0"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Ioffe, Sergey, and Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. ArXiv:1502.03167 [Cs], February 10, 2015. http://arxiv.org/abs/1502.03167.\n",
        "* Im, Daniel Jiwoong, Michael Tao, and Kristin Branson. An Empirical Analysis of the Optimization of Deep Network Loss Surfaces. ArXiv:1612.04010 [Cs], December 12, 2016. http://arxiv.org/abs/1612.04010.\n",
        "* Santurkar, Shibani, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How Does Batch Normalization Help Optimization? In Advances in Neural Information Processing Systems 31, edited by S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, 24832493. Curran Associates, Inc., 2018. http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf.\n",
        "* Coursera Course: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization\n",
        "* Intro to optimization in deep learning: Busting the myth about batch normalization [[link](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)]\n",
        "* Why Does Batch Normalization Work? [[link](https://abay.tech/blog/2018/07/01/why-does-batch-normalization-work/)]\n",
        "*  http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf\n",
        "*  https://medium.com/nanonets/how-to-do-image-segmentation-using-deep-learning-c673cc5862ef\n",
        "* https://www.jeremyjordan.me/semantic-segmentation/\n",
        "\n"
      ]
    }
  ]
}