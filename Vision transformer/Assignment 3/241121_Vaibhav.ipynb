{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION INSTRUCTIONS**\n",
        "\n",
        "First make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "**To write an answer to any question, First Add a TEXT block below the question and type it in only one single block**\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 19/12/2025 Friday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and **under Assignment 3**\n",
        "\n",
        "And remember to keep title of your pull request to be ViT_name_rollno_assgn3\n",
        "\n",
        "Github Submission repo -\n",
        "https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Assignment%203"
      ],
      "metadata": {
        "id": "XmTMSeaTLwVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THEORETICAL ASSIGNMENT**\n",
        "\n"
      ],
      "metadata": {
        "id": "-TjKxTBEz8i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment consists of theoretical questions. Objective answers will not be accepted. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading the question and finding about them). Questions that need less explanation can be answered in 20-100 words. Please ensure the answers are well-written and thorough."
      ],
      "metadata": {
        "id": "AnVa1_8AKqtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vkEIJN_zZeLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Assume that the inputs **X**\n",
        " to some scalar function **f**\n",
        " are **n x m**\n",
        " matrices. What is the dimensionality of the gradient of **f**\n",
        " with respect to **X**?\n",
        "**Give reasons to justify your answer.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ERhYz9qV_YXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> If X is an n×m matrix and f is a scalar function, then the gradient of f with respect to X has the same dimensionality as X, i.e., n× m.\n",
        "\n",
        "This is because the gradient is defined as the matrix of partial derivatives of f with respect to each element of X"
      ],
      "metadata": {
        "id": "_Vw8jkPsZfrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the evaluation metrics Accuracy, Precision, Recall, and F1 score.\n",
        "\n",
        "   Consider the following diagram:\n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score.\n",
        "   |                | Actual: Cancer | Actual: No Cancer |\n",
        "   |----------------|---------------|------------------|\n",
        "   | Predicted: Cancer | 80 | 80 |\n",
        "   | Predicted: No Cancer | 20 | 820 |\n",
        "    \n",
        "   \n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score using the above data.\n"
      ],
      "metadata": {
        "id": "9vnyYHlq2g4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->TP (Cancer correctly predicted) = 80\n",
        "\n",
        "FP (Predicted Cancer, actually No Cancer) = 80\n",
        "\n",
        "FN (Missed Cancer cases) = 20\n",
        "\n",
        "TN (Correctly predicted No Cancer) = 820\n",
        "\n",
        "Total samples = 1000\n",
        "\n",
        "Accuracy measures how often the model is correct overall. It is the ratio of correct predictions to total predictions.\n",
        "\n",
        "Accuracy=(TP+TN)/(FP+FN+TP+TN)\n",
        "\n",
        "Accuracy=(80+820)/1000=0.9\n",
        "\n",
        "Precision tells us how reliable positive predictions are. Out of everything\n",
        "\n",
        "predicted as positive, how many were actually positive.\n",
        "\n",
        "Precision=TP/(TP+FP)\n",
        "\n",
        "Precision=80/(80+80)=0.5\n",
        "\n",
        "Recall measures how well the model detects actual positives. Out of all real positives, how many did the model correctly identify.\n",
        "\n",
        "Recall=TP/(TP+FN)\n",
        "\n",
        "Recall=80/(80+20)=0.8\n",
        "\n",
        "F1 score is the harmonic mean of Precision and Recall. It balances both, especially useful when classes are imbalanced.\n",
        "\n",
        "F1=2⋅Precision⋅Recall/(Precision+Recall)\n",
        "\n",
        "F1=0.615\n"
      ],
      "metadata": {
        "id": "6sSsBdP4Z4OV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is a confusion matrix ?"
      ],
      "metadata": {
        "id": "h1dJMD0vJKZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->A confusion matrix is a table used to evaluate the performance of a classification model by comparing its predicted labels with the actual (ground-truth) labels. It shows not just how many predictions were correct, but what kinds of mistakes the model made."
      ],
      "metadata": {
        "id": "EG3LURSobtZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is overfitting and underfitting ?"
      ],
      "metadata": {
        "id": "aOqF8Dzw0DdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Underfitting happens when a model is too simple to capture the underlying patterns in the data. It fails to learn meaningful relationships, so it performs poorly even on the training data.\n",
        "\n",
        "->Overfitting happens when a model learns the training data too well, including noise and random fluctuations. It performs extremely well on training data but fails to generalize to unseen data.\n"
      ],
      "metadata": {
        "id": "KdfGhnq1cNES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain vanishing and exploding gradients, give reasons why they occur and how they can be prevented.\n"
      ],
      "metadata": {
        "id": "n4KfKc0z0ulm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Vanishing gradients happen when gradients shrink as they are backpropagated through many layers, making earlier layers learn extremely slowly or not at all. This usually occurs in deep networks because gradients are repeatedly multiplied by small derivatives, especially when using saturating activation functions like sigmoid or tanh, or when weights are poorly initialized. It can be prevented by using non-saturating activations like ReLU, proper weight initialization methods such as Xavier or He initialization, batch normalization, and architectural tricks like residual connections or gated units.\n",
        "\n",
        "->Exploding gradients occur when gradients grow uncontrollably as they move backward through the network, causing very large weight updates and unstable training. This is common in deep networks or long recurrent sequences where gradients are repeatedly multiplied by large values. The issue can be prevented by gradient clipping, careful weight initialization, using smaller learning rates, batch normalization, and residual connections."
      ],
      "metadata": {
        "id": "joY4lmE4cUQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is regularization ? Explain L1 and L2 regularization"
      ],
      "metadata": {
        "id": "6yaOipvU1JoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->Regularization is a technique used to prevent overfitting by discouraging a model from becoming too complex. It works by adding a penalty term to the loss function so that the model is forced to keep its weights small and avoid fitting noise in the training data. This improves generalization to unseen data.\n",
        "\n",
        "L1 regularization adds the sum of absolute values of the weights to the loss function. Because it pushes many weights exactly to zero, it naturally performs feature selection and produces sparse models. This is especially useful when you suspect that only a few features are actually important.\n",
        "\n",
        "L2 regularization adds the sum of squares of the weights to the loss function. Instead of making weights zero, it penalizes large weights and spreads importance across many features. This leads to smoother, more stable models and reduces sensitivity to small changes in input."
      ],
      "metadata": {
        "id": "J6GJqX6lI-7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is Dropout Layer and To which part of a neural network is dropout generally applied? how does it prevent overfitting"
      ],
      "metadata": {
        "id": "NjeRGpCE7QJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "->A Dropout layer is a regularization technique where, during training, a random fraction of neurons is temporarily turned off (their outputs are set to zero). This means the network cannot rely on any single neuron and is forced to learn more robust, distributed representations.\n",
        "\n",
        "Dropout is generally applied to the hidden layers of a neural network, especially fully connected layers. It is rarely applied to the output layer, and in convolutional networks it is usually applied after convolution or dense blocks rather than on raw inputs.\n",
        "\n",
        "Dropout prevents overfitting by reducing co-adaptation between neurons. Since different subsets of neurons are active in each training step, the network effectively trains many smaller subnetworks and averages their behavior at inference time. This makes the model less sensitive to noise in the training data and improves generalization."
      ],
      "metadata": {
        "id": "MvsX_znLJG1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. A hidden layer of a neural network has the following activations:\n",
        "\n",
        "   \\[\n",
        "   a = [2.0, 5.0, 7.12, 4.5, 6.0]\n",
        "   \\]\n",
        "\n",
        "   Dropout is applied **during training** with dropout probability \\(p = 0.5\\).\n",
        "\n",
        "   A randomly generated dropout mask is:\n",
        "\n",
        "   \\[\n",
        "   m = [1, 0, 0, 1, 1]\n",
        "   \\]\n",
        "\n",
        "   Here,  \n",
        "   - `1` → neuron is **kept**  \n",
        "   - `0` → neuron is **dropped**\n",
        "\n",
        "   ---\n",
        "\n",
        "   **Question:**  \n",
        "   What will be the output activations of this layer **after applying dropout**?\n",
        "   *(Show the final activation vector)*\n"
      ],
      "metadata": {
        "id": "jLZFLyv4-A67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original activations\n",
        "a = [2.0, 5.0, 7.12, 4.5, 6.0]\n",
        "\n",
        "Dropout mask\n",
        "m = [1, 0, 0, 1, 1]\n",
        "\n",
        "After applying the mask (element-wise multiplication):\n",
        "[2.0, 0, 0, 4.5, 6.0]\n",
        "\n",
        "Since dropout probability p = 0.5, during training we usually use inverted dropout, meaning we scale the kept activations by\n",
        "1/(1-p)=2 to keep the expected value same.\n",
        "\n",
        "Final activations after scaling:\n",
        "[4.0, 0, 0, 9.0, 12.0]\n",
        "\n",
        "So the final output activation vector is:\n",
        "[4.0, 0, 0, 9.0, 12.0]"
      ],
      "metadata": {
        "id": "RbWg25l0JR9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "La3K0HmUGj8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Gradient Descent , the gradient is computed using the entire training dataset before updating the weights. This gives a stable and accurate gradient direction, but it is very slow and memory-heavy for large datasets. It also makes learning impractical when the dataset does not fit in memory.\n",
        "\n",
        "In Stochastic Gradient Descent, the model updates its weights after every single training example. This makes training very fast and allows the model to start learning immediately, but the updates are noisy and the loss can fluctuate heavily. Because of this noise, convergence is less stable, though it can help escape local minima.\n",
        "\n",
        "In Mini-Batch Gradient Descent, the dataset is split into small batches, and the gradient is computed per batch. This balances the stability of batch gradient descent and the speed of SGD. It is the most commonly used approach because it is efficient, stable, and works well with modern hardware like GPUs."
      ],
      "metadata": {
        "id": "9O-JwcloJxqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are optimizers ? Explain Adam, RMS prop and Momentum in detail"
      ],
      "metadata": {
        "id": "FngV9WtV7JxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizers are algorithms that decide how model weights are updated during training in order to minimize the loss function. They control the step size, direction, and stability of learning, and directly affect how fast and how well a neural network converges.\n",
        "\n",
        "Momentum improves basic gradient descent by adding a fraction of the previous update to the current one. Instead of moving only in the direction of the current gradient, it accumulates velocity over time, which helps the optimizer move faster in consistent directions and reduces oscillations in narrow valleys. This leads to smoother and faster convergence, especially for ravine-shaped loss surfaces.\n",
        "\n",
        "RMSprop adapts the learning rate individually for each parameter by keeping an exponential moving average of squared gradients. Parameters with large gradients get smaller learning rates, while those with small gradients get larger ones. This prevents overly large updates and works especially well for non-stationary problems and deep networks where gradients vary significantly.\n",
        "\n",
        "Adam combines the strengths of both Momentum and RMSprop. It keeps an exponential moving average of past gradients and squared gradients. These estimates are bias-corrected and used to adapt learning rates for each parameter. Adam converges faster, is robust to noisy gradients, and works well with minimal tuning, which is why it is the default optimizer in many deep learning tasks."
      ],
      "metadata": {
        "id": "uewHM_P1J-tk"
      }
    }
  ]
}