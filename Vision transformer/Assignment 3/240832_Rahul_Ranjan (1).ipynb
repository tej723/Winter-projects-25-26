{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION INSTRUCTIONS**\n",
        "\n",
        "First make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "**To write an answer to any question, First Add a TEXT block below the question and type it in only one single block**\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 19/12/2025 Friday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and **under Assignment 3**\n",
        "\n",
        "And remember to keep title of your pull request to be ViT_name_rollno_assgn3\n",
        "\n",
        "Github Submission repo -\n",
        "https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Assignment%203"
      ],
      "metadata": {
        "id": "XmTMSeaTLwVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THEORETICAL ASSIGNMENT**\n",
        "\n"
      ],
      "metadata": {
        "id": "-TjKxTBEz8i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment consists of theoretical questions. Objective answers will not be accepted. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading the question and finding about them). Questions that need less explanation can be answered in 20-100 words. Please ensure the answers are well-written and thorough."
      ],
      "metadata": {
        "id": "AnVa1_8AKqtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Assume that the inputs **X**\n",
        " to some scalar function **f**\n",
        " are **n x m**\n",
        " matrices. What is the dimensionality of the gradient of **f**\n",
        " with respect to **X**?\n",
        "**Give reasons to justify your answer.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ERhYz9qV_YXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If inputs $X$ to a scalar function $f$ are an $n \\times m$ matrix, the dimensionality of the gradient of $f$ with respect to $X$ ($\\nabla_X f$) is $n \\times m$.\n",
        "\n",
        "Reasoning:The gradient represents the collection of partial derivatives of the function with respect to every single element of the input. Since $f$ maps the matrix $X$ to a scalar value ($f: \\mathbb{R}^{n \\times m} \\rightarrow \\mathbb{R}$), we must calculate how much $f$ changes as each specific element of $X$ changes.\n",
        "\n",
        "Mathematically, the gradient is defined as a matrix where the element at row $i$ and column $j$ is the partial derivative of $f$ with respect to the element $X_{ij}$:$$(\\nabla_X f)_{ij} = \\frac{\\partial f}{\\partial X_{ij}}$$Since the input matrix $X$ has $n$ rows and $m$ columns, there are exactly $n \\times m$ distinct entries ($X_{11}, X_{12}, ..., X_{nm}$). Consequently, there must be $n \\times m$ corresponding partial derivatives. Therefore, the gradient matrix must have the exact same dimensions as the input matrix $X$ to hold all these derivative values."
      ],
      "metadata": {
        "id": "gfAtIXIYdwJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the evaluation metrics Accuracy, Precision, Recall, and F1 score.\n",
        "\n",
        "   Consider the following diagram:\n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score.\n",
        "   |                | Actual: Cancer | Actual: No Cancer |\n",
        "   |----------------|---------------|------------------|\n",
        "   | Predicted: Cancer | 80 | 80 |\n",
        "   | Predicted: No Cancer | 20 | 820 |\n",
        "    \n",
        "   \n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score using the above data.\n"
      ],
      "metadata": {
        "id": "9vnyYHlq2g4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: Ratio of correct predictions to the total predictions  (# correct prediction/ # Total predictions)\n",
        "\n",
        "Precision: Precision measures how many of the predicted positives were actually correct (True Positives / (True Positive + False Positives))\n",
        "\n",
        "Recall: Recall measures how many of the actual positives the model found(True Positives / (True Positive + False Negatives))\n",
        "\n",
        "F1 score : It Combines the model's Precision and Recall to give evaluation metric (F1 score)\n",
        "\n",
        "F1 Score = 2 x Precision x Recall / (Precision + Recall)\n",
        "\n",
        "For given data:\n",
        "- Accuracy = 0.9 (90%)\n",
        "- Precision = 0.5(50%)\n",
        "- Recall = 0.8 (80%)\n",
        "- F1-score= 0.615 (61.5%)"
      ],
      "metadata": {
        "id": "49oLtoPpxQz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is a confusion matrix ?"
      ],
      "metadata": {
        "id": "h1dJMD0vJKZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix is a matrix representation of TP, TN, FP and FN values, where\n",
        "\n",
        "TP (True Positive) : Prediction = +ve and Ground truth = +ve\n",
        "\n",
        "TN (True Negative) : Prediction = -ve and Ground truth = -ve\n",
        "\n",
        "FP (False Positive) : Prediction = +ve and Ground truth = -ve\n",
        "\n",
        "FN (False Negative) : Prediction = -ve and Ground truth = +ve"
      ],
      "metadata": {
        "id": "rREJJ0eytkYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is overfitting and underfitting ?"
      ],
      "metadata": {
        "id": "aOqF8Dzw0DdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting:\n",
        "- To complex model that learns training data too well (including noises).\n",
        "- It performs great on training data set but bad on new/ test dataset.\n",
        "\n",
        "Underfitting:\n",
        "- Too simple model which performs poorly on both trainning and test dataset.\n",
        "- It have low accuracy and high error"
      ],
      "metadata": {
        "id": "FXQwTuf7vY6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain vanishing and exploding gradients, give reasons why they occur and how they can be prevented.\n"
      ],
      "metadata": {
        "id": "n4KfKc0z0ulm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vanishing and Exploding gradients are problems associated with training Deep Neural Networks (DNNs) via backpropagation.\n",
        "\n",
        "Why they occur:During backpropagation, gradients are calculated using the chain rule, which involves multiplying derivatives of activation functions and weights layer by layer from the output back to the input.\n",
        "- Vanishing Gradients: Occur when the derivatives are small (e.g., $< 1$). As these small numbers are multiplied repeatedly through many layers, the gradient approaches zero. This causes the weights in earlier layers to stop updating, effectively halting the training. This is common with activation functions like Sigmoid or Tanh, which saturate.\n",
        "\n",
        "- Exploding Gradients: Occur when derivatives or weights are large ($> 1$). Repeated multiplication causes the gradients to grow exponentially large, resulting in massive weight updates that destabilize the network (weights become NaN or infinity).\n",
        "\n",
        "Prevention:\n",
        "1. Weight Initialization: Using heuristics like Xavier (Glorot) or He initialization ensures weights start at a scale that maintains variance across layers.\n",
        "2. Activation Functions: Using ReLU (Rectified Linear Unit) helps prevents vanishing gradients because its derivative is either 0 or 1 (non-saturating for positive values).\n",
        "\n",
        "3. Batch Normalization: Normalizes layer inputs, keeping them in a range where derivatives behave well.\n",
        "\n",
        "4. Gradient Clipping: Specifically for exploding gradients, this technique caps the gradient norm at a threshold during backpropagation.\n",
        "\n",
        "5. Residual Connections (ResNets): Skip connections allow gradients to flow through the network more easily."
      ],
      "metadata": {
        "id": "iNzBkdyrbwt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is regularization ? Explain L1 and L2 regularization"
      ],
      "metadata": {
        "id": "6yaOipvU1JoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization is a technique used to prevent overfitting by discouraging the model from learning overly complex patterns that fit the training noise rather than the underlying signal. It achieves this by adding a \"penalty\" term to the loss function during optimization.\n",
        "\n",
        "L1 Regularization (Lasso):\n",
        "- Adds the sum of the absolute values of the weights to the loss function:$$Loss = Error + \\lambda \\sum_{i} |w_i|$$\n",
        "\n",
        "- Effect: It tends to drive some weights exactly to zero. This results in a sparse model, effectively performing feature selection by eliminating less important features.\n",
        "\n",
        "L2 Regularization (Ridge):\n",
        "- Adds the sum of the squared values of the weights to the loss function:$$Loss = Error + \\lambda \\sum_{i} w_i^2$$\n",
        "- Effect: It penalizes large weights heavily but rarely drives them to exactly zero. It encourages the weights to be small and diffuse, distributing the error reduction across all features. This is generally the default choice for neural networks (often called \"Weight Decay\")."
      ],
      "metadata": {
        "id": "OxTdQTcUcmZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is Dropout Layer and To which part of a neural network is dropout generally applied? how does it prevent overfitting"
      ],
      "metadata": {
        "id": "NjeRGpCE7QJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout is a regularization technique where typically randomly selected neurons are ignored (or \"dropped out\") during the training phase. Where it is applied: It is generally applied after the activation function of fully connected (dense) layers, and sometimes after convolutional layers. How it prevents overfitting:\n",
        "\n",
        "1. Prevents Co-adaptation: By randomly dropping neurons, no single neuron can rely solely on the presence of specific other neurons to correct its mistakes. Each neuron is forced to learn more robust features that are useful in a variety of contexts.\n",
        "\n",
        "2. Ensemble Effect: Dropout can be viewed as training a massive ensemble of different \"thinned\" neural networks. At test time, using the full network approximates averaging the predictions of this exponential number of thinned models, which improves generalization."
      ],
      "metadata": {
        "id": "7Gx7ZVlkdn7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MdY8mSq7dHhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. A hidden layer of a neural network has the following activations:\n",
        "\n",
        "   \\[\n",
        "   a = [2.0, 5.0, 7.12, 4.5, 6.0]\n",
        "   \\]\n",
        "\n",
        "   Dropout is applied **during training** with dropout probability \\(p = 0.5\\).\n",
        "\n",
        "   A randomly generated dropout mask is:\n",
        "\n",
        "   \\[\n",
        "   m = [1, 0, 0, 1, 1]\n",
        "   \\]\n",
        "\n",
        "   Here,  \n",
        "   - `1` → neuron is **kept**  \n",
        "   - `0` → neuron is **dropped**\n",
        "\n",
        "   ---\n",
        "\n",
        "   **Question:**  \n",
        "   What will be the output activations of this layer **after applying dropout**?\n",
        "   *(Show the final activation vector)*\n"
      ],
      "metadata": {
        "id": "jLZFLyv4-A67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given:\n",
        "- Activations $a = [2.0, 5.0, 7.12, 4.5, 6.0]$\n",
        "- Mask $m = [1, 0, 0, 1, 1]$ (1=Keep, 0=Drop)\n",
        "- Probability $p = 0.5$ (Dropout probability)\n",
        "\n",
        "Solution: In modern deep learning frameworks (like PyTorch/TensorFlow), Inverted Dropout is used. This means when neurons are kept during training, they are scaled up by $\\frac{1}{1-p}$ to maintain the expected magnitude of the sum, so no scaling is needed at test time.\n",
        "1. Apply Mask: Multiply $a$ by $m$ element-wise.$$[2.0\\times1,~~ 5.0\\times0,~~ 7.12\\times0,~~ 4.5\\times1,~~ 6.0\\times1] = [2.0, 0, 0, 4.5, 6.0]$$\n",
        "2. Apply Scaling (Inverted Dropout):Scaling Factor $= \\frac{1}{1 - p} = \\frac{1}{1 - 0.5} = \\frac{1}{0.5} = 2$Multiply the masked vector by 2.$$[2.0, 0, 0, 4.5, 6.0] \\times 2 = [4.0, 0, 0, 9.0, 12.0]$$\n",
        "\n",
        "Final Activation Vector:$$[4.0, 0, 0, 9.0, 12.0]$$"
      ],
      "metadata": {
        "id": "Jc09Eh_HdJLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "La3K0HmUGj8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent:\n",
        "\n",
        "It uses  the entire dataset to find the gradient.\n",
        "\n",
        "It have Stable convergence (straight path to the minimum).But it is extremely slow for large datasets and requires high memory.\n",
        "\n",
        "Stochastic Gradient Descent:\n",
        "\n",
        "It uses a single training example which is chosen at random to update weights.\n",
        "\n",
        "Pros: Very fast updates; adds noise which can help escape local minima.\n",
        "\n",
        "Cons: Highly unstable convergence (zigzag path); high variance in updates.\n",
        "\n",
        "Mini-Batch Gradient Descent:\n",
        "\n",
        "Uses a small batch of samples (e.g., 32, 64, 128) per update.\n",
        "\n",
        "Pros: The \"sweet spot.\" It offers the stability of Batch GD (due to averaging over the batch) and the speed/computational efficiency of SGD. It also leverages matrix operation optimizations (vectorization) on GPUs.\n"
      ],
      "metadata": {
        "id": "keWGFAuoZcP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are optimizers ? Explain Adam, RMS prop and Momentum in detail"
      ],
      "metadata": {
        "id": "FngV9WtV7JxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizers are algorithms used to update the weights of the neural network to minimize the loss function.\n",
        "\n",
        "Momentum:Standard SGD can get stuck in \"ravines\" (areas where the surface curves much more steeply in one dimension than in another). Momentum helps accelerate SGD in the relevant direction and dampens oscillations. It does this by adding a fraction $\\gamma$ of the previous update vector to the current update vector, effectively building up \"velocity\" in directions with consistent gradients.\n",
        "\n",
        "RMSprop (Root Mean Square Propagation):RMSprop is an adaptive learning rate method. It solves the issue of the learning rate diminishing too quickly (a problem in Adagrad). It keeps a moving average of the squared gradients for each weight. It divides the current gradient by the square root of this average.\n",
        "  \n",
        "  Effect: It penalizes weights with large gradients (forcing smaller updates) and boosts weights with small gradients (allowing larger updates), balancing the step sizes.\n",
        "  \n",
        "Adam (Adaptive Moment Estimation):Adam is widely considered the best overall optimizer for most cases. It combines the best properties of Momentum and RMSprop.\n",
        "- It computes adaptive learning rates for each parameter.\n",
        "- It stores both the decaying average of past gradients (first moment, like Momentum) and the decaying average of past squared gradients (second moment, like RMSprop).\n",
        "- It is generally fast, requires little tuning, and handles sparse gradients and noisy problems well."
      ],
      "metadata": {
        "id": "4LKq-RTSa-hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5SPbnaPka_EJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}