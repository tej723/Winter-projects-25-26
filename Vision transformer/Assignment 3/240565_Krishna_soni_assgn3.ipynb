{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION INSTRUCTIONS**\n",
        "\n",
        "First make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "**To write an answer to any question, First Add a TEXT block below the question and type it in only one single block**\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 19/12/2025 Friday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and **under Assignment 3**\n",
        "\n",
        "And remember to keep title of your pull request to be ViT_name_rollno_assgn3\n",
        "\n",
        "Github Submission repo -\n",
        "https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Assignment%203"
      ],
      "metadata": {
        "id": "XmTMSeaTLwVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THEORETICAL ASSIGNMENT**\n",
        "\n"
      ],
      "metadata": {
        "id": "-TjKxTBEz8i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment consists of theoretical questions. Objective answers will not be accepted. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading the question and finding about them). Questions that need less explanation can be answered in 20-100 words. Please ensure the answers are well-written and thorough."
      ],
      "metadata": {
        "id": "AnVa1_8AKqtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Assume that the inputs **X**\n",
        " to some scalar function **f**\n",
        " are **n x m**\n",
        " matrices. What is the dimensionality of the gradient of **f**\n",
        " with respect to **X**?\n",
        "**Give reasons to justify your answer.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ERhYz9qV_YXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensionality of the gradient of a scalar function $f$ with respect to an $n \\times m$ matrix $X$ is $n \\times m$.                                                                                                                                                           Reasoning:The gradient, denoted as $\\nabla_X f$, is defined as the collection of partial derivatives of the scalar function $f$ with respect to every individual element of the input variable $X$. Since the input $X$ is a matrix with dimensions $n \\times m$, it contains $n \\times m$ distinct scalar entries, $X_{ij}$. Consequently, we must calculate a partial derivative $\\frac{\\partial f}{\\partial X_{ij}}$ for each of these entries.By convention in matrix calculus, these partial derivatives are organized into a matrix that matches the shape of the original input. This structure is essential because it allows the gradient to be used in element-wise operations with the input matrix, such as the parameter updates performed during gradient descent training in neural networks. Therefore, the gradient matrix must have the same number of rows ($n$) and columns ($m$) as the input matrix $X$.2. Evaluation Metrics"
      ],
      "metadata": {
        "id": "5pYcMSKcy9Oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the evaluation metrics Accuracy, Precision, Recall, and F1 score.\n",
        "\n",
        "   Consider the following diagram:\n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score.\n",
        "   |                | Actual: Cancer | Actual: No Cancer |\n",
        "   |----------------|---------------|------------------|\n",
        "   | Predicted: Cancer | 80 | 80 |\n",
        "   | Predicted: No Cancer | 20 | 820 |\n",
        "    \n",
        "   \n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score using the above data.\n"
      ],
      "metadata": {
        "id": "9vnyYHlq2g4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitions:Accuracy: This metric measures the overall correctness of the model. It is defined as the ratio of correctly predicted observations (both True Positives and True Negatives) to the total number of observations.Precision: This measures the exactness of the positive predictions. It is the ratio of correctly predicted positive observations (True Positives) to the total number of observations predicted as positive (True Positives + False Positives).Recall (Sensitivity): This measures the completeness of the positive predictions. It is the ratio of correctly predicted positive observations to the total number of actual positive observations in the dataset.F1 Score: This is the harmonic mean of Precision and Recall. It is used to find a balance between Precision and Recall, which is particularly useful when the class distribution is uneven (imbalanced data).Calculations:Based on the provided confusion matrix, the values are:True Positives (TP): 80False Positives (FP): 80False Negatives (FN): 20True Negatives (TN): 820Total Observations: 1000Accuracy:$$\\frac{TP + TN}{\\text{Total}} = \\frac{80 + 820}{1000} = \\frac{900}{1000} = \\mathbf{0.9}$$Precision:$$\\frac{TP}{TP + FP} = \\frac{80}{80 + 80} = \\frac{80}{160} = \\mathbf{0.5}$$Recall:$$\\frac{TP}{TP + FN} = \\frac{80}{80 + 20} = \\frac{80}{100} = \\mathbf{0.8}$$F1 Score:$$2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\cdot \\frac{0.5 \\cdot 0.8}{0.5 + 0.8} = 2 \\cdot \\frac{0.4}{1.3} \\approx \\mathbf{0.615}$$"
      ],
      "metadata": {
        "id": "Sv2AaNdFy_Mn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is a confusion matrix ?"
      ],
      "metadata": {
        "id": "h1dJMD0vJKZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix is a tabular visualization used to evaluate the performance of a classification model.1 Unlike a single metric like accuracy, which gives a general idea of correctness, a confusion matrix provides a granular breakdown of how the model's predictions compare to the actual ground truth values.2 It is an 3$N \\times N$ matrix, where 4$N$ is the number of target classes.5"
      ],
      "metadata": {
        "id": "Ymdy7xU5zAYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is overfitting and underfitting ?"
      ],
      "metadata": {
        "id": "aOqF8Dzw0DdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Overfitting**: Overfitting occurs when a machine learning model learns the training data too well. It captures not only the underlying patterns but also the noise, random fluctuations, and specific details of that particular dataset. As a result, the model performs exceptionally well on the training data (high accuracy) but fails to generalize to new, unseen data (poor test accuracy). This is often described as the model having high variance. It is analogous to a student who memorizes the textbook word-for-word but cannot answer conceptual questions on an exam.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Underfitting**: Underfitting happens when a model is too simple to capture the underlying structure of the data. It fails to learn the patterns in the training data effectively, resulting in poor performance on both the training and the testing datasets. This is typically described as the model having high bias. Using the student analogy, this is like a student who barely studies and performs poorly on both the practice quizzes and the final exam."
      ],
      "metadata": {
        "id": "bDmyfATjzBXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain vanishing and exploding gradients, give reasons why they occur and how they can be prevented.\n"
      ],
      "metadata": {
        "id": "n4KfKc0z0ulm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitions and Causes: Vanishing and exploding gradients are significant problems in training deep neural networks, arising from the Chain Rule used in backpropagation.\n",
        "\n",
        "Vanishing Gradients: This occurs when gradients become effectively zero as they propagate backward to earlier layers. It happens because activation functions like Sigmoid or Tanh have derivatives smaller than 1. When these small values are multiplied repeatedly across many layers, the gradient decays exponentially. Consequently, the initial layers stop learning, preventing the model from capturing low-level features.\n",
        "\n",
        "Exploding Gradients: Conversely, this occurs when gradients accumulate and become excessively large. This is often caused by improper weight initialization (weights > 1) or long sequences in Recurrent Neural Networks (RNNs). The repeated multiplication results in massive weight updates, causing the model to become unstable and the loss to diverge.\n",
        "\n",
        "Prevention Methods:\n",
        "\n",
        "Activation Functions: Using ReLU (Rectified Linear Unit) is the most common fix for vanishing gradients. Since the derivative of ReLU is 1 for positive inputs, it prevents the gradient signal from shrinking as it passes through layers.\n",
        "\n",
        "Weight Initialization: Proper initialization techniques, such as He Initialization (for ReLU) or Xavier Initialization, ensure that the variance of activations remains consistent, preventing signals from vanishing or exploding at the start.\n",
        "\n",
        "Batch Normalization: This technique normalizes the inputs of each layer, stabilizing the learning process and allowing for higher learning rates.\n",
        "\n",
        "Gradient Clipping: To prevent exploding gradients, the norm of the gradient vector is \"clipped\" or capped at a threshold. If the gradient exceeds this limit, it is scaled down before updating the weights.\n",
        "\n",
        "Residual Connections: Architectures like ResNets use skip connections to allow gradients to flow directly to earlier layers, bypassing potential bottlenecks."
      ],
      "metadata": {
        "id": "t0w19UxBzCPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is regularization ? Explain L1 and L2 regularization"
      ],
      "metadata": {
        "id": "6yaOipvU1JoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition:Regularization is a technique used in machine learning to prevent overfitting and improve the generalization of a model.1 When a model becomes too complex, it often \"memorizes\" the noise in the training data rather than learning the underlying patterns, leading to poor performance on new data.2 Regularization addresses this by adding a penalty term to the loss function during training.3 This penalty discourages the model from assigning excessively large weights to features, forcing the model to remain simpler and smoother.4L1 Regularization (Lasso):L1 regularization, often called Lasso Regression (Least Absolute Shrinkage and Selection Operator), adds a penalty equal to the sum of the absolute values of the weights:5$$Loss_{new} = Loss_{original} + \\lambda \\sum_{i} |w_i|$$The defining characteristic of L1 is that it can shrink the coefficients of less important features entirely to zero.6 This means L1 performs automatic feature selection, making it highly effective when dealing with high-dimensional datasets where many features might be irrelevant (sparse solutions).7L2 Regularization (Ridge):L2 regularization, or Ridge Regression, adds a penalty equal to the sum of the squared magnitudes of the weights:8$$Loss_{new} = Loss_{original} + \\lambda \\sum_{i} w_i^2$$Unlike L1, L2 regularization shrinks the weights towards zero but rarely makes them exactly zero.9 It retains all features but minimizes their individual influence.10 This method is particularly useful for handling multicollinearity (when features are highly correlated) and ensures that the model relies on a combination of all features rather than just a few strong ones.11"
      ],
      "metadata": {
        "id": "n_UBfBsVzC8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is Dropout Layer and To which part of a neural network is dropout generally applied? how does it prevent overfitting"
      ],
      "metadata": {
        "id": "NjeRGpCE7QJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition**:\n",
        "A Dropout Layer is a regularization technique used in neural networks to prevent overfitting.1 During the training phase, it randomly \"drops out\" (i.e., temporarily ignores) a specific subset of neurons in a layer with a probability 2$p$ (commonly 0.5).3 This means those neurons do not contribute to the forward pass and are not updated during the backward pass for that specific iteration.4\n",
        "\n",
        "**Where it is Applied**:\n",
        "Dropout is generally applied to the fully connected (dense) layers of a neural network, where the number of parameters is highest and overfitting is most likely.5 It is inserted after the activation function of a layer.6 Crucially, dropout is only active during training.7 During testing/inference, all neurons remain active, but their weights are typically scaled down by the factor 8$p$ to maintain consistent magnitude.9\n",
        "\n",
        "**How it Prevents Overfitting**:\n",
        "\n",
        "**Breaking Co-adaptation**: Without dropout, neurons often develop complex co-dependencies, where one neuron relies on specific corrections from another to function correctly. By randomly removing neurons, each neuron is forced to learn more robust features independently, without relying on the presence of others.\n",
        "\n",
        "\n",
        "**Ensemble Effect**: Dropout can be viewed as training a massive ensemble of different \"thinned\" neural networks that share weights. In every iteration, a slightly different network architecture is trained. When the full network is used for testing, it acts as an average of all these thinner networks, which naturally reduces variance and improves generalization"
      ],
      "metadata": {
        "id": "wZLeL_lAzECI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. A hidden layer of a neural network has the following activations:\n",
        "\n",
        "   \\[\n",
        "   a = [2.0, 5.0, 7.12, 4.5, 6.0]\n",
        "   \\]\n",
        "\n",
        "   Dropout is applied **during training** with dropout probability \\(p = 0.5\\).\n",
        "\n",
        "   A randomly generated dropout mask is:\n",
        "\n",
        "   \\[\n",
        "   m = [1, 0, 0, 1, 1]\n",
        "   \\]\n",
        "\n",
        "   Here,  \n",
        "   - `1` → neuron is **kept**  \n",
        "   - `0` → neuron is **dropped**\n",
        "\n",
        "   ---\n",
        "\n",
        "   **Question:**  \n",
        "   What will be the output activations of this layer **after applying dropout**?\n",
        "   *(Show the final activation vector)*\n"
      ],
      "metadata": {
        "id": "jLZFLyv4-A67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given:Input Activations vector $a = [2.0, 5.0, 7.12, 4.5, 6.0]$Dropout Probability $p = 0.5$Dropout Mask $m = [1, 0, 0, 1, 1]$ (where 1 = keep, 0 = drop)Method (Inverted Dropout):In modern deep learning frameworks (like PyTorch and TensorFlow), \"Inverted Dropout\" is the standard implementation. This technique involves two steps during the training phase:Masking: Multiply the input activations element-wise by the mask.Scaling: Scale the remaining activations by a factor of $\\frac{1}{1-p}$ to maintain the expected sum of activations. This ensures that the magnitude of the neuron outputs remains consistent between training and testing (when no neurons are dropped).Step-by-Step Calculation:Apply Mask:$$a_{masked} = a \\odot m$$$$a_{masked} = [2.0 \\times 1, \\quad 5.0 \\times 0, \\quad 7.12 \\times 0, \\quad 4.5 \\times 1, \\quad 6.0 \\times 1]$$$$a_{masked} = [2.0, \\quad 0.0, \\quad 0.0, \\quad 4.5, \\quad 6.0]$$Apply Scaling:Calculate the scaling factor:$$\\text{Scale Factor} = \\frac{1}{1 - p} = \\frac{1}{1 - 0.5} = \\frac{1}{0.5} = 2$$Multiply the masked vector by the scaling factor:$$a_{final} = a_{masked} \\times 2$$$$a_{final} = [2.0 \\times 2, \\quad 0.0 \\times 2, \\quad 0.0 \\times 2, \\quad 4.5 \\times 2, \\quad 6.0 \\times 2]$$"
      ],
      "metadata": {
        "id": "E3WV6unyzFyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "La3K0HmUGj8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent (Batch Gradient Descent): In standard Batch Gradient Descent, the model calculates the gradient of the loss function using the entire training dataset before making a single update to the weights.\n",
        "\n",
        "Pros: The error gradient is stable, and the convergence path is smooth and direct.\n",
        "\n",
        "Cons: It is computationally very expensive and slow for large datasets because every single sample must be processed just to take one step. It also requires significant memory to load the full dataset.\n",
        "\n",
        "Stochastic Gradient Descent (SGD): SGD updates the model weights after processing a single random training example at a time.\n",
        "\n",
        "Pros: It is extremely fast per step and consumes very little memory. The noise introduced by updating on single examples can help the model escape shallow local minima.\n",
        "\n",
        "Cons: The convergence path is extremely noisy and oscillates heavily (zig-zag pattern) rather than moving directly toward the minimum. This can make it difficult for the model to settle on the exact optimal solution.\n",
        "\n",
        "Mini-Batch Gradient Descent: Mini-Batch GD is the compromise between Batch GD and SGD. It splits the dataset into small batches (e.g., 32, 64, or 128 samples) and updates the weights after processing each batch.\n",
        "\n",
        "Pros: It combines the stability of Batch GD with the speed of SGD. Matrix operations on batches are computationally efficient (optimized for GPUs), and the convergence is smoother than SGD while still being faster than Batch GD. This is the standard algorithm used in deep learning today."
      ],
      "metadata": {
        "id": "_aRQgNbTzGjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are optimizers ? Explain Adam, RMS prop and Momentum in detail"
      ],
      "metadata": {
        "id": "FngV9WtV7JxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition**:Optimizers are algorithms or methods used to change the attributes of a neural network, such as weights and learning rates, in order to reduce the losses. They solve the optimization problem by minimizing the function $J(\\theta)$ (the loss function) through the iterative update of model parameters.\n",
        "\n",
        "**Momentum**:Standard Stochastic Gradient Descent (SGD) has trouble navigating areas where the surface curves much more steeply in one dimension than another (ravines), leading to oscillation. Momentum addresses this by adding a fraction of the past update vector to the current update vector. It accelerates convergence in the relevant direction and dampens oscillations.Concept: It builds \"velocity\" in directions with consistent gradients.\n",
        "\n",
        "**Formula**: $v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta)$, where $\\gamma$ is the momentum term (usually 0.9).RMSprop (Root Mean Square Propagation):RMSprop is an adaptive learning rate method designed to resolve the diminishing learning rates encountered in Adagrad. It adapts the learning rate for each parameter individually.\n",
        "\n",
        "**Concept**: It maintains a moving average of the squared gradients. It divides the current gradient by the square root of this average. This effectively penalizes large gradients (preventing explosion) and boosts small gradients (preventing vanishing), ensuring the step size is appropriate for each weight.\n",
        "\n",
        "**Adam (Adaptive Moment Estimation)**:Adam is currently the most popular optimizer because it combines the best properties of both Momentum and RMSprop.\n",
        "\n",
        "**Concept**: It computes adaptive learning rates for each parameter. It stores both an exponentially decaying average of past gradients (First Moment, like Momentum) and an exponentially decaying average of past squared gradients (Second Moment, like RMSprop).\n",
        "\n",
        "**Mechanism**: It uses these moments to update parameters, ensuring smooth convergence and handling sparse gradients effectively. It also includes bias correction to improve performance at the start of training."
      ],
      "metadata": {
        "id": "Pe3I6GhmzHOr"
      }
    }
  ]
}