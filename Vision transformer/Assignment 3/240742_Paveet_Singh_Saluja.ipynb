{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION INSTRUCTIONS**\n",
        "\n",
        "First make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "**To write an answer to any question, First Add a TEXT block below the question and type it in only one single block**\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 19/12/2025 Friday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and **under Assignment 3**\n",
        "\n",
        "And remember to keep title of your pull request to be ViT_name_rollno_assgn3\n",
        "\n",
        "Github Submission repo -\n",
        "https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Assignment%203"
      ],
      "metadata": {
        "id": "XmTMSeaTLwVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THEORETICAL ASSIGNMENT**\n",
        "\n"
      ],
      "metadata": {
        "id": "-TjKxTBEz8i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment consists of theoretical questions. Objective answers will not be accepted. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading the question and finding about them). Questions that need less explanation can be answered in 20-100 words. Please ensure the answers are well-written and thorough."
      ],
      "metadata": {
        "id": "AnVa1_8AKqtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Assume that the inputs **X**\n",
        " to some scalar function **f**\n",
        " are **n x m**\n",
        " matrices. What is the dimensionality of the gradient of **f**\n",
        " with respect to **X**?\n",
        "**Give reasons to justify your answer.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ERhYz9qV_YXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a scalar function $f$ where the input $\\mathbf{X}$ is an $n \\times m$ matrix, the dimensionality of the gradient $\\nabla_{\\mathbf{X}} f$ is $n \\times m$.\n",
        "1. Definition by Partial Derivatives : The gradient of a scalar-valued function with respect to a matrix is defined as the matrix of partial derivatives of that function with respect to each element of the input matrix. If the input matrix $\\mathbf{X}$ has dimensions $n \\times m$, it contains $n \\times m$ individual scalar variables $x_{i,j}$ (where $i$ ranges from $1$ to $n$ and $j$ from $1$ to $m$).The gradient $\\nabla_{\\mathbf{X}} f$ is an arrangement where the element at the $i$-th row and $j$-th column is the partial derivative of $f$ with respect to $x_{i,j}$:$$[\\nabla_{\\mathbf{X}} f]_{i,j} = \\frac{\\partial f}{\\partial x_{i,j}}$$Since there are $n$ rows and $m$ columns of such variables, the resulting gradient matrix naturally inherits the $n \\times m$ shape.\n",
        "2. The Principle of Total Differential : In multivariable calculus, the total differential $df$ represents the change in the output of the function for an infinitesimal change $d\\mathbf{X}$ in the input. For a scalar function, this is given by:$$df = \\sum_{i=1}^n \\sum_{j=1}^m \\frac{\\partial f}{\\partial x_{i,j}} dx_{i,j}$$In matrix calculus notation, this sum is expressed using the Frobenius inner product:$$df = \\langle \\nabla_{\\mathbf{X}} f, d\\mathbf{X} \\rangle_F = \\text{Tr}((\\nabla_{\\mathbf{X}} f)^T d\\mathbf{X})$$For the inner product to be defined, the two matrices involved—the gradient $\\nabla_{\\mathbf{X}} f$ and the differential $d\\mathbf{X}$—must have identical dimensions. Since $d\\mathbf{X}$ is a matrix of the same size as $\\mathbf{X}$ ($n \\times m$), the gradient $\\nabla_{\\mathbf{X}} f$ must also be $n \\times m$.\n",
        "3. Consistency in Optimization (Gradient Descent) : In practical applications like Machine Learning, we update parameters using the gradient. The update rule is typically:$$\\mathbf{X}_{new} = \\mathbf{X}_{old} - \\eta \\nabla_{\\mathbf{X}} f$$This operation (matrix subtraction) is only mathematically valid if the gradient $\\nabla_{\\mathbf{X}} f$ has the exact same dimensions as the parameter matrix $\\mathbf{X}$. Thus, to maintain structural consistency, the gradient must be $n \\times m$."
      ],
      "metadata": {
        "id": "9-CJhlynl6c4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the evaluation metrics Accuracy, Precision, Recall, and F1 score.\n",
        "\n",
        "   Consider the following diagram:\n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score.\n",
        "   |                | Actual: Cancer | Actual: No Cancer |\n",
        "   |----------------|---------------|------------------|\n",
        "   | Predicted: Cancer | 80 | 80 |\n",
        "   | Predicted: No Cancer | 20 | 820 |\n",
        "    \n",
        "   \n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score using the above data.\n"
      ],
      "metadata": {
        "id": "9vnyYHlq2g4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cancer is the Positive class and No Cancer is the Negative class :\n",
        "\n",
        "True Positive (TP): 80 (Correctly predicted Cancer)\n",
        "\n",
        "True Negative (TN): 820 (Correctly predicted No Cancer)\n",
        "\n",
        "False Positive (FP): 80 (Incorrectly predicted Cancer; Type I Error)\n",
        "\n",
        "False Negative (FN): 20 (Incorrectly predicted No Cancer; Type II Error)\n",
        "\n",
        "Accuracy : The ratio of correctly predicted observations to the total observations. It answers: Overall, how often is the classifier correct?\n",
        "\n",
        "Accuracy = $\\frac{TP + TN}{TP + TN + FP + FN}$ = $\\frac{80 + 820}{80 + 820 + 80 + 20} = \\frac{900}{1000} = \\mathbf{0.90}$ (or 90%)\n",
        "\n",
        "Precision : The ratio of correctly predicted positive observations to the total predicted positives. It answers: Of all patients predicted to have cancer, how many actually had it.\n",
        "\n",
        "Precision = $\\frac{TP}{TP + FP}$ = $\\frac{80}{80 + 80} = \\frac{80}{160} = \\mathbf{0.50}$ (or 50%)\n",
        "\n",
        "Recall (Sensitivity) : The ratio of correctly predicted positive observations to all actual positives. It answers: Of all patients who actually had cancer, how many did we correctly identify?\n",
        "\n",
        "Recall = $\\frac{TP}{TP + FN}$ = $\\frac{80}{80 + 20} = \\frac{80}{100} = \\mathbf{0.80}$ (or 80%)\n",
        "\n",
        "F1 Score : The harmonic mean of Precision and Recall. It is a useful metric when we have an uneven class distribution and need a balance between Precision and Recall.\n",
        "\n",
        "F1 Score = $2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$ = $2 \\times \\frac{0.5 \\times 0.8}{0.5 + 0.8} = 2 \\times \\frac{0.4}{1.3} = \\frac{0.8}{1.3} \\approx \\mathbf{0.615}$"
      ],
      "metadata": {
        "id": "M-aUaThPl-A5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is a confusion matrix ?"
      ],
      "metadata": {
        "id": "h1dJMD0vJKZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Confusion Matrix is a performance measurement tool used in machine learning for classification problems. It is a table that allows visualization of the performance of an algorithm by comparing the Actual target values with those Predicted by the model.\n",
        "\n",
        "In a binary classification case, it is a $2 \\times 2$ matrix consisting of:\n",
        "\n",
        "True Positives (TP): The model correctly predicted the positive class.\n",
        "\n",
        "True Negatives (TN): The model correctly predicted the negative class.\n",
        "\n",
        "False Positives (FP): The model incorrectly predicted the positive class (Type I Error).\n",
        "\n",
        "False Negatives (FN): The model incorrectly predicted the negative class (Type II Error)."
      ],
      "metadata": {
        "id": "R2QQ6eOzl_Ea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is overfitting and underfitting ?"
      ],
      "metadata": {
        "id": "aOqF8Dzw0DdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Underfitting: This occurs when a model is too simple to capture the underlying pattern of the data. It typically results in high error (bias) on both the training data and the unseen test data because the model has not learned enough from the features.\n",
        "\n",
        "Overfitting: This happens when a model is overly complex and learns the noise or random fluctuations in the training data rather than the intended pattern. While the model performs exceptionally well on training data (low bias), it fails to generalize to new, unseen data (high variance)."
      ],
      "metadata": {
        "id": "Pjqox-fzl_zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain vanishing and exploding gradients, give reasons why they occur and how they can be prevented.\n"
      ],
      "metadata": {
        "id": "n4KfKc0z0ulm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitions :\n",
        "\n",
        "Vanishing Gradients: This occurs during backpropagation when gradients become extremely small, effectively vanishing. This stops the weights from updating, preventing the network from learning.\n",
        "\n",
        "Exploding Gradients: This occurs when gradients accumulate and result in very large updates to the network weights, leading to an unstable model that cannot converge.\n",
        "\n",
        "Reasons Why They Occur :\n",
        "\n",
        "Vanishing: Often caused by using certain activation functions (like Sigmoid or Tanh) in very deep networks. The derivative of these functions is small, and when multiplied across many layers, the gradient decreases exponentially.\n",
        "\n",
        "Exploding: Usually caused by large weight initializations or the accumulation of gradients in deep networks (especially Recurrent Neural Networks), where large derivatives multiply together.\n",
        "\n",
        "Prevention Methods :\n",
        "\n",
        "Activation Functions: Use ReLU (Rectified Linear Unit) instead of Sigmoid/Tanh to avoid small derivatives.\n",
        "\n",
        "Weight Initialization: Use techniques like He initialization or Xavier initialization to keep gradients in a reasonable range.\n",
        "\n",
        "Batch Normalization: Normalizing layer inputs to stabilize the learning process.\n",
        "\n",
        "Gradient Clipping: For exploding gradients, cap the maximum value a gradient can take during training."
      ],
      "metadata": {
        "id": "umIsbTKVmAul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is regularization ? Explain L1 and L2 regularization"
      ],
      "metadata": {
        "id": "6yaOipvU1JoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. This discourages the model from learning overly complex patterns or relying too heavily on specific features.\n",
        "\n",
        "L1 Regularization (Lasso): It adds a penalty equal to the absolute value of the magnitude of coefficients.\n",
        "\n",
        "Formula Penalty: $\\lambda \\sum |w_i|$\n",
        "\n",
        "Effect: It can shrink some coefficients to exactly zero, effectively performing feature selection.\n",
        "\n",
        "L2 Regularization (Ridge): It adds a penalty equal to the square of the magnitude of coefficients.\n",
        "\n",
        "Formula Penalty: $\\lambda \\sum w_i^2$\n",
        "\n",
        "Effect: It forces coefficients to be small but rarely exactly zero, resulting in a model where all features contribute but none dominate excessively."
      ],
      "metadata": {
        "id": "qfUW7OOpmBfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is Dropout Layer and To which part of a neural network is dropout generally applied? how does it prevent overfitting"
      ],
      "metadata": {
        "id": "NjeRGpCE7QJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Dropout Layer is a regularization technique where a randomly selected subset of neurons is ignored (set to zero) during each training step.\n",
        "\n",
        "Application: It is generally applied to the fully connected (dense) layers of a neural network during the training phase.\n",
        "\n",
        "How it Prevents Overfitting : By randomly dropping neurons, dropout prevents neurons from co-adapting too much to the training data. It forces the network to learn more robust features that are useful across different subsets of neurons, effectively acting like an ensemble of many smaller networks."
      ],
      "metadata": {
        "id": "TAHtz9tVmCZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. A hidden layer of a neural network has the following activations:\n",
        "\n",
        "   \\[\n",
        "   a = [2.0, 5.0, 7.12, 4.5, 6.0]\n",
        "   \\]\n",
        "\n",
        "   Dropout is applied **during training** with dropout probability \\(p = 0.5\\).\n",
        "\n",
        "   A randomly generated dropout mask is:\n",
        "\n",
        "   \\[\n",
        "   m = [1, 0, 0, 1, 1]\n",
        "   \\]\n",
        "\n",
        "   Here,  \n",
        "   - `1` → neuron is **kept**  \n",
        "   - `0` → neuron is **dropped**\n",
        "\n",
        "   ---\n",
        "\n",
        "   **Question:**  \n",
        "   What will be the output activations of this layer **after applying dropout**?\n",
        "   *(Show the final activation vector)*\n"
      ],
      "metadata": {
        "id": "jLZFLyv4-A67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given:\n",
        "Activations:\n",
        "\n",
        "$a = [2.0, 5.0, 7.12, 4.5, 6.0]$\n",
        "\n",
        "Dropout mask: $m = [1, 0, 0, 1, 1]$ (where 1 = kept, 0 = dropped)\n",
        "\n",
        "Dropout probability: $p = 0.5$\n",
        "\n",
        "Step 1: Element-wise multiplication : To apply the mask, we multiply the activations by the mask:\n",
        "\n",
        "$2.0 \\times 1 = 2.0$\n",
        "\n",
        "$5.0 \\times 0 = 0.0$\n",
        "\n",
        "$7.12 \\times 0 = 0.0$\n",
        "\n",
        "$4.5 \\times 1 = 4.5$\n",
        "\n",
        "$6.0 \\times 1 = 6.0$\n",
        "\n",
        "Step 2: Scaling (Inverted Dropout) : In modern implementations (Inverted Dropout), the remaining activations are divided by $(1 - p)$ to maintain the same expected sum of activations during testing:\n",
        "\n",
        "Scale factor = $1 / (1 - 0.5) = 1 / 0.5 = 2$\n",
        "\n",
        "$2.0 \\times 2 = 4.0$\n",
        "\n",
        "$4.5 \\times 2 = 9.0$\n",
        "\n",
        "$6.0 \\times 2 = 12.0$\n",
        "\n",
        "Final Activation Vector:$[4.0, 0.0, 0.0, 9.0, 12.0]$"
      ],
      "metadata": {
        "id": "z46MVegUmDpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "La3K0HmUGj8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent (Batch): Uses the entire dataset to calculate the gradient and update weights once per epoch. It is slow for large datasets but stable.\n",
        "\n",
        "Stochastic Gradient Descent (SGD): Updates weights after calculating the gradient for each individual sample. It is faster but has high variance in updates.\n",
        "\n",
        "Mini-Batch Gradient Descent: Updates weights after calculating the gradient for a small subset (batch) of the data. It combines the stability of Batch GD with the speed of SGD."
      ],
      "metadata": {
        "id": "rh_zL6SOmFE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are optimizers ? Explain Adam, RMS prop and Momentum in detail"
      ],
      "metadata": {
        "id": "FngV9WtV7JxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizers are algorithms used to change the attributes of the neural network, such as weights and learning rates, to reduce losses.\n",
        "\n",
        "Momentum: Accelerates Gradient Descent by taking into account the previous gradients to smooth out the updates.\n",
        "\n",
        "RMS prop: Adapts the learning rate for each parameter by dividing the gradient by a running average of its recent magnitudes.\n",
        "\n",
        "Adam (Adaptive Moment Estimation): Combines the ideas of Momentum and RMSprop. It calculates adaptive learning rates for each parameter by storing both an exponentially decaying average of past squared gradients and past gradients."
      ],
      "metadata": {
        "id": "-ry1abVUmF4H"
      }
    }
  ]
}