{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION INSTRUCTIONS**\n",
        "\n",
        "First make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "**To write an answer to any question, First Add a TEXT block below the question and type it in only one single block**\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 19/12/2025 Friday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and **under Assignment 3**\n",
        "\n",
        "And remember to keep title of your pull request to be ViT_name_rollno_assgn3\n",
        "\n",
        "Github Submission repo -\n",
        "https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Assignment%203"
      ],
      "metadata": {
        "id": "XmTMSeaTLwVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THEORETICAL ASSIGNMENT**\n",
        "\n"
      ],
      "metadata": {
        "id": "-TjKxTBEz8i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment consists of theoretical questions. Objective answers will not be accepted. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading the question and finding about them). Questions that need less explanation can be answered in 20-100 words. Please ensure the answers are well-written and thorough."
      ],
      "metadata": {
        "id": "AnVa1_8AKqtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Assume that the inputs **X**\n",
        " to some scalar function **f**\n",
        " are **n x m**\n",
        " matrices. What is the dimensionality of the gradient of **f**\n",
        " with respect to **X**?\n",
        "**Give reasons to justify your answer.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ERhYz9qV_YXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "If the input to function f i.e. X has dimensions (n x m) then gradient of f with respect to X will also have the same dimensions as X i.e. (n x m)\n",
        "\n",
        "Considering a matrix X of dimension (n x m). It is evident that this matrix has n\\*m elements. Since, f is a scalar function as mentioned in the question, it gives output as a single number. Since, X has n*m inputs, each element of X affects the scalar output independently, so the gradient must contain one partial derivative for each element of X, resulting in the same shape as X.\n",
        "Hence, this forms a matrix of the same size as X.\n",
        "\n",
        "In matrix form, we can write this as <br>\n",
        "If matrix X has n\\*m elements,\n",
        "then the gradient, will also have n*m elements.\n",
        "$$\n",
        "\\frac{\\partial f}{\\partial X}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial f}{\\partial X_{11}} & \\cdots & \\frac{\\partial f}{\\partial X_{1m}} \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "\\frac{\\partial f}{\\partial X_{n1}} & \\cdots & \\frac{\\partial f}{\\partial X_{nm}}\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "AGuzJECLZzz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the evaluation metrics Accuracy, Precision, Recall, and F1 score.\n",
        "\n",
        "   Consider the following diagram:\n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score.\n",
        "   |                | Actual: Cancer | Actual: No Cancer |\n",
        "   |----------------|---------------|------------------|\n",
        "   | Predicted: Cancer | 80 | 80 |\n",
        "   | Predicted: No Cancer | 20 | 820 |\n",
        "    \n",
        "   \n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score using the above data.\n"
      ],
      "metadata": {
        "id": "9vnyYHlq2g4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "For the following answer, <br>\n",
        "TP - True Positives<br>\n",
        "TN - True Negatives<br>\n",
        "FP - False Positives<Br>\n",
        "FN - False Negatives<br>\n",
        "1. Accuracy: <br>\n",
        "Accuracy is the percentage of correctly classified samples out of the total number of samples. This metric should be preferred when our dataset has roughly equal proportions of each class.<br>\n",
        "\n",
        "$$\n",
        "\\text{Accuracy}\n",
        "=\n",
        "\\frac{TP + TN}{TP + TN + FP + FN}\n",
        "$$\n",
        "\n",
        "2. Precision: <br>\n",
        "Precision metric measures the ratio of truly positive cases to the total predicted positive cases. This is a useful metric when the cost of a false positive is very high.\n",
        "\n",
        "$$\n",
        "\\text{Precision}\n",
        "=\n",
        "\\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "3. Recall: <br>\n",
        "Recall metric measures the ratio of truly positive cases identified by the model correctly to the total positive cases present. This metric is useful when the cost of missing a positive case (i.e. a false negative) is very high.\n",
        "\n",
        "$$\n",
        "\\text{Recall}\n",
        "=\n",
        "\\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "4. F1 score: <br>\n",
        "It is the harmonic mean of the precision and recall. In this way, this metric considers both precision and recall. Since, harmonic mean is sensitive to low values, if either precision or recall is low, F1 score becomes low. This metric is useful when we don't just want to minimise either FP or FN, but we want to balance both.\n",
        "\n",
        "$$\n",
        "\\text{F1 score}\n",
        "=\n",
        "2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}\n",
        "{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "For the given data, <br>\n",
        "TP = 80<BR>\n",
        "TN = 820<BR>\n",
        "FP = 80<BR>\n",
        "FN = 20<BR>\n",
        "\n",
        "1. Accuracy = (80+820)/(80+820+80+20) = 900/1000 = 0.9 -> 90%\n",
        "2. Precision = 80/(80+80) = 80/160 = 0.5 -> 50%\n",
        "3. Recall = 80/(80+20) = 80/100 = 0.8 -> 80%\n",
        "4. F1 score = 2\\*(0.5*0.8)/(0.5+0.8) = 0.8/1.3 = 0.615 -> 61.5%\n"
      ],
      "metadata": {
        "id": "l3A7dOUcAAlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is a confusion matrix ?"
      ],
      "metadata": {
        "id": "h1dJMD0vJKZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "A Confusion matrix is a table which gives the summary of the performance of a classification model. It helps us to visualize the predicted outcomes and actual outcomes. In this table, we mention 4 components, True classes on the x-axis and Predicted classes on the y-axis.\n",
        "\n",
        "It has 4 components : <br>\n",
        "TP (True Positives) -> Positive Cases classified correctly <br>\n",
        "TN (True Negatives) -> Negative Cases classified correctly <br>\n",
        "FP (False Positives) -> Negative Cases classified wrongly as Positive <Br>\n",
        "FN (False Negatives) -> Positive Cases classified wrongly as Negative <br>  \n",
        "\n"
      ],
      "metadata": {
        "id": "TnU2OCbGGGYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is overfitting and underfitting ?"
      ],
      "metadata": {
        "id": "aOqF8Dzw0DdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Overfitting is a situation in which our model has a very high train accuracy but low test accuracy. This may occur because our dataset might be very small.\n",
        "\n",
        "On the other hand, in the case of underfitting, our model has both low train accuracy and low test accuracy. This may occur because the function we are using is pretty basic, so it is not able to recognise the complex features in the date or because we might have stopped the training process halfway through.\n",
        "\n",
        "In overfitting, the decision boundary is too accurate for the train dataset because of which the test accuracy decreases. And in underfitting, the decision boundary for the train dataset is very less accurate and pretty vague, which eventually reflects on the test accuracy."
      ],
      "metadata": {
        "id": "tu5Btz6MaoS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain vanishing and exploding gradients, give reasons why they occur and how they can be prevented.\n"
      ],
      "metadata": {
        "id": "n4KfKc0z0ulm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Vanishing gradients and exploding gradients are two problems which occur during the backpropagation step when we train deep learning neural networks.\n",
        "\n",
        "Vanishing Gradients: <br>\n",
        "When gradients are propagated backward through many layers, they become very small. As a result of this, the earlier layers learn very slowly or even stop learning because the gradients are now so small. The main reasons for this are repeated multiplication with small numbers especially when we use activation functions like the sigmoid function, and also when the weights are too small.\n",
        "\n",
        "Exploding Gradients: <br>\n",
        "This occurs when gradients become very large while propagating backwards, and thus cause unstable training and very large update steps. This is caused when we repeatedly multiply large numbers or large weights.\n",
        "\n",
        "Prevention: <br>\n",
        "To prevent these problems, we can use the ReLU activation function instead of activation functions like sigmoid and tanh, initialise the weights properly so that they are not too large or too small, add normalization layers in the network, and use LSTM/GRU architectures instead of vanilla RNN."
      ],
      "metadata": {
        "id": "jGNLkWiCHyqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is regularization ? Explain L1 and L2 regularization"
      ],
      "metadata": {
        "id": "6yaOipvU1JoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "The technique to nullify the effect of certain neurons in a neural network to solve the problem of overfitting is called regularization.\n",
        "In regularization, we add a penalty term to the cost function which forces the algorithm to reduce the value of some of the parameters to nearly 0, nullifying the effect of those related neurons.\n",
        "\n",
        "1. L1 regularization : <br>\n",
        "In L1 regularization, we add the sum of the absolute values of weights to the cost function.<br>\n",
        "This pushes some weights exactly to 0 value.\n",
        "$$\n",
        "Cost = \\frac{1}{2m}\\sum_{i=1}^{m}\n",
        "(Loss)\n",
        "+ \\lambda \\sum_{j=1}^{n} |w_j|\n",
        "$$\n",
        "\n",
        "\n",
        "2. L2 regularization : <br>\n",
        "In L2 regularization, we add the sum of the squared weights to the cost function.\n",
        "This reduces the value of some weights to near 0 but not exactly 0.\n",
        "$$\n",
        "Cost = \\frac{1}{2m}\\sum_{i=1}^{m}\n",
        "(Loss)\n",
        "+ \\lambda \\sum_{j=1}^{n} |w_j|^2\n",
        "$$"
      ],
      "metadata": {
        "id": "Ta1ccPdDeeqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is Dropout Layer and To which part of a neural network is dropout generally applied? how does it prevent overfitting"
      ],
      "metadata": {
        "id": "NjeRGpCE7QJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Dropout layer is a regularization technique used in neural networks to solve the problem of overfitting.\n",
        "\n",
        "When we train our model, dropout randomly drops some fraction of neurons in a layer meaning they don't participate in the forward or backward propagation for that training step.\n",
        "\n",
        "Dropout layer is generally applied to hidden layers and is not applied to the output layer.\n",
        "\n",
        "Dropout prevents overfitting by not letting the model become too dependent on specific neurons. Since, the dropout layer drops different neurons in each iteration, model is able to learn various features from the data rather than memorising the training data.\n",
        "While training our neural network, some of the neurons might develop and hold certain patterns in them, and then to emphasize these patterns, it might increase the value of the weights associated with those neurons. Due to this, our network will be able to strongly recognize those patterns but might fail to recognize other patterns and lead to high overfitting. When we drop some neurons randomly, our network will distribute evenly among all weights, so now the output neuron cannot rely on some specific neurons to pass the info but it will have to distribute the weight among all the neurons. This spreading will reduce the value of the W's and thus reduce overfitting.   \n"
      ],
      "metadata": {
        "id": "Z9_-DvXPdGmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. A hidden layer of a neural network has the following activations:\n",
        "\n",
        "   \\[\n",
        "   a = [2.0, 5.0, 7.12, 4.5, 6.0]\n",
        "   \\]\n",
        "\n",
        "   Dropout is applied **during training** with dropout probability \\(p = 0.5\\).\n",
        "\n",
        "   A randomly generated dropout mask is:\n",
        "\n",
        "   \\[\n",
        "   m = [1, 0, 0, 1, 1]\n",
        "   \\]\n",
        "\n",
        "   Here,  \n",
        "   - `1` → neuron is **kept**  \n",
        "   - `0` → neuron is **dropped**\n",
        "\n",
        "   ---\n",
        "\n",
        "   **Question:**  \n",
        "   What will be the output activations of this layer **after applying dropout**?\n",
        "   *(Show the final activation vector)*\n"
      ],
      "metadata": {
        "id": "jLZFLyv4-A67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Given,\n",
        "a = [2.0, 5.0, 7.12, 4.5, 6.0]...... (activations)\n",
        "m = [1, 0, 0, 1, 1]...... (dropout mask)\n",
        "p = 0.5 ......(dropout probability)\n",
        "\n",
        "Applying the dropout mask on the activations ->\n",
        "Multiplying each activation with the corresponding dropout mask value\n",
        "we get, [2.0, 0, 0, 4.5, 6.0]\n",
        "\n",
        "since, dropout probability = 0.5\n",
        "=> keep probability = 1-0.5 = 0.5\n",
        "\n",
        "after applying the mask, we also scale the kept activation vector by the inverse of keep probability i.e. 1/0.5 = 2\n",
        "\n",
        "so, we multiply the kept activation vector by 2\n",
        "\n",
        "final activation vector = [4.0, 0, 0, 9.0, 12.0]"
      ],
      "metadata": {
        "id": "rBnJc1Pli2xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "La3K0HmUGj8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent mainly differ in how much data they use to calculate the gradient at each update step.\n",
        "\n",
        "Gradient Descent: <br>\n",
        "It uses the entire dataset to calculate the gradient when updating the model parameters. Although this gives a smooth path towards the minimum but it is very slow and requires a lot of memory because it is using the entire dataset everytime it computes the gradient, and this problem is even more amplified for large datasets.\n",
        "\n",
        "Stochastic Gradient Descent: <br>\n",
        "It calculates the gradient using only one training example at a time. This makes the learning part very fast and helps the model improve quickly. The problem in this is that the updates can be very far apart because of which the loss may fluctuate a lot and not decrease smoothly.\n",
        "\n",
        "Mini-Batch Gradient Descent: <br>\n",
        "It uses a small batch of data examples for each step in which it calculates the gradient and then updates the parameters. Its benefits are that it is faster than Gradient Descent and more stable than Stochastic Gradient Descent and hence it is most commonly used.\n"
      ],
      "metadata": {
        "id": "FolUdj4dkz6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are optimizers ? Explain Adam, RMS prop and Momentum in detail"
      ],
      "metadata": {
        "id": "FngV9WtV7JxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "Optimizers are algorithms which speed up the training of a model while implementing mini-batch gradient descent or stochastic gradient descent. Basically, if we observe the contour plots of the cost function vs weights, it is clear that in gradient descent, the path is pretty straight and leads to the valley point but in case of mini-batch gradient descent or stochastic gradient descent, the path is very zig-zag and does not travel straight to the valley point but also goes in other directions. Using optimizers, we make this path less zig-zag and more straight. Hence, it makes training faster and more stable.\n",
        "\n",
        "Momentum: <br>\n",
        "This algorithm improves the gradient descent by adding a fraction of the previous update to the current one. This helps model to move in the correct direction and reduces oscillations in the valleys of the cost function surface.\n",
        "\n",
        "RMS prop: <br>\n",
        "It adapts learning rate for each update individually by keeping a moving average of squared gradients and divides the learning rate by this average. This prevents very large updates and works well when gradients change a lot.\n",
        "\n",
        "Adam: <br>\n",
        "Adam (Adaptive Moment Estimation) uses both concepts of Momentum and RMS prop together. It keeps track of moving average of the gradients and the moving average of the squared gradients. It automatically adjusts learning rates for each parameter.\n"
      ],
      "metadata": {
        "id": "sBqHtD-CospV"
      }
    }
  ]
}