{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SUBMISSION INSTRUCTIONS**\n",
        "\n",
        "First make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "**To write an answer to any question, First Add a TEXT block below the question and type it in only one single block**\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 19/12/2025 Friday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and **under Assignment 3**\n",
        "\n",
        "And remember to keep title of your pull request to be ViT_name_rollno_assgn3\n",
        "\n",
        "Github Submission repo -\n",
        "https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Assignment%203"
      ],
      "metadata": {
        "id": "XmTMSeaTLwVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THEORETICAL ASSIGNMENT**\n",
        "\n"
      ],
      "metadata": {
        "id": "-TjKxTBEz8i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment consists of theoretical questions. Objective answers will not be accepted. You need to write detailed answers (200-300 words) for the questions that require more in-depth explanations (you should be able to identify these after reading the question and finding about them). Questions that need less explanation can be answered in 20-100 words. Please ensure the answers are well-written and thorough."
      ],
      "metadata": {
        "id": "AnVa1_8AKqtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Assume that the inputs **X**\n",
        " to some scalar function **f**\n",
        " are **n x m**\n",
        " matrices. What is the dimensionality of the gradient of **f**\n",
        " with respect to **X**?\n",
        "**Give reasons to justify your answer.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ERhYz9qV_YXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensionality of gradient of f w.r.t. X will be as the dimensionality of X i.e. n*m.\n",
        "# Gradient of a Scalar Function with Matrix Input\n",
        "\n",
        "Assume that  \n",
        "$$\n",
        "f : \\mathbb{R}^{n \\times m} \\rightarrow \\mathbb{R}\n",
        "$$\n",
        "is a scalar-valued function whose input \\(X\\) is an \\(n \\times m\\) matrix.\n",
        "\n",
        "---\n",
        "\n",
        "## Dimensionality of the Gradient\n",
        "\n",
        "The gradient of \\(f\\) with respect to \\(X\\) has the **same dimensionality as \\(X\\)**.\n",
        "\n",
        "$$\n",
        "\\boxed{\\nabla_X f \\in \\mathbb{R}^{n \\times m}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## Justification\n",
        "\n",
        "The space of all \\(n \\times m\\) matrices, \\(\\mathbb{R}^{n \\times m}\\), is a finite-dimensional vector space of dimension \\(nm\\).\n",
        "\n",
        "The derivative of a scalar function with respect to its input is a **linear functional** acting on this space:\n",
        "$$\n",
        "Df(X) : \\mathbb{R}^{n \\times m} \\rightarrow \\mathbb{R}\n",
        "$$\n",
        "\n",
        "Since \\(\\mathbb{R}^{n \\times m}\\) is an inner-product space (with the Frobenius inner product), every linear functional can be uniquely represented as an inner product with a matrix of the same shape.\n",
        "\n",
        "$$\n",
        "Df(X)[H] = \\langle \\nabla_X f, H \\rangle\n",
        "= \\mathrm{tr}\\left((\\nabla_X f)^T H\\right)\n",
        "$$\n",
        "\n",
        "for all \\(H \\in \\mathbb{R}^{n \\times m}\\).\n",
        "\n",
        "---\n",
        "\n",
        "## Final Conclusion\n",
        "\n",
        "Because the derivative must act on all directions in \\(\\mathbb{R}^{n \\times m}\\), the gradient must lie in the same space as the input.\n",
        "\n",
        "$$\n",
        "\\boxed{\\text{Dimensionality of } \\nabla_X f = n \\times m}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "3-IfhlLR6WV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the evaluation metrics Accuracy, Precision, Recall, and F1 score.\n",
        "\n",
        "   Consider the following diagram:\n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score.\n",
        "   |                | Actual: Cancer | Actual: No Cancer |\n",
        "   |----------------|---------------|------------------|\n",
        "   | Predicted: Cancer | 80 | 80 |\n",
        "   | Predicted: No Cancer | 20 | 820 |\n",
        "    \n",
        "   \n",
        "   Find the values of Accuracy, Precision, Recall, and F1 score using the above data.\n"
      ],
      "metadata": {
        "id": "9vnyYHlq2g4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TP = 80\n",
        "\n",
        "FP = 80\n",
        "\n",
        "FN = 20\n",
        "\n",
        "TN = 820\n",
        "\n",
        "total=80+80+20+820=1000\n",
        "\n",
        "Accuracy=(true negative +true positive)/total =(820+80)/ 1000=.9=90%\n",
        "\n",
        "precision=(true positive)/(true positive+false positive)=80/(80+80)=.5=50%\n",
        "\n",
        "recall= (true positive)/(true positive+false negative)=80/(80+20)=.8=80%\n",
        "\n",
        "f12 score =(2X precision Xrecall)/(precision+recall)=2X.5X.8/(.5+.8)=.62=62%"
      ],
      "metadata": {
        "id": "tBMBXCJ37uBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is a confusion matrix ?"
      ],
      "metadata": {
        "id": "h1dJMD0vJKZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix is a tabular representation of the performance of a classification model, which compares actual class labels with predicted class labels.\n",
        "For a binary classification problem, a confusion matrix is a 2X2 matrix defined as:\n",
        "\n",
        "\t                   Actual Positive\t    Actual Negative\n",
        "Predicted Positive\t True Positive (TP)\tFalse Positive (FP)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Predicted Negative\tFalse Negative (FN)\tTrue Negative (TN)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Meaning of Each Term\n",
        "\n",
        "True Positive (TP):\n",
        "Model predicts positive and the actual class is positive.\n",
        "\n",
        "True Negative (TN):\n",
        "Model predicts negative and the actual class is negative.\n",
        "\n",
        "False Positive (FP):\n",
        "Model predicts positive but the actual class is negative\n",
        "\n",
        "\n",
        "False Negative (FN):\n",
        "Model predicts negative but the actual class is positive\n"
      ],
      "metadata": {
        "id": "VW0EDX6r-H0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is overfitting and underfitting ?"
      ],
      "metadata": {
        "id": "aOqF8Dzw0DdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**underfitting**\n",
        "\n",
        "Underfitting occurs when a model is too simple to capture the underlying pattern in the data.\n",
        "\n",
        "\n",
        "Characteristics\n",
        "\n",
        "\n",
        "*   Poor performance on training data\n",
        "*   Poor performance on test/validation data\n",
        "*  High bias, low variance\n",
        "\n",
        "Causes\n",
        "\n",
        "\n",
        "*   Model is too simple (e.g., linear model for nonlinear data)\n",
        "*   Insufficient features\n",
        "*   Excessive regularization\n",
        "*   Inadequate training (too few epochs)\n",
        "\n",
        "Example\n",
        "\n",
        "Fitting a straight line to data that clearly follows a curve.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**overfitting**\n",
        "\n",
        "Overfitting occurs when a model learns noise and random fluctuations in the training data instead of the true pattern.\n",
        "\n",
        "Characteristics\n",
        "\n",
        "\n",
        "*   Very high performance on training data\n",
        "*   Poor performance on test/validation data\n",
        "*   Low bias, high variance\n",
        "\n",
        "Causes\n",
        "\n",
        "* Model is too complex (too many parameters)\n",
        "\n",
        "* Too many training epochs\n",
        "\n",
        "* Small training dataset\n",
        "\n",
        "* Lack of regularization\n",
        "\n",
        "Example\n",
        "\n",
        "A high-degree polynomial fitting every training point exactly but failing on new data.\n"
      ],
      "metadata": {
        "id": "6iJVOs86_dBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain vanishing and exploding gradients, give reasons why they occur and how they can be prevented.\n"
      ],
      "metadata": {
        "id": "n4KfKc0z0ulm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vanishing gradient problem:**\n",
        "The vanishing gradient problem occurs when gradients become extremely small as they are propagated backward through a deep neural network during training. As a result, the weights of earlier layers update very slowly or stop updating, and the model fails to learn important patterns, especially long-range dependencies.\n",
        "\n",
        "Reasons:\n",
        "\n",
        "* Backpropagation uses the chain rule, which involves multiplying many derivatives. If these derivatives are less than 1, repeated multiplication causes gradients to shrink toward zero.\n",
        "\n",
        "* Saturating activation functions like sigmoid and tanh have derivatives less than 1.\n",
        "\n",
        "* Deep networks and long sequences in RNNs increase the number of multiplications.\n",
        "\n",
        "* Small weight initialization further reduces gradient magnitude.\n",
        "\n",
        "Prevention:\n",
        "\n",
        "* Use non-saturating activation functions such as ReLU, Leaky ReLU, or GELU.\n",
        "\n",
        "* Use proper weight initialization (Xavier/Glorot for tanh, He initialization for ReLU).\n",
        "\n",
        "* Apply batch normalization to keep activations in a stable range.\n",
        "\n",
        "* Use residual connections (skip connections).\n",
        "\n",
        "\n",
        "---\n",
        "**Exploding gradient problem:**\n",
        "The exploding gradient problem occurs when gradients grow very large during backpropagation, leading to unstable updates, divergence of loss, or numerical overflow.\n",
        "\n",
        "Reasons:\n",
        "\n",
        "* Repeated multiplication of derivatives greater than 1 during backpropagation.\n",
        "\n",
        "* Large initial weights.\n",
        "\n",
        "* Very deep networks or long RNN sequences.\n",
        "\n",
        "* High learning rates.\n",
        "\n",
        "Prevention:\n",
        "\n",
        "* Apply gradient clipping to limit the maximum gradient value.\n",
        "\n",
        "* Use smaller learning rates.\n",
        "\n",
        "* Use appropriate weight initialization.\n",
        "\n",
        "* Apply batch normalization.\n"
      ],
      "metadata": {
        "id": "PuC5m8bkAzPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is regularization ? Explain L1 and L2 regularization"
      ],
      "metadata": {
        "id": "6yaOipvU1JoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regularization**\n",
        "\n",
        "Regularization is a technique used in machine learning to reduce overfitting by discouraging overly complex models. It works by adding a penalty term to the original loss function, which restricts the magnitude of model parameters (weights). By controlling weight growth, regularization improves the model’s ability to generalize to unseen data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**L1 Regularization (Lasso) **\n",
        "\n",
        "L1 regularization adds a penalty equal to the sum of the absolute values of the model weights to the loss function.\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "Loss= Loss)original + λ.∑ |w)i|\n",
        "\n",
        "Key points:\n",
        "\n",
        "Encourages sparsity in the model.\n",
        "\n",
        "Many weights become exactly zero.\n",
        "\n",
        "Performs implicit feature selection.\n",
        "\n",
        "Useful when only a small number of features are relevant.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**L2 Regularization (Ridge)**\n",
        "\n",
        "L2 regularization adds a penalty equal to the sum of the squares of the model weights to the loss function.\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "Loss=Loss)original + λ.∑ (w)i)^2\n",
        "\n",
        "\n",
        "\n",
        "Key points:\n",
        "\n",
        "Encourages small but non-zero weights.\n",
        "\n",
        "Reduces model complexity smoothly.\n",
        "\n",
        "Improves numerical stability.\n",
        "\n",
        "Does not perform feature selection."
      ],
      "metadata": {
        "id": "4QC1DJoMHP1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is Dropout Layer and To which part of a neural network is dropout generally applied? how does it prevent overfitting"
      ],
      "metadata": {
        "id": "NjeRGpCE7QJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropout Layer**\n",
        "\n",
        "A dropout layer is a regularization technique used in neural networks to reduce overfitting. During training, it randomly deactivates (drops) a fraction of neurons by setting their outputs to zero. This prevents the network from becoming too dependent on any specific neuron.\n",
        "\n",
        "\n",
        "---\n",
        "Dropout is generally applied to:\n",
        "\n",
        "* Hidden layers of a neural network\n",
        "\n",
        "* Especially fully connected (dense) layers\n",
        "\n",
        "* It is usually not applied to:\n",
        "\n",
        "* The output layer\n",
        "\n",
        "* Input layer (except in some special cases)\n",
        "\n",
        "\n",
        "---\n",
        " Dropout Prevents Overfitting by-\n",
        "\n",
        "* Randomly dropping neurons forces the network to learn redundant and robust features.\n",
        "\n",
        "* Prevents co-adaptation of neurons, where neurons rely heavily on each other.\n",
        "\n",
        "* Each training iteration uses a different sub-network, which acts like training an ensemble of many smaller networks.\n",
        "\n",
        "* This increases model generalization and reduces variance.\n"
      ],
      "metadata": {
        "id": "-27kXyV0IhB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. A hidden layer of a neural network has the following activations:\n",
        "\n",
        "   \\[\n",
        "   a = [2.0, 5.0, 7.12, 4.5, 6.0]\n",
        "   \\]\n",
        "\n",
        "   Dropout is applied **during training** with dropout probability \\(p = 0.5\\).\n",
        "\n",
        "   A randomly generated dropout mask is:\n",
        "\n",
        "   \\[\n",
        "   m = [1, 0, 0, 1, 1]\n",
        "   \\]\n",
        "\n",
        "   Here,  \n",
        "   - `1` → neuron is **kept**  \n",
        "   - `0` → neuron is **dropped**\n",
        "\n",
        "   ---\n",
        "\n",
        "   **Question:**  \n",
        "   What will be the output activations of this layer **after applying dropout**?\n",
        "   *(Show the final activation vector)*\n"
      ],
      "metadata": {
        "id": "jLZFLyv4-A67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ans:-\n",
        "\n",
        "Activations\n",
        "\n",
        "a=[2.0,5.0,7.12,4.5,6.0]\n",
        "\n",
        "Dropout mask\n",
        "\n",
        "m=[1,0,0,1,1]\n",
        "\n",
        "Dropout is applied by element-wise multiplication of activations with the mask.\n",
        "\n",
        "(a)dropout\n",
        "\t​\n",
        "=a .dot product .m\n",
        "\n",
        "\n",
        "=[2.0×1,5.0×0,7.12×0,4.5×1,6.0×1]\n",
        "\n",
        "=[2.0,0,0,4.5,6.0] is the output after applying dropout"
      ],
      "metadata": {
        "id": "hw13FoUmJkfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Explain the difference between Gradient Descent, Stochastic Gradient Descent, Mini-Batch Gradient Descent"
      ],
      "metadata": {
        "id": "La3K0HmUGj8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Gradient Descent (Batch Gradient Descent)\n",
        "\n",
        "Gradient Descent computes the gradient of the loss function using the entire training dataset for each parameter update.\n",
        "\n",
        "Update rule:\n",
        "\n",
        "\n",
        "θ=θ−η∇\n",
        "J(θ)\n",
        "\n",
        "div is  w.r.t. theta\n",
        "\n",
        "Key points:\n",
        "\n",
        "* Uses all training samples for every update.\n",
        "\n",
        "* Convergence is smooth and stable.\n",
        "\n",
        "* Computationally expensive for large datasets.\n",
        "\n",
        "* Requires high memory.\n",
        "\n",
        "* Rarely used for very large datasets.\n",
        "\n",
        "2. Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Stochastic Gradient Descent updates the parameters using the gradient from only one training example at a time.\n",
        "\n",
        "Update rule:\n",
        "\n",
        "\n",
        "θ=θ−η∇\n",
        "J(θ;x\n",
        "(i)\n",
        ",y\n",
        "(i)\n",
        ")\n",
        "\n",
        "div is w.r.t. theta.\n",
        "\n",
        "Key points:\n",
        "\n",
        "* Very fast updates with low memory usage.\n",
        "\n",
        "* Loss function fluctuates due to noisy updates.\n",
        "\n",
        "* Can escape local minima.\n",
        "\n",
        "* Suitable for large-scale and online learning.\n",
        "\n",
        "3. Mini-Batch Gradient Descent\n",
        "\n",
        "Mini-batch Gradient Descent updates parameters using a small subset (batch) of the training data.\n",
        "\n",
        "Update rule:\n",
        "\n",
        "\n",
        "θ=θ−η∇\n",
        "J(θ;mini-batch)\n",
        "\n",
        "div is w.r.t.  theta .\n",
        "\n",
        "Key points:\n",
        "\n",
        "* Balances stability and speed.\n",
        "\n",
        "* Less noisy than SGD.\n",
        "\n",
        "* Faster than batch gradient descent.\n",
        "\n",
        "* Efficient on GPUs.\n",
        "\n",
        "* Most commonly used in deep learning."
      ],
      "metadata": {
        "id": "u1y4LQemapRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are optimizers ? Explain Adam, RMS prop and Momentum in detail"
      ],
      "metadata": {
        "id": "FngV9WtV7JxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizers in Neural Networks\n",
        "\n",
        "Optimizers are algorithms used to update the parameters (weights and biases) of a neural network in order to minimize the loss function. They determine how the gradients computed during backpropagation are used to adjust the model parameters efficiently.\n",
        "\n",
        "---\n",
        "\n",
        "## Momentum Optimizer\n",
        "\n",
        "The momentum optimizer accelerates gradient descent by accumulating an exponentially weighted average of past gradients, called velocity. This helps reduce oscillations and speeds up convergence.\n",
        "\n",
        "**Update equations:**\n",
        "\n",
        "$$\n",
        "v_t = \\beta v_{t-1} + (1-\\beta)\\nabla_\\theta J(\\theta)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\theta = \\theta - \\eta v_t\n",
        "$$\n",
        "\n",
        "where  \n",
        "- $\\beta$ is the momentum coefficient (typically 0.9)  \n",
        "- $\\eta$ is the learning rate  \n",
        "\n",
        "**Key points:**\n",
        "- Faster convergence  \n",
        "- Reduces oscillations  \n",
        "- Effective in narrow valleys of the loss surface  \n",
        "\n",
        "---\n",
        "\n",
        "## RMSProp\n",
        "\n",
        "RMSProp (Root Mean Square Propagation) adapts the learning rate for each parameter by dividing the gradient by a running average of squared gradients. This stabilizes training and prevents very large updates.\n",
        "\n",
        "**Update equations:**\n",
        "\n",
        "$$\n",
        "s_t = \\beta s_{t-1} + (1-\\beta)(\\nabla_\\theta J(\\theta))^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\theta = \\theta - \\frac{\\eta}{\\sqrt{s_t} + \\epsilon}\\nabla_\\theta J(\\theta)\n",
        "$$\n",
        "\n",
        "where  \n",
        "- $s_t$ is the running average of squared gradients  \n",
        "- $\\epsilon$ is a small constant for numerical stability  \n",
        "\n",
        "**Key points:**\n",
        "- Uses adaptive learning rates  \n",
        "- Prevents exploding gradients  \n",
        "- Suitable for non-stationary problems  \n",
        "\n",
        "---\n",
        "\n",
        "## Adam Optimizer\n",
        "\n",
        "Adam (Adaptive Moment Estimation) combines the advantages of Momentum and RMSProp by maintaining both the first moment (mean) and second moment (variance) of the gradients.\n",
        "\n",
        "**Update equations:**\n",
        "\n",
        "$$\n",
        "m_t = \\beta_1 m_{t-1} + (1-\\beta_1)\\nabla_\\theta J(\\theta)\n",
        "$$\n",
        "\n",
        "$$\n",
        "v_t = \\beta_2 v_{t-1} + (1-\\beta_2)(\\nabla_\\theta J(\\theta))^2\n",
        "$$\n",
        "\n",
        "**Bias-corrected estimates:**\n",
        "\n",
        "$$\n",
        "\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}, \\quad\n",
        "\\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}\n",
        "$$\n",
        "\n",
        "**Final parameter update:**\n",
        "\n",
        "$$\n",
        "\\theta = \\theta - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon}\\hat{m}_t\n",
        "$$\n",
        "\n",
        "Typical values:  \n",
        "- $\\beta_1 = 0.9$  \n",
        "- $\\beta_2 = 0.999$  \n",
        "- $\\epsilon = 10^{-8}$  \n",
        "\n",
        "**Key points:**\n",
        "- Combines momentum and adaptive learning rates  \n",
        "- Fast convergence  \n",
        "- Works well with sparse gradients  \n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "- **Momentum** speeds up gradient descent using past gradients  \n",
        "- **RMSProp** adapts learning rates to stabilize training  \n",
        "- **Adam** combines Momentum and RMSProp for fast and robust optimization\n"
      ],
      "metadata": {
        "id": "J_rvcODNb71b"
      }
    }
  ]
}