{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SUBMISSION INSTRUCTIONS\n",
        "\n",
        "It is recommended that you make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 18/12/2025 Thursday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and under Week1\n",
        "\n",
        "when submitting your pull request on the submission repo keep title as ViT_name_rollno_assgn2\n",
        "\n",
        "Github Submission repo - https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Week1\n"
      ],
      "metadata": {
        "id": "6UgUdG-lKTZk"
      },
      "id": "6UgUdG-lKTZk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NOTE:\n",
        "Do not use any pre-built functions from any new libraries apart from numpy, matplot-lib, pandas except for importing datasets."
      ],
      "metadata": {
        "id": "27cU1xGjF6mm"
      },
      "id": "27cU1xGjF6mm"
    },
    {
      "cell_type": "markdown",
      "id": "bored-updating",
      "metadata": {
        "id": "bored-updating"
      },
      "source": [
        "#### Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8gATfPCgKVlV"
      },
      "id": "8gATfPCgKVlV"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "prime-observer",
      "metadata": {
        "id": "prime-observer"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "81YcAGXOK2x8"
      },
      "id": "81YcAGXOK2x8"
    },
    {
      "cell_type": "markdown",
      "id": "primary-craps",
      "metadata": {
        "id": "primary-craps"
      },
      "source": [
        "# Importing Datasets\n",
        "\n",
        "Import the MNIST dataset and create X_train, Y_train, and X_test, Y_test.\n",
        "\n",
        "After importing the dataset you can resize it such that you are dealing with only 1000 images of each number.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading full MNIST data\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train_full, Y_train_full), (X_test_full, Y_test_full) = mnist.load_data()\n",
        "\n",
        "# since we want only 1000 images per digit\n",
        "def resize_dataset(X,Y,samples_per_digit=1000):\n",
        "  X_resized = []\n",
        "  Y_resized = []\n",
        "\n",
        "  for digit in range(10):\n",
        "    indices = np.where(Y==digit)[0] # indices where label equals the digit\n",
        "\n",
        "    count = min(len(indices), samples_per_digit)\n",
        "    selected_indices = indices[:count]\n",
        "\n",
        "    X_resized.append(X[selected_indices])\n",
        "    Y_resized.append(Y[selected_indices])\n",
        "\n",
        "  X_final = np.concatenate(X_resized, axis=0)\n",
        "  Y_final = np.concatenate(Y_resized, axis=0)\n",
        "\n",
        "  return X_final, Y_final\n",
        "\n",
        "X_train, Y_train = resize_dataset(X_train_full, Y_train_full, 1000)\n",
        "X_test, Y_test = resize_dataset(X_test_full, Y_test_full, 1000)\n",
        "\n",
        "print(f\"Final train size: {X_train.shape}\")\n",
        "print(f\"Final test size:{X_test.shape}\")"
      ],
      "metadata": {
        "id": "ou82GN8DFRwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6e633e-ae13-4982-c0b2-1944c84e36d5"
      },
      "id": "ou82GN8DFRwE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final train size: (10000, 28, 28)\n",
            "Final test size:(9786, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flattenning each 28x28 size image to a 784 dimension column vector and then taking transpose to (784, m)\n",
        "# and then normalising pixel values from [0,255] to [0,1]\n",
        "X_train = X_train.reshape(X_train.shape[0], -1).T / 255.0\n",
        "X_test  = X_test.reshape(X_test.shape[0], -1).T / 255.0\n",
        "\n",
        "print(\"X_train shape after reshaping:\", X_train.shape)\n",
        "print(\"X_test shape after reshaping:\", X_test.shape)\n",
        "\n",
        "# One hot encoding labels to shape (10, m)\n",
        "def one_hot_encode(y, num_classes=10):\n",
        "    y = y.astype(int)\n",
        "    one_hot = np.zeros((num_classes, y.shape[0]))\n",
        "    one_hot[y, np.arange(y.shape[0])] = 1\n",
        "    return one_hot\n",
        "\n",
        "Y_train = one_hot_encode(Y_train, 10)\n",
        "Y_test  = one_hot_encode(Y_test, 10)\n",
        "\n",
        "print(\"Y_train shape after one hot encoding:\", Y_train.shape)\n",
        "print(\"Y_test shape after one hot encoding:\", Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftRBWY7uMesw",
        "outputId": "cd155dcc-c60e-4d18-b28f-ed3fe9131588"
      },
      "id": "ftRBWY7uMesw",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape after reshaping: (784, 10000)\n",
            "X_test shape after reshaping: (784, 9786)\n",
            "Y_train shape after one hot encoding: (10, 10000)\n",
            "Y_test shape after one hot encoding: (10, 9786)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conservative-graphic",
      "metadata": {
        "id": "conservative-graphic"
      },
      "source": [
        "# Model\n",
        "\n",
        "\n",
        "## Initialize parameters Randomly\n",
        "$ W_1 = np.random.randn(n_1, n_0) $\n",
        "\n",
        "$ b_1 = np.zeros((n_1, 1))$\n",
        "\n",
        "$ W_2 = np.random.randn(n_2, n_1) $\n",
        "\n",
        "$ b_2 = np.zeros((n_2, 1))$\n",
        "\n",
        "\n",
        "## Repeat Below Steps for many times :\n",
        "\n",
        "\n",
        "## Forward Propagation\n",
        "\n",
        "$ Z_1 = W_1 * X + B_1 $\n",
        "\n",
        "$ A_1 = f ( Z_1 ) $  \n",
        "\n",
        "$ Z_2 = W2 * A_1 + B_2 $\n",
        "\n",
        "$ A_2 = Softmax( Z_2 ) $\n",
        "\n",
        "## Softmax\n",
        "\n",
        "$ a_i = \\frac{e^{z_i}}{\\sum_{i=k}^ne^{z_k}}$\n",
        "\n",
        "\n",
        "## Cost Function\n",
        "\n",
        "$Loss = - \\sum_{i=k}^{n}[ y_k*log(a_k) ]$\n",
        "\n",
        "$Cost = - \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{n}[ y_k*log(a_k) ]$\n",
        "\n",
        "\n",
        "\n",
        "## Backward Propagation\n",
        "$dZ_2 = ( A_2 - Y )$\n",
        "\n",
        "$ dW_2 = \\frac{1}{m}. dZ_2 . A_1^T$\n",
        "\n",
        "$ dB_2 = \\frac{1}{m}.sum(dZ_2, 1)$\n",
        "\n",
        "\n",
        "\n",
        "$dZ_1 = W_2^T . dZ_2 * f_1^|(Z_1) $\n",
        "\n",
        "$dW_1 = \\frac{1}{m}.dZ_1.X^T$\n",
        "\n",
        "$dB_1 = \\frac{1}{m}.sum(dZ_1, 1)$\n",
        "\n",
        "\n",
        "## Updating Parameters\n",
        "\n",
        "$ W_2 = W_2 -  \\alpha * \\frac{\\partial Cost }{\\partial W_2}$\n",
        "\n",
        "$ B_2 = B_2 -  \\alpha * \\frac{\\partial Cost }{\\partial B_2}$\n",
        "\n",
        "$ W_1 = W_1 -  \\alpha * \\frac{\\partial Cost }{\\partial W_1}$\n",
        "\n",
        "$ B_1 = B_1 -  \\alpha * \\frac{\\partial Cost }{\\partial B_1}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "private-seven",
      "metadata": {
        "id": "private-seven"
      },
      "source": [
        "# Activation Functions\n",
        "\n",
        "***Now, its your time to implement !***\n",
        "\n",
        "Complete the below functions for Activations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "better-winning",
      "metadata": {
        "id": "better-winning"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "    ## Your Code Here ##\n",
        "\n",
        "    return np.tanh(x)\n",
        "\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "immune-wright",
      "metadata": {
        "id": "immune-wright"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    ## Your Code Here ##\n",
        "\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "several-roommate",
      "metadata": {
        "id": "several-roommate"
      },
      "outputs": [],
      "source": [
        "def softmax(z):\n",
        "    ## Your Code Here ##\n",
        "\n",
        "    # subtracting maximum value for stability\n",
        "    z_new = z - np.max(z, axis=0, keepdims=True)\n",
        "    exp_z = np.exp(z_new)\n",
        "    sum_exp = np.sum(exp_z, axis=0, keepdims=True)\n",
        "    return exp_z / sum_exp\n",
        "\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "smart-gambling",
      "metadata": {
        "id": "smart-gambling"
      },
      "source": [
        "The function *derivative_tanh* must return the derivative of tanh.\n",
        "The function *derivative_relu* must return the derivative of ReLU\n",
        "\n",
        "\n",
        "derivative of tanh is given by 1 - tanh^2(x).\n",
        "\n",
        "\n",
        "so, derivative_tanh(x):\n",
        "\n",
        "return 1 - np.power(np.tanh(x), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "german-stake",
      "metadata": {
        "id": "german-stake"
      },
      "outputs": [],
      "source": [
        "def derivative_tanh(x):\n",
        "    ## Your Code Here ##\n",
        "\n",
        "    return 1 - np.power(np.tanh(x), 2)\n",
        "\n",
        "    ## Code Ends ##\n",
        "\n",
        "\n",
        "def derivative_relu(x):\n",
        "    ## Your Code Here ##\n",
        "\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forward-heading",
      "metadata": {
        "id": "forward-heading"
      },
      "source": [
        "# Initialize Parameters\n",
        "\n",
        "We need to initialize the **W** parameters randomly, and **B** with zeros\n",
        "\n",
        "- np.random.randn(a, b) return a numpy array of shape(a, b) with small random values\n",
        "- For making the values small, we multiply 0.01\n",
        "- np.zeros(a, b) return a numpy array of shape(a, b) with zeros\n",
        "\n",
        "### Why need small weights W?\n",
        "If we initialize weights will large values, then Z = W * X + B, will be large. For functions like tanh and sigmoid, the slope becomes very less for large Z value, thus learning can be very slow.\n",
        "\n",
        "#### We have an increase in the cost function at the beginning while training the model with ReLU activation function.\n",
        "It is because our weights were still very large and it was creating problem for training our model.\n",
        "\n",
        "Multiply weights with 0.001 instead of 0.01, and you will see that the graph becomes normal, with a smooth decrease in cost value.\n",
        "\n",
        "There are many weight initialization techniques available as well, to solve other such problems.\n",
        "\n",
        "Now, We need to return a dictionary containing all the parameters.\n",
        "\n",
        "More about np.random.randn here : https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "several-textbook",
      "metadata": {
        "id": "several-textbook"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "\n",
        "    ## Complete the code below ##\n",
        "\n",
        "    # n_x : size of input layer\n",
        "    # n_h : size of hidden layer\n",
        "    # n_y : size of output layer\n",
        "\n",
        "    w1 = np.random.randn(n_h, n_x) * 0.01\n",
        "    b1 = np.zeros((n_h, 1))\n",
        "    w2 = np.random.randn(n_y, n_h) * 0.01\n",
        "    b2 = np.zeros((n_y, 1))\n",
        "\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    parameters = {\n",
        "        \"w1\" : w1,\n",
        "        \"b1\" : b1,\n",
        "        \"w2\" : w2,\n",
        "        \"b2\" : b2\n",
        "    }\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "listed-sauce",
      "metadata": {
        "id": "listed-sauce"
      },
      "source": [
        "# Forward Propagation\n",
        "\n",
        "We need to impletement the following equation for forward propagation :\n",
        "\n",
        "$ Z_1 = W_1 * X + B_1 $\n",
        "\n",
        "$ A_1 = f ( Z_1 ) $  \n",
        "\n",
        "$ Z_2 = W2 * A_1 + B_2 $\n",
        "\n",
        "$ A_2 = Softmax( Z_2 ) $\n",
        "\n",
        "For f(x), you can use either tanh or ReLU activation function.\n",
        "\n",
        "But also use the same for Backpropagation as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "described-excess",
      "metadata": {
        "id": "described-excess"
      },
      "outputs": [],
      "source": [
        "def forward_prop(x, parameters):\n",
        "\n",
        "    # To fetch the parameters\n",
        "    w1 = parameters['w1']\n",
        "    b1 = parameters['b1']\n",
        "    w2 = parameters['w2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    ## Complete the Code below : ##\n",
        "    z1 = np.dot(w1, x) + b1\n",
        "    a1 = relu(z1)                      # taking f(x) to be relu function\n",
        "    z2 = np.dot(w2, a1) + b2\n",
        "    a2 = softmax(z2)\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    # To return our Zs and As\n",
        "    forward_cache = {\n",
        "        \"z1\" : z1,\n",
        "        \"a1\" : a1,\n",
        "        \"z2\" : z2,\n",
        "        \"a2\" : a2\n",
        "    }\n",
        "\n",
        "    return forward_cache"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sharp-tourist",
      "metadata": {
        "id": "sharp-tourist"
      },
      "source": [
        "# Cost Function\n",
        "\n",
        "$Loss = - \\sum_{k=1}^{n}[ y_k*log(a_k) ]$ .. *for 1 observation*\n",
        "\n",
        "$Cost = - \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{n}[ y_k*log(a_k) ]$  .. *for all m observations*\n",
        "\n",
        "You need to return the cost in the below function\n",
        "\n",
        "You can use np.sum()\n",
        "- np.sum(A, axis = 1, keepdims = True) return the column-wise sum for a matrix A\n",
        "- np.sum(A, axis = 0, keepdims = True) returns the row-wise sum for a matrix A\n",
        "- np.sum(A) returns the summation of all the elements of A\n",
        "\n",
        "*keepdims = True keeps the dimenstion in place. In certain cases, the returned sum can be of shape(m,) instead of shape(m, 1).\n",
        "So, keepdims = True forces it to return the sum in shape(m, 1) instead of shape(m,)*\n",
        "\n",
        "\n",
        "More about np.sum() here : https://numpy.org/doc/stable/reference/generated/numpy.sum.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "conservative-straight",
      "metadata": {
        "id": "conservative-straight"
      },
      "outputs": [],
      "source": [
        "def cost_function(a2, y):\n",
        "\n",
        "    ## Your Code Here ##\n",
        "\n",
        "    m = a2.shape[1]                             # m is number of training examples\n",
        "    cost = -1/m * np.sum(y * np.log(a2))\n",
        "    return cost\n",
        "\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "configured-draft",
      "metadata": {
        "id": "configured-draft"
      },
      "source": [
        "# Backward Propagation\n",
        "\n",
        "We need to implement the below equations\n",
        "\n",
        "$dZ_2 = ( A_2 - Y )$\n",
        "\n",
        "$ dW_2 = \\frac{1}{m}. dZ_2 . A_2^T$\n",
        "\n",
        "$ dB_2 = \\frac{1}{m}.sum(dZ_2, 1)$\n",
        "\n",
        "\n",
        "\n",
        "$dZ_1 = W_2^T . dZ_2 * f_1^|(Z_1) $\n",
        "\n",
        "$dW_1 = \\frac{1}{m}.dZ_1.A_1^T$\n",
        "\n",
        "$dB_1 = \\frac{1}{m}.sum(dZ_1, 1)$\n",
        "\n",
        "Helper python functions :\n",
        "- A.T returns the transpose of matrix A\n",
        "- np.dot(A, B) returns the matrix multiplication of A and B\n",
        "- A*B returns the element wise multi-plication for A and B\n",
        "- np.sum(A, axis = 1, keepdims = True) return the column-wise sum for a matrix A\n",
        "- np.sum(A, axis = 0, keepdims = True) returns the row-wise sum for a matrix A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "regulation-internship",
      "metadata": {
        "id": "regulation-internship"
      },
      "outputs": [],
      "source": [
        "def backward_prop(x, y, parameters, forward_cache):\n",
        "\n",
        "    m = x.shape[1]\n",
        "\n",
        "    # Fetching our parameters\n",
        "    w1 = parameters['w1']\n",
        "    b1 = parameters['b1']\n",
        "    w2 = parameters['w2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    # Fetching our forward_cache\n",
        "    a1 = forward_cache['a1']\n",
        "    a2 = forward_cache['a2']\n",
        "\n",
        "\n",
        "    ## Complete the Code below ##\n",
        "\n",
        "    dz2 = a2 - y\n",
        "    dw2 = 1/m * np.dot(dz2, a1.T)\n",
        "    db2 = 1/m * np.sum(dz2, axis=1, keepdims=True)\n",
        "    dz1 = np.dot(w2.T, dz2) * derivative_relu(forward_cache['z1'])\n",
        "    dw1 = 1/m * np.dot(dz1, x.T)\n",
        "    db1 = 1/m * np.sum(dz1, axis=1, keepdims=True)\n",
        "\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    ## Returning the Gradients\n",
        "    gradients = {\n",
        "        \"dw1\" : dw1,\n",
        "        \"db1\" : db1,\n",
        "        \"dw2\" : dw2,\n",
        "        \"db2\" : db2\n",
        "    }\n",
        "\n",
        "    return gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "soviet-sentence",
      "metadata": {
        "id": "soviet-sentence"
      },
      "source": [
        "# Update Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "convertible-samba",
      "metadata": {
        "id": "convertible-samba"
      },
      "outputs": [],
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "\n",
        "    # Fetching our parameters\n",
        "    w1 = parameters['w1']\n",
        "    b1 = parameters['b1']\n",
        "    w2 = parameters['w2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    # Fetching our gradients\n",
        "    dw1 = gradients['dw1']\n",
        "    db1 = gradients['db1']\n",
        "    dw2 = gradients['dw2']\n",
        "    db2 = gradients['db2']\n",
        "\n",
        "    ## Complete the Code below ##\n",
        "\n",
        "    w1 = w1 - learning_rate * dw1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "    w2 = w2 - learning_rate * dw2\n",
        "    b2 = b2 - learning_rate * db2\n",
        "\n",
        "    ## Your code ends ##\n",
        "\n",
        "    # Returning the updated parameters\n",
        "    Parameters = {\n",
        "        \"w1\" : w1,\n",
        "        \"b1\" : b1,\n",
        "        \"w2\" : w2,\n",
        "        \"b2\" : b2\n",
        "    }\n",
        "\n",
        "    return Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sharing-effort",
      "metadata": {
        "id": "sharing-effort"
      },
      "source": [
        "# Complete Model\n",
        "\n",
        "Implement the entire Neural Network here\n",
        "\n",
        "### Instructions :\n",
        "\n",
        "We need to initialize parameters once, and after that, we will run the following in a loop:\n",
        "- forward_prop(x, parameters)\n",
        "- cost_function(a2, y)\n",
        "- backward_prop(x, y, parameters, forward_cache)\n",
        "- parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "\n",
        "### Return :\n",
        "- parameters, which will be our trained parameters\n",
        "- cost_list, which contains cost for every iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "powerful-sailing",
      "metadata": {
        "id": "powerful-sailing"
      },
      "outputs": [],
      "source": [
        "def model(x, y, n_h, learning_rate, iterations):\n",
        "\n",
        "    ## Complete the Code Below ##\n",
        "\n",
        "    n_x = x.shape[0]                       # number of neurons in input layer\n",
        "    n_y = y.shape[0]                       # number of neurons in output layer\n",
        "\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    cost_list = []\n",
        "\n",
        "    ## Complete the Code Below ##\n",
        "\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "\n",
        "    ## Your Code ends ##\n",
        "\n",
        "\n",
        "    ## Complete the Code Below ##\n",
        "    for i in range(iterations):\n",
        "\n",
        "        # Forward Propagation\n",
        "        forward_cache = forward_prop(x, parameters)\n",
        "\n",
        "        # Cost Function\n",
        "        cost = cost_function(forward_cache['a2'], y)\n",
        "\n",
        "        # Backward propagation\n",
        "        gradients = backward_prop(x, y, parameters, forward_cache)\n",
        "\n",
        "        # Update Parameters\n",
        "        parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "        cost_list.append(cost)\n",
        "\n",
        "        if i%(iterations/10) == 0 :\n",
        "            print(\"cost after\", i, \"iters is\" ,     cost   )\n",
        "\n",
        "    ## Your Code ends ##\n",
        "\n",
        "\n",
        "    return parameters, cost_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "democratic-williams",
      "metadata": {
        "id": "democratic-williams",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66d2bf1-c1ba-4b40-b055-c28902e94992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost after 0 iters is 2.3016257116863734\n",
            "cost after 200 iters is 0.3341002260342495\n",
            "cost after 400 iters is 0.25395747523839735\n",
            "cost after 600 iters is 0.21021231377184005\n",
            "cost after 800 iters is 0.1767246093814764\n",
            "cost after 1000 iters is 0.15003726388292868\n",
            "cost after 1200 iters is 0.1288739309336428\n",
            "cost after 1400 iters is 0.1116070685469912\n",
            "cost after 1600 iters is 0.09707316879593285\n",
            "cost after 1800 iters is 0.0847636929408597\n"
          ]
        }
      ],
      "source": [
        "## Complete the Code Below ##\n",
        "\n",
        "n_h = 100\n",
        "learning_rate = 0.2\n",
        "iterations = 2000\n",
        "\n",
        "## Your Code ends ##\n",
        "\n",
        "Parameters, Cost_list = model(X_train, Y_train, n_h = n_h, learning_rate = learning_rate, iterations = iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "permanent-music",
      "metadata": {
        "id": "permanent-music",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "c67ea5dc-de82-4305-d953-85e00ea3b29c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "t = np.arange(0, iterations)\n",
        "plt.plot(t, Cost_list)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "apparent-contribution",
      "metadata": {
        "id": "apparent-contribution"
      },
      "source": [
        "# Checking Accuracy\n",
        "\n",
        "Run the below cells to check your model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "alone-liver",
      "metadata": {
        "id": "alone-liver"
      },
      "outputs": [],
      "source": [
        "def accuracy(inp, labels, parameters):\n",
        "    forward_cache = forward_prop(inp, parameters)\n",
        "    a_out = forward_cache['a2']   # containes propabilities with shape(10, 1)\n",
        "\n",
        "    a_out = np.argmax(a_out, 0)  # 0 represents row wise\n",
        "\n",
        "    labels = np.argmax(labels, 0)\n",
        "\n",
        "    acc = np.mean(a_out == labels)*100\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "later-brake",
      "metadata": {
        "id": "later-brake",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c5c806-a81a-4844-888b-a691d21d6f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Train Dataset 98.34 %\n",
            "Accuracy of Test Dataset 93.92 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of Train Dataset\", accuracy(X_train, Y_train, Parameters), \"%\")\n",
        "print(\"Accuracy of Test Dataset\", round(accuracy(X_test, Y_test, Parameters), 2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "banned-clone",
      "metadata": {
        "id": "banned-clone",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "7225216d-65cc-4231-8764-ff895040b535"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our model says it is : 0\n"
          ]
        }
      ],
      "source": [
        "idx = int(random.randrange(0,X_test.shape[1]))\n",
        "plt.imshow(X_test[:, idx].reshape((28,28)),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "cache = forward_prop(X_test[:, idx].reshape(X_test[:, idx].shape[0], 1), Parameters)\n",
        "a_pred = cache['a2']\n",
        "a_pred = np.argmax(a_pred, 0)\n",
        "\n",
        "print(\"Our model says it is :\", a_pred[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}