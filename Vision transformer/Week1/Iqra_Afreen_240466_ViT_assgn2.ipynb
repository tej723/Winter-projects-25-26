{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SUBMISSION INSTRUCTIONS\n",
        "\n",
        "It is recommended that you make a copy of this colab file and then solve the assignment and upload your final notebook on github.\n",
        "\n",
        "Before uploading your downloaded notebook, RENAME the file as rollno_name.ipynb\n",
        "\n",
        "Submission Deadline : 18/12/2025 Thursday EOD i.e before 11:59 PM\n",
        "\n",
        "The deadline is strict and will not be extended, Late submissions are not allowed\n",
        "\n",
        "Note that you have to upload your solution on the github page of the project Vision Transformer and under Week1\n",
        "\n",
        "when submitting your pull request on the submission repo keep title as ViT_name_rollno_assgn2\n",
        "\n",
        "Github Submission repo - https://github.com/electricalengineersiitk/Winter-projects-25-26/tree/main/Vision%20transformer/Week1\n"
      ],
      "metadata": {
        "id": "6UgUdG-lKTZk"
      },
      "id": "6UgUdG-lKTZk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NOTE:\n",
        "Do not use any pre-built functions from any new libraries apart from numpy, matplot-lib, pandas except for importing datasets."
      ],
      "metadata": {
        "id": "27cU1xGjF6mm"
      },
      "id": "27cU1xGjF6mm"
    },
    {
      "cell_type": "markdown",
      "id": "bored-updating",
      "metadata": {
        "id": "bored-updating"
      },
      "source": [
        "#### Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8gATfPCgKVlV"
      },
      "id": "8gATfPCgKVlV"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "prime-observer",
      "metadata": {
        "id": "prime-observer"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "81YcAGXOK2x8"
      },
      "id": "81YcAGXOK2x8"
    },
    {
      "cell_type": "markdown",
      "id": "primary-craps",
      "metadata": {
        "id": "primary-craps"
      },
      "source": [
        "# Importing Datasets\n",
        "\n",
        "Import the MNIST dataset and create X_train, Y_train, and X_test, Y_test.\n",
        "\n",
        "After importing the dataset you can resize it such that you are dealing with only 1000 images of each number.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load raw data\n",
        "(train_bits, train_labs), (test_bits, test_labs) = mnist.load_data()\n",
        "\n",
        "def grab_subset(bits, labs, n=1000):\n",
        "    xs, ys = [], []\n",
        "    for i in range(10):\n",
        "        all_idx = np.where(labs == i)[0]\n",
        "        # Use min to safely grab whatever is available if less than n\n",
        "        idx = all_idx[:min(len(all_idx), n)]\n",
        "        xs.append(bits[idx])\n",
        "        ys.append(labs[idx])\n",
        "    # Use np.concatenate to join chunks of different sizes\n",
        "    return np.concatenate(xs), np.concatenate(ys)\n",
        "\n",
        "X_train, Y_train = grab_subset(train_bits, train_labs, 1000)\n",
        "X_test, Y_test = grab_subset(test_bits, test_labs, 1000)"
      ],
      "metadata": {
        "id": "ou82GN8DFRwE"
      },
      "id": "ou82GN8DFRwE",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "conservative-graphic",
      "metadata": {
        "id": "conservative-graphic"
      },
      "source": [
        "# Model\n",
        "\n",
        "\n",
        "## Initialize parameters Randomly\n",
        "$ W_1 = np.random.randn(n_1, n_0) $\n",
        "\n",
        "$ b_1 = np.zeros((n_1, 1))$\n",
        "\n",
        "$ W_2 = np.random.randn(n_2, n_1) $\n",
        "\n",
        "$ b_2 = np.zeros((n_2, 1))$\n",
        "\n",
        "\n",
        "## Repeat Below Steps for many times :\n",
        "\n",
        "\n",
        "## Forward Propagation\n",
        "\n",
        "$ Z_1 = W_1 * X + B_1 $\n",
        "\n",
        "$ A_1 = f ( Z_1 ) $  \n",
        "\n",
        "$ Z_2 = W2 * A_1 + B_2 $\n",
        "\n",
        "$ A_2 = Softmax( Z_2 ) $\n",
        "\n",
        "## Softmax\n",
        "\n",
        "$ a_i = \\frac{e^{z_i}}{\\sum_{i=k}^ne^{z_k}}$\n",
        "\n",
        "\n",
        "## Cost Function\n",
        "\n",
        "$Loss = - \\sum_{i=k}^{n}[ y_k*log(a_k) ]$\n",
        "\n",
        "$Cost = - \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{n}[ y_k*log(a_k) ]$\n",
        "\n",
        "\n",
        "\n",
        "## Backward Propagation\n",
        "$dZ_2 = ( A_2 - Y )$\n",
        "\n",
        "$ dW_2 = \\frac{1}{m}. dZ_2 . A_1^T$\n",
        "\n",
        "$ dB_2 = \\frac{1}{m}.sum(dZ_2, 1)$\n",
        "\n",
        "\n",
        "\n",
        "$dZ_1 = W_2^T . dZ_2 * f_1^|(Z_1) $\n",
        "\n",
        "$dW_1 = \\frac{1}{m}.dZ_1.X^T$\n",
        "\n",
        "$dB_1 = \\frac{1}{m}.sum(dZ_1, 1)$\n",
        "\n",
        "\n",
        "## Updating Parameters\n",
        "\n",
        "$ W_2 = W_2 -  \\alpha * \\frac{\\partial Cost }{\\partial W_2}$\n",
        "\n",
        "$ B_2 = B_2 -  \\alpha * \\frac{\\partial Cost }{\\partial B_2}$\n",
        "\n",
        "$ W_1 = W_1 -  \\alpha * \\frac{\\partial Cost }{\\partial W_1}$\n",
        "\n",
        "$ B_1 = B_1 -  \\alpha * \\frac{\\partial Cost }{\\partial B_1}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "private-seven",
      "metadata": {
        "id": "private-seven"
      },
      "source": [
        "# Activation Functions\n",
        "\n",
        "***Now, its your time to implement !***\n",
        "\n",
        "Complete the below functions for Activations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "better-winning",
      "metadata": {
        "id": "better-winning"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "    ## Your Code Here ##\n",
        "    return np.tanh(x)\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "immune-wright",
      "metadata": {
        "id": "immune-wright"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    ## Your Code Here ##\n",
        "    return np.maximum(0, x)\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "several-roommate",
      "metadata": {
        "id": "several-roommate"
      },
      "outputs": [],
      "source": [
        "def softmax(z):\n",
        "    ## Your Code Here ##\n",
        "    exp_z = np.exp(z - np.max(z))\n",
        "    return exp_z / np.sum(exp_z, axis=0)\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "smart-gambling",
      "metadata": {
        "id": "smart-gambling"
      },
      "source": [
        "The function *derivative_tanh* must return the derivative of tanh.\n",
        "The function *derivative_relu* must return the derivative of ReLU\n",
        "\n",
        "\n",
        "derivative of tanh is given by 1 - tanh^2(x).\n",
        "\n",
        "\n",
        "so, derivative_tanh(x):\n",
        "\n",
        "return 1 - np.power(np.tanh(x), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "german-stake",
      "metadata": {
        "id": "german-stake"
      },
      "outputs": [],
      "source": [
        "def derivative_tanh(x):\n",
        "    ## Your Code Here ##\n",
        "    return 1 - np.power(np.tanh(x), 2)\n",
        "    ## Code Ends ##\n",
        "\n",
        "def derivative_relu(x):\n",
        "    ## Your Code Here ##\n",
        "    return (x > 0).astype(float)\n",
        "    ## Code Ends ##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forward-heading",
      "metadata": {
        "id": "forward-heading"
      },
      "source": [
        "# Initialize Parameters\n",
        "\n",
        "We need to initialize the **W** parameters randomly, and **B** with zeros\n",
        "\n",
        "- np.random.randn(a, b) return a numpy array of shape(a, b) with small random values\n",
        "- For making the values small, we multiply 0.01\n",
        "- np.zeros(a, b) return a numpy array of shape(a, b) with zeros\n",
        "\n",
        "### Why need small weights W?\n",
        "If we initialize weights will large values, then Z = W * X + B, will be large. For functions like tanh and sigmoid, the slope becomes very less for large Z value, thus learning can be very slow.\n",
        "\n",
        "#### We have an increase in the cost function at the beginning while training the model with ReLU activation function.\n",
        "It is because our weights were still very large and it was creating problem for training our model.\n",
        "\n",
        "Multiply weights with 0.001 instead of 0.01, and you will see that the graph becomes normal, with a smooth decrease in cost value.\n",
        "\n",
        "There are many weight initialization techniques available as well, to solve other such problems.\n",
        "\n",
        "Now, We need to return a dictionary containing all the parameters.\n",
        "\n",
        "More about np.random.randn here : https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "several-textbook",
      "metadata": {
        "id": "several-textbook"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "\n",
        "    ## Complete the code below ##\n",
        "    w1 = np.random.randn(n_h, n_x) * 0.01\n",
        "    b1 = np.zeros((n_h, 1))\n",
        "    w2 = np.random.randn(n_y, n_h) * 0.01\n",
        "    b2 = np.zeros((n_y, 1))\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    parameters = {\n",
        "        \"w1\" : w1,\n",
        "        \"b1\" : b1,\n",
        "        \"w2\" : w2,\n",
        "        \"b2\" : b2\n",
        "    }\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "listed-sauce",
      "metadata": {
        "id": "listed-sauce"
      },
      "source": [
        "# Forward Propagation\n",
        "\n",
        "We need to impletement the following equation for forward propagation :\n",
        "\n",
        "$ Z_1 = W_1 * X + B_1 $\n",
        "\n",
        "$ A_1 = f ( Z_1 ) $  \n",
        "\n",
        "$ Z_2 = W2 * A_1 + B_2 $\n",
        "\n",
        "$ A_2 = Softmax( Z_2 ) $\n",
        "\n",
        "For f(x), you can use either tanh or ReLU activation function.\n",
        "\n",
        "But also use the same for Backpropagation as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "described-excess",
      "metadata": {
        "id": "described-excess"
      },
      "outputs": [],
      "source": [
        "def forward_prop(x, parameters):\n",
        "\n",
        "    # To fetch the parameters\n",
        "    w1 = parameters['w1']\n",
        "    b1 = parameters['b1']\n",
        "    w2 = parameters['w2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    ## Complete the Code below : ##\n",
        "    z1 = np.dot(w1, x) + b1\n",
        "    a1 = relu(z1)\n",
        "    z2 = np.dot(w2, a1) + b2\n",
        "    a2 = softmax(z2)\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    # To return our Zs and As\n",
        "    forward_cache = {\n",
        "        \"z1\" : z1,\n",
        "        \"a1\" : a1,\n",
        "        \"z2\" : z2,\n",
        "        \"a2\" : a2\n",
        "    }\n",
        "\n",
        "    return forward_cache"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sharp-tourist",
      "metadata": {
        "id": "sharp-tourist"
      },
      "source": [
        "# Cost Function\n",
        "\n",
        "$Loss = - \\sum_{k=1}^{n}[ y_k*log(a_k) ]$ .. *for 1 observation*\n",
        "\n",
        "$Cost = - \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{n}[ y_k*log(a_k) ]$  .. *for all m observations*\n",
        "\n",
        "You need to return the cost in the below function\n",
        "\n",
        "You can use np.sum()\n",
        "- np.sum(A, axis = 1, keepdims = True) return the column-wise sum for a matrix A\n",
        "- np.sum(A, axis = 0, keepdims = True) returns the row-wise sum for a matrix A\n",
        "- np.sum(A) returns the summation of all the elements of A\n",
        "\n",
        "*keepdims = True keeps the dimenstion in place. In certain cases, the returned sum can be of shape(m,) instead of shape(m, 1).\n",
        "So, keepdims = True forces it to return the sum in shape(m, 1) instead of shape(m,)*\n",
        "\n",
        "\n",
        "More about np.sum() here : https://numpy.org/doc/stable/reference/generated/numpy.sum.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "conservative-straight",
      "metadata": {
        "id": "conservative-straight"
      },
      "outputs": [],
      "source": [
        "def cost_function(a2, y):\n",
        "\n",
        "    ## Your Code Here ##\n",
        "    m = y.shape[1]\n",
        "    logprobs = np.multiply(y, np.log(a2 + 1e-8))\n",
        "    cost = - (1/m) * np.sum(logprobs)\n",
        "    ## Code Ends ##\n",
        "    cost = np.squeeze(cost) # Ensures cost is a scalar\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "configured-draft",
      "metadata": {
        "id": "configured-draft"
      },
      "source": [
        "# Backward Propagation\n",
        "\n",
        "We need to implement the below equations\n",
        "\n",
        "$dZ_2 = ( A_2 - Y )$\n",
        "\n",
        "$ dW_2 = \\frac{1}{m}. dZ_2 . A_2^T$\n",
        "\n",
        "$ dB_2 = \\frac{1}{m}.sum(dZ_2, 1)$\n",
        "\n",
        "\n",
        "\n",
        "$dZ_1 = W_2^T . dZ_2 * f_1^|(Z_1) $\n",
        "\n",
        "$dW_1 = \\frac{1}{m}.dZ_1.A_1^T$\n",
        "\n",
        "$dB_1 = \\frac{1}{m}.sum(dZ_1, 1)$\n",
        "\n",
        "Helper python functions :\n",
        "- A.T returns the transpose of matrix A\n",
        "- np.dot(A, B) returns the matrix multiplication of A and B\n",
        "- A*B returns the element wise multi-plication for A and B\n",
        "- np.sum(A, axis = 1, keepdims = True) return the column-wise sum for a matrix A\n",
        "- np.sum(A, axis = 0, keepdims = True) returns the row-wise sum for a matrix A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "regulation-internship",
      "metadata": {
        "id": "regulation-internship"
      },
      "outputs": [],
      "source": [
        "def backward_prop(x, y, parameters, forward_cache):\n",
        "    m = x.shape[1]\n",
        "\n",
        "    # Fetching our parameters\n",
        "    w1 = parameters['w1']\n",
        "    b1 = parameters['b1']\n",
        "    w2 = parameters['w2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    # Fetching our forward_cache\n",
        "    a1 = forward_cache['a1']\n",
        "    a2 = forward_cache['a2']\n",
        "    z1 = forward_cache['z1']\n",
        "\n",
        "    ## Complete the Code below ##\n",
        "    # Output Layer Gradients\n",
        "    # Inside backward_prop\n",
        "    dz2 = a2 - y\n",
        "    dw2 = (1/m) * np.dot(dz2, a1.T)\n",
        "    db2 = (1/m) * np.sum(dz2, axis=1, keepdims=True)\n",
        "    dz1 = np.dot(w2.T, dz2) * derivative_relu(z1)\n",
        "    dw1 = (1/m) * np.dot(dz1, x.T)\n",
        "    db1 = (1/m) * np.sum(dz1, axis=1, keepdims=True)\n",
        "    ## Your Code Ends ##\n",
        "\n",
        "    gradients = {\n",
        "        \"dw1\" : dw1,\n",
        "        \"db1\" : db1,\n",
        "        \"dw2\" : dw2,\n",
        "        \"db2\" : db2\n",
        "    }\n",
        "\n",
        "    return gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "soviet-sentence",
      "metadata": {
        "id": "soviet-sentence"
      },
      "source": [
        "# Update Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "convertible-samba",
      "metadata": {
        "id": "convertible-samba"
      },
      "outputs": [],
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "\n",
        "    # Fetching our parameters\n",
        "    w1 = parameters['w1']\n",
        "    b1 = parameters['b1']\n",
        "    w2 = parameters['w2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    # Fetching our gradients\n",
        "    dw1 = gradients['dw1']\n",
        "    db1 = gradients['db1']\n",
        "    dw2 = gradients['dw2']\n",
        "    db2 = gradients['db2']\n",
        "\n",
        "    ## Complete the Code below ##\n",
        "    w1 = w1 - learning_rate * dw1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "    w2 = w2 - learning_rate * dw2\n",
        "    b2 = b2 - learning_rate * db2\n",
        "    ## Your code ends ##\n",
        "\n",
        "    # Returning the updated parameters\n",
        "    Parameters = {\n",
        "        \"w1\" : w1,\n",
        "        \"b1\" : b1,\n",
        "        \"w2\" : w2,\n",
        "        \"b2\" : b2\n",
        "    }\n",
        "\n",
        "    return Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sharing-effort",
      "metadata": {
        "id": "sharing-effort"
      },
      "source": [
        "# Complete Model\n",
        "\n",
        "Implement the entire Neural Network here\n",
        "\n",
        "### Instructions :\n",
        "\n",
        "We need to initialize parameters once, and after that, we will run the following in a loop:\n",
        "- forward_prop(x, parameters)\n",
        "- cost_function(a2, y)\n",
        "- backward_prop(x, y, parameters, forward_cache)\n",
        "- parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "\n",
        "### Return :\n",
        "- parameters, which will be our trained parameters\n",
        "- cost_list, which contains cost for every iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "powerful-sailing",
      "metadata": {
        "id": "powerful-sailing"
      },
      "outputs": [],
      "source": [
        "def model(x, y, n_h, learning_rate, iterations):\n",
        "\n",
        "    ## Complete the Code Below ##\n",
        "    n_x = x.shape[0]                        # must return the number of neurons/features in input layer\n",
        "    n_y = y.shape[0]                       # must return the number of neurons in output layer\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    cost_list = []\n",
        "\n",
        "    ## Complete the Code Below ##\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    ## Your Code ends ##\n",
        "\n",
        "    for i in range(iterations):\n",
        "        # Forward Propagation\n",
        "        cache = forward_prop(x, parameters)\n",
        "\n",
        "        # Cost Function\n",
        "        cost = cost_function(cache['a2'], y)\n",
        "\n",
        "        # Backward propagation\n",
        "        grads = backward_prop(x, y, parameters, cache)\n",
        "\n",
        "        # Update Parameters\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        # Add current cost to the list\n",
        "        cost_list.append(cost)\n",
        "\n",
        "        if i % (iterations/10) == 0:\n",
        "            print(\"cost after\", i, \"iters is\", cost)\n",
        "\n",
        "    return parameters, cost_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "democratic-williams",
      "metadata": {
        "id": "democratic-williams",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb3c422-78ea-430a-ab60-96724816c760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost after 0 iters is 2.3022742922603263\n",
            "cost after 100 iters is 1.079092456421437\n",
            "cost after 200 iters is 0.5078062997866084\n",
            "cost after 300 iters is 0.38967658097916413\n",
            "cost after 400 iters is 0.3405335511531284\n",
            "cost after 500 iters is 0.31127272532323436\n",
            "cost after 600 iters is 0.290471176289073\n",
            "cost after 700 iters is 0.27409206575070216\n",
            "cost after 800 iters is 0.2604632532702767\n",
            "cost after 900 iters is 0.248532622137196\n"
          ]
        }
      ],
      "source": [
        "## Complete the Code Below ##\n",
        "\n",
        "n_h = 64\n",
        "learning_rate = 0.1\n",
        "iterations = 1000\n",
        "\n",
        "## Your Code ends ##\n",
        "\n",
        "Parameters, Cost_list = model(X_train_flat, Y_train_one_hot, n_h, learning_rate, iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "permanent-music",
      "metadata": {
        "id": "permanent-music",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "42e0fdf4-8ab0-487e-9901-69856b71b333"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "t = np.arange(0, len(Cost_list))\n",
        "plt.plot(t, Cost_list)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "apparent-contribution",
      "metadata": {
        "id": "apparent-contribution"
      },
      "source": [
        "# Checking Accuracy\n",
        "\n",
        "Run the below cells to check your model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "alone-liver",
      "metadata": {
        "id": "alone-liver"
      },
      "outputs": [],
      "source": [
        "def accuracy(inp, labels, parameters):\n",
        "    forward_cache = forward_prop(inp, parameters)\n",
        "    a_out = forward_cache['a2']   # containes propabilities with shape(10, 1)\n",
        "\n",
        "    a_out = np.argmax(a_out, 0)  # 0 represents row wise\n",
        "\n",
        "    labels = np.argmax(labels, 0)\n",
        "\n",
        "    acc = np.mean(a_out == labels)*100\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "later-brake",
      "metadata": {
        "id": "later-brake",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "2c51bad3-77e6-476e-fcd6-2ca98587a979"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (64,784) and (10000,28,28) not aligned: 784 (dim 1) != 28 (dim 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2249719077.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of Train Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of Test Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1264230133.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(X, Y, parameters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2133502252.py\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(x, parameters)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m## Complete the Code below : ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (64,784) and (10000,28,28) not aligned: 784 (dim 1) != 28 (dim 1)"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of Train Dataset\", accuracy(X_train, Y_train, Parameters), \"%\")\n",
        "print(\"Accuracy of Test Dataset\", round(accuracy(X_test, Y_test, Parameters), 2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "banned-clone",
      "metadata": {
        "id": "banned-clone",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "4fabbc4c-8c1e-4de2-f847-6fe58bccdbc0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'random' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3509225021.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ],
      "source": [
        "idx = int(random.randrange(0,X_test.shape[1]))\n",
        "plt.imshow(X_test[:, idx].reshape((28,28)),cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "cache = forward_prop(X_test[:, idx].reshape(X_test[:, idx].shape[0], 1), Parameters)\n",
        "a_pred = cache['a2']\n",
        "a_pred = np.argmax(a_pred, 0)\n",
        "\n",
        "print(\"Our model says it is :\", a_pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "pediatric-submission",
      "metadata": {
        "id": "pediatric-submission",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3db4b7f-b458-4b4d-bf6b-64c41b6740ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Train Dataset 93.46 %\n",
            "Accuracy of Test Dataset 91.65 %\n"
          ]
        }
      ],
      "source": [
        "def accuracy(X, Y, parameters):\n",
        "    cache = forward_prop(X, parameters)\n",
        "    predictions = np.argmax(cache['a2'], axis=0)\n",
        "    return np.mean(predictions == Y) * 100\n",
        "\n",
        "# Use X_train_flat and X_test_flat here\n",
        "print(\"Accuracy of Train Dataset\", accuracy(X_train_flat, Y_train, Parameters), \"%\")\n",
        "print(\"Accuracy of Test Dataset\", round(accuracy(X_test_flat, Y_test, Parameters), 2), \"%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}