{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font size=\"7\">üìù **Assignment-6**</font>\n",
        "I hope this assignment will give you clarity on how mathematical models like **Multilayer Perceptrons (MLP)** can be made from scratch using **PyTorch** & can be used to solve complex, non-linear geometric problems **without relying on black-box libraries**.\n",
        "\n",
        "---\n",
        "# ‚ö´ **Mission Critical: The Exclusion Zone Protocol**\n",
        "\n",
        "**Date:** Year 2142  \n",
        "**Location:** Exoplanet *Kepler-186f*   **Clearance:** IITians\n",
        "\n",
        "---\n",
        "\n",
        "### **‚ö´ The Story**\n",
        "Humanity has colonized the distant exoplanet *Kepler-186f*. While the surface is habitable, the planet's magnetic core is unstable. The **Global Defense Council (GDC)** has identified a dangerous phenomenon known as the **\"Radiation Ring.\"**\n",
        "\n",
        "Sensors indicate that the safe zones on the planet follow a peculiar geometry:\n",
        "* ‚ö´ **The Core Zone:** Distance $< 2$ km from the colony center (Safe).\n",
        "* ‚ö´ **The Outer Wilds:** Distance $> 4$ km from the colony center (Safe).\n",
        "* ‚ö´ **The Dead Zone:** The region **between 2 km and 4 km** is flooded with lethal gamma radiation.\n",
        "\n",
        "Your engineering team has deployed **3,000 sensor drones** across the colony to map this danger. Each drone reports its coordinates $(x, y)$ and a binary label:\n",
        "* `1`: Radiation Detected (Dead Zone)\n",
        "* `0`: Safe Zone\n",
        "\n",
        " **‚ö´ The Problem:** The sensors are cheap and prone to interference. Approximately **5%** of the drones are malfunctioning and reporting the wrong safety status (noise). The GDC mainframe is a legacy system that forbids the use of modern \"Neural Libraries\" (i.e., you cannot use `torch.nn` or `torch.optim`). You must build a **Multi-Layer Perceptron (MLP) from scratch** to filter out the noise and mathematically define the Exclusion Zone boundaries using **PyTorch**. ( Hint: You know this is a binary classification problem, which Loss function would you use?? )\n",
        "\n",
        "---\n",
        "\n",
        "### **‚ö´ Your Objective**\n",
        "\n",
        "1.  **Initialize the System:** Use your **Group Number** as the random seed. This ensures your team works on a unique sensor distribution pattern.\n",
        "2.  **Architect the Filter:** Construct a neural network with **3 hidden layers** (16 neurons each) to learn the non-linear \"donut\" shape of the Dead Zone.\n",
        "3.  **Manual Calibration:** You cannot use auto-optimizers. You must manually calculate the gradients (Backpropagation) and update the system weights using **Gradient Descent**.\n",
        "4.  **Verify Integrity:** Split your sensor data (70% training, 30% validation). Prove that your system doesn't just memorize the malfunctioning sensors (overfitting) but actually learns the geometric shape of the Dead Zone.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö´ Engineering Constraints (Read Carefully)\n",
        "\n",
        "**1. Restricted Modules**\n",
        "*  **Forbidden:** You are strictly forbidden from importing `torch.nn` (Layers/Loss) or `torch.optim` (Optimizers).\n",
        "*  **Allowed:** `import torch`, `import matplotlib.pyplot`, `import pandas`, `import numpy`, using `sklearn`.\n",
        "\n",
        "\n",
        "**2. The Mechanics**\n",
        "* **Forward Pass:** Must be implemented using raw matrix multiplication (`torch.matmul`) and bias addition.\n",
        "* **Backward Pass:** You **MAY** use `loss.backward()` to compute gradients automatically (Autograd).\n",
        "* **Optimization:** You **MUST** implement the weight updates manually (Stochastic Gradient Descent).\n",
        "    > `w_new = w_old - learning_rate * w_old.grad`\n",
        "\n",
        "**3. Loss Function**\n",
        "Since `torch.nn` is banned, you must implement **Binary Cross Entropy** manually using basic tensor math.\n",
        "\n",
        "$$Loss = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\cdot \\log(\\hat{y}_i) + (1-y_i) \\cdot \\log(1-\\hat{y}_i)]$$\n",
        "\n",
        "* **Note:** Ensure you handle the log of zero (numerical stability) or use `torch.clamp` to avoid `NaN` errors.\n",
        "\n",
        "**4. Visual Proof:** Your final output must include a Decision Boundary Map showing the \"Donut\" shape.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö´ **The GDC Dashboard (Required Output)**\n",
        "\n",
        "\n",
        "\n",
        "The Global Defense Council requires visual confirmation that your system is stable before we can upload it to the drone fleet. You must generate a **3-Panel Heads-Up Display (HUD)** containing the following telemetry:\n",
        "\n",
        "**1. System Error Trajectory (Loss Plot)**\n",
        "* **Mission:** Plot the **Training Loss** (Blue) vs. **Validation Loss** (Orange) over all epochs.\n",
        "* **Why:** We need to confirm that the system is actually learning and not just diverging (exploding gradients).\n",
        "\n",
        "**2. Integrity Check (Accuracy Plot)**\n",
        "* **Mission:** Plot the **Training Accuracy** vs. **Validation Accuracy**.\n",
        "* **Why:** If Training Accuracy is high (95%) but Validation Accuracy is low (80%), you have failed to generalize. This is a sign of **Overfitting**‚Äîmemorizing sensor noise instead of the Radiation Ring.\n",
        "\n",
        "**3. Geospatial Threat Map (Decision Boundary)**\n",
        "* **Mission:** Visualize the **Validation Set** on a 2D map.\n",
        "* **Overlay:** Draw the neural network's **Decision Boundary** (the contours where confidence = 0.5).\n",
        "* **Why:** The Commander needs to *see* the \"Donut\" shape. If your boundary looks like a jagged mess, the model is rejected.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sqmYfcSkoQPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# ===========================================================\n",
        "# PART 1: Data Generation (The Exclusion Zone)\n",
        "# ===========================================================\n",
        "\n",
        "# ‚ö†Ô∏è INSTRUCTION: Replace 1 with your actual Group Number\n",
        "GROUP_NUMBER = 1\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(GROUP_NUMBER)\n",
        "np.random.seed(GROUP_NUMBER)\n",
        "\n",
        "def generate_data(n_samples=3000):\n",
        "    \"\"\"\n",
        "    Generates 3000 sensor readings for the Kepler-186f Exclusion Zone.\n",
        "    Shape: Concentric circles (Donut).\n",
        "    Logic:\n",
        "      - Dead Zone (1): 2km < distance < 4km\n",
        "      - Safe Zone (0): distance < 2km OR distance > 4km\n",
        "    \"\"\"\n",
        "    # Generate random coordinates between -5 and 5 km\n",
        "    X = (torch.rand(n_samples, 2) * 10) - 5\n",
        "\n",
        "    # Calculate distance from center (radius)\n",
        "    radius = torch.sqrt(X[:, 0]**2 + X[:, 1]**2)\n",
        "\n",
        "    # Assign Labels: 1 if inside the Dead Zone, 0 otherwise\n",
        "    y = ((radius > 2) & (radius < 4)).float().view(-1, 1)\n",
        "\n",
        "    # Add 5% Noise (Malfunctioning Drones)\n",
        "    n_noise = int(0.05 * n_samples)\n",
        "    noise_indices = torch.randperm(n_samples)[:n_noise]\n",
        "    y[noise_indices] = 1 - y[noise_indices] # Flip labels\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Generate the dataset\n",
        "X_full, y_full = generate_data(3000)\n",
        "\n",
        "print(f\"Data Generated: {X_full.shape} samples.\")\n",
        "print(f\"Target Generated: {y_full.shape} labels.\")"
      ],
      "metadata": {
        "id": "rP6_Oh-3OJ9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Code from here. Best of luckk :)\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "sgzsnDTloTQ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}