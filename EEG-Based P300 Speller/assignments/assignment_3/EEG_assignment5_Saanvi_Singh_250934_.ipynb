{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylwj81y1XJBx"
      },
      "source": [
        "# **Assignment Roadmap**\n",
        "\n",
        "This assignment asks you to build a complete Brain-Computer Interface (BCI) pipeline. Your goal is to take raw, noisy electrical brain signals and turn them into a clear Yes/No decision: Is this the character the user wants?\n",
        "\n",
        "**Theres not much theory to learn other than implementation, you have to learn this by doing**\n",
        "\n",
        "## AI Usage Policy for This Assignment\n",
        "\n",
        "You're welcome to use AI for this assignment. Given the complexity of EEG signal processing and machine learning,\n",
        "We don't expect you to know every implementation detail from scratch and neither does any recuiter or any professor.\n",
        "\n",
        "\n",
        "Use AI to:\n",
        "\n",
        "    Debug errors and troubleshoot issues\n",
        "\n",
        "    Understand concepts and explore different approaches\n",
        "\n",
        "What matters:\n",
        "\n",
        "    You understand your code and can explain how it works\n",
        "\n",
        "    You learn from the process, not just copy-paste\n",
        "\n",
        "### **1: Cleaning the Signal (Preprocessing)**\n",
        "\n",
        "The Goal: Raw EEG data is full of \"garbage\" frequencies like muscle movement and electrical hum. You need to filter the data to keep only the brain waves relevant to the P300 response (typically 0.1Hz – 20Hz).\n",
        "\n",
        "You have already done this in the previous assignment but this one is a more standard procedure.\n",
        "\n",
        "Common Pitfalls:\n",
        "\n",
        "    Filter Lag: Standard filters can delay the signal, meaning the brain response looks like it happened later than it actually did. To prevent this, use zero-phase filtering (e.g., scipy.signal.filtfilt) instead of standard filtering (lfilter).\n",
        "\n",
        "    Aliasing: You are asked to downsample the data from 240Hz to 60Hz to make it faster to process. Do not simply slice the array (e.g., data[::4]) without filtering first. If you do, high-frequency noise will \"fold over\" into your low frequencies and corrupt the data. Always filter before downsampling.\n",
        "\n",
        "### **2: Epoch Extraction**\n",
        "\n",
        "The Goal: You need to convert the continuous stream of data into specific \"events\" or \"epochs.\"\n",
        "\n",
        "The Concept: A P300 response happens roughly 300ms after a flash. Your code needs to identify every moment a flash occurs (stimulus_onset), look forward in time (e.g., 800ms), and \"snip\" that window of data out.\n",
        "\n",
        "Visualizing the Data Structure:\n",
        "\n",
        "    Input: A continuous 2D matrix (Total_Time_Points, 64_Channels)\n",
        "\n",
        "    Output: A 3D block of events (Number_of_Flashes, Time_Points_Per_Window, 64_Channels)\n",
        "\n",
        "Common Pitfall:\n",
        "\n",
        "    Indexing Errors: This dataset may originate from MATLAB (which uses 1-based indexing), while Python uses 0-based indexing. If your index calculation is off by even one sample, your window will shift, and the machine learning model will be training on random noise rather than the brain response. Double-check your start and end indices.\n",
        "\n",
        "### **3: Making Data \"Model-Ready\" (Feature Engineering)**\n",
        "\n",
        "The Goal: Standard Machine Learning models (like SVM or LDA) cannot understand 3D arrays. They generally require a 2D matrix (like an Excel sheet). The Task:\n",
        "\n",
        "    Time Domain: You will need to \"flatten\" the epochs. If an epoch is 60 time points × 64 channels, it becomes a single flat row of 3,840 numbers.\n",
        "\n",
        "    PCA/CSP: These are compression techniques. The goal is to reduce those 3,840 numbers down to perhaps 20 numbers that capture the most important information.\n",
        "\n",
        "Common Pitfall:\n",
        "\n",
        "    Data Leakage: When using PCA or CSP, you must be careful not to \"cheat.\" You should .fit() your reducer only on the training data, and then .transform() the test data. If you fit on the combined dataset, your model \"sees\" the test answers ahead of time, leading to artificially high scores that won't work in the real world.\n",
        "\n",
        "### **4: Classification**\n",
        "\n",
        "The Goal: Feed your features into the ML models (LDA, SVM, etc.) provided in the skeleton code to classify \"Target\" vs. \"Non-Target\" flashes.\n",
        "\n",
        "Common Pitfall:\n",
        "\n",
        "    Class Imbalance: In a P300 speller, the letter the user wants (Target) only flashes 1 out of 6 times. The other 5 flashes are Non-Targets.\n",
        "\n",
        "        If your model decides to simply guess \"Non-Target\" every single time, it will still achieve ~83% accuracy. This is a useless model.\n",
        "\n",
        "        Do not rely solely on Accuracy. Check the F1-Score or the Confusion Matrix. A good model must be able to correctly identify the rare Target events, not just the frequent Non-Targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPwo3PCfXrg5",
        "outputId": "09e6f6a5-a058-4760-f20e-f9fa4463d594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "# The assignment is structured in a way that its modular so thats its easier to debug whats wrong\n",
        "!pip install mne\n",
        "from mne.decoding import CSP\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from scipy.signal import butter, filtfilt, iirnotch,find_peaks,resample\n",
        "from scipy.linalg import eigh\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report,\n",
        "                             confusion_matrix)\n",
        "\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tna0pc46s4yv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GzYFt1HdZy-B"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# SECTION 1: DATA LOADING AND BASIC SETUP\n",
        "################################################################################\n",
        "\n",
        "# Character matrix (6x6) for P300 speller\n",
        "CHAR_MATRIX = np.array([\n",
        "    ['A', 'B', 'C', 'D', 'E', 'F'],\n",
        "    ['G', 'H', 'I', 'J', 'K', 'L'],\n",
        "    ['M', 'N', 'O', 'P', 'Q', 'R'],\n",
        "    ['S', 'T', 'U', 'V', 'W', 'X'],\n",
        "    ['Y', 'Z', '1', '2', '3', '4'],\n",
        "    ['5', '6', '7', '8', '9', '_']\n",
        "])\n",
        "\n",
        "def load_data(file_path):\n",
        "  mat_data=sio.loadmat(file_path)\n",
        "  return mat_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Training data has labels, test data doesn't\n",
        "\n",
        "\n",
        "def get_char_from_codes(row_code, col_code):\n",
        "    \"\"\"Convert row/column stimulus codes to character\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "p6MhOVcFZ2tU",
        "outputId": "1a88df00-5553-4440-8c7b-67ac71460789"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Visualize ERP responses and confirm P300 peaks around 300ms\\n    Channel 31 = Cz (central midline electrode, best for P300)\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "################################################################################\n",
        "# SECTION 2: EEG SIGNAL ACQUISITION & PREPROCESSING\n",
        "################################################################################\n",
        "#extracting and reshaping eeg signal\n",
        "def extract_signal(mat_data):\n",
        " signal=mat_data['Signal']\n",
        " x,y,z=signal.shape\n",
        " signal= np.transpose(signal, axes=(0, 2, 1))\n",
        " signal= signal.reshape(z, x*y)\n",
        " signal=signal*1e-6 #conerting to microvolts\n",
        " return signal\n",
        "def bandpass_filter(signal, lowcut=0.1, highcut=20, fs=240, order=5):\n",
        "    nyq = 0.5 * fs #half sampling rate\n",
        "    low = lowcut / nyq #normalizing cutoff to nyq\n",
        "    high = highcut / nyq #normalizing cutoff to nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, signal, axis=-1)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Apply band-pass filter to remove low-frequency drift and high-frequency noise\n",
        "    Typical P300 band: 0.1-20 Hz\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def notch_filter(signal, freq=50, fs=240, Q=30):\n",
        "  b, a = iirnotch(freq / (fs / 2), Q)\n",
        "  for ch in range(signal.shape[0]):\n",
        "    signal[ch] = filtfilt(b, a, signal[ch])\n",
        "    \"\"\"\n",
        "    Remove powerline interference (50/60 Hz)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def baseline_correction(epoch, baseline_samples=50):\n",
        "    \"\"\"\n",
        "    Apply baseline correction by subtracting pre-stimulus baseline mean.\n",
        "    Subtracts the mean of the first `baseline_samples` from each time point across channels.\n",
        "    \"\"\"\n",
        "    if baseline_samples >= epoch.shape[0]:\n",
        "        raise ValueError(\"baseline_samples must be less than epoch length\")\n",
        "\n",
        "    baseline_mean = np.mean(epoch[:baseline_samples, :], axis=0)  # Mean per channel or you can understand as per epoch\n",
        "    corrected_epoch = epoch - baseline_mean\n",
        "    return corrected_epoch\n",
        "\n",
        "\n",
        "def downsample_signal(signal, original_fs=240, target_fs=60):\n",
        "  #lesser data improves computational efficiency\n",
        "  num_samples = int(len(signal) * target_fs / original_fs)\n",
        "  signal = resample(signal, num_samples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def artifact_rejection(signal, threshold=100):\n",
        "  abs_signal = np.abs(signal)\n",
        "  mask = abs_signal < threshold\n",
        "  return np.where(mask, signal, np.nan)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_pipeline(data, apply_bandpass=True, apply_notch=True,\n",
        "                       apply_downsample=True, fs=240):\n",
        "  data=bandpass_filter(data, lowcut=0.1, highcut=20, fs=240, order=5)\n",
        "  notch_filter(data, freq=50, fs=240, Q=30)\n",
        "  downsample_signal(data, original_fs=240, target_fs=60)\n",
        "  return data\n",
        "\n",
        "  \"\"\"\n",
        "    Complete preprocessing pipeline:\n",
        "    1. Bandpass filtering (0.1-20 Hz)\n",
        "    2. Notch filtering (50 Hz)\n",
        "    3. Downsampling (240->60 Hz)\n",
        "    \"\"\"\n",
        "\n",
        "def extract_epochs(data, epoch_length_ms=800, fs=60):\n",
        "    \"\"\"\n",
        "    Extract epochs around stimulus onset\n",
        "    - Event tagging: Use flashing signal to detect stimulus onset\n",
        "    - Stimulus alignment: Extract fixed-length windows after each flash\n",
        "    - Epoch extraction: Collect all stimulus-locked epochs\n",
        "\n",
        "    Returns: Dictionary with epochs, labels, codes, character indices\n",
        "    \"\"\"\n",
        "    epoch_samples = int((epoch_length_ms / 1000) * fs)\n",
        "\n",
        "    signal = data['Signal']\n",
        "    flashing = data['Flashing']\n",
        "    stimulus_code = data['StimulusCode']\n",
        "    stimulus_type = data.get('StimulusType')#returns none if key StimulusType is not present\n",
        "\n",
        "    epochs_list = []\n",
        "    labels_list = []\n",
        "    codes_list = []\n",
        "    char_idx_list = []\n",
        "\n",
        "    n_chars = signal.shape[0]\n",
        "\n",
        "    for char_idx in range(n_chars):\n",
        "        char_signal = signal[char_idx]\n",
        "        char_flashing = flashing[char_idx]\n",
        "        char_code = stimulus_code[char_idx]\n",
        "        char_type = stimulus_type[char_idx] if stimulus_type is not None else None\n",
        "\n",
        "        # Find stimulus onsets (flashing goes from 0 to 1)\n",
        "        flash_onsets = np.where(np.diff(char_flashing) == 1)[0] + 1\n",
        "\n",
        "        for onset in flash_onsets:\n",
        "            if onset + epoch_samples <= len(char_signal):\n",
        "                epoch = char_signal[onset:onset + epoch_samples, :]\n",
        "\n",
        "                # Apply baseline correction\n",
        "                epoch = baseline_correction(epoch, baseline_samples=10)\n",
        "\n",
        "                code = char_code[onset]\n",
        "                label = char_type[onset] if char_type is not None else -1\n",
        "\n",
        "                epochs_list.append(epoch)\n",
        "                labels_list.append(label)\n",
        "                codes_list.append(code)\n",
        "                char_idx_list.append(char_idx)\n",
        "\n",
        "    epochs = np.array(epochs_list) #epochs has shape (n_epochs,n_samples, n_channels);n_epochs is the total number of stimulus onsets and epoch_samples is time points per epoch\n",
        "    labels = np.array(labels_list)\n",
        "    codes = np.array(codes_list)\n",
        "    char_indices = np.array(char_idx_list)\n",
        "    return {'epochs':epochs,'labels':labels,'codes':codes,'char_indices':char_indices}\n",
        "\n",
        "def plot_erp_responses(epoch_data, channel_idx=31, fs=60):\n",
        " time = np.arange(epoch_data.shape[1]) / fs * 1000  # Time in ms\n",
        " p300_start = int(250 * fs / 1000)  #multiplying by fs/1000 gives the index;in this it is the 15th sample\n",
        " p300_end = int(500 * fs / 1000)\n",
        " data = epoch_data[:,p300_start:p300_end, channel_idx].mean(axis=0)\n",
        " peaks, _ = find_peaks(data, height=0)\n",
        " p300_peak_idx = peaks[np.argmax(data[peaks])]  # Highest peak index\n",
        " p300_amplitude = data[p300_peak_idx] - 0\n",
        " p300_latency_ms = time[p300_start + p300_peak_idx]# timestamp where peak oocurs\n",
        " plt.figure(figsize=(10, 5))\n",
        "\n",
        " plt.plot(time[p300_start:p300_end], data)\n",
        " plt.axvspan(250, 500, alpha=0.2, color='yellow', label='P300 window') #adds a yellow semi transparent shaded region(rectangle)\n",
        " if not np.isnan(p300_amplitude):\n",
        "    plt.plot([p300_latency_ms], [p300_amplitude], 'ro', markersize=10, label='P300 peak') #highlights the peak in red colour\n",
        " plt.axhline(0, color='k', linestyle='--', alpha=0.5) #adds a baseline for reference\n",
        " plt.xlabel('Time (ms)'); plt.ylabel('Voltage (µV)'); plt.title('ERP at Cz'); plt.legend()\n",
        " plt.show()\n",
        "\"\"\"\n",
        "    Visualize ERP responses and confirm P300 peaks around 300ms\n",
        "    Channel 31 = Cz (central midline electrode, best for P300)\n",
        "    \"\"\"\n",
        "    # Plot averages with standard error\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Mark P300 peak region\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate P300 amplitude difference\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Gj9JOgSfZ6Lu"
      },
      "outputs": [],
      "source": [
        "#################################################################################\n",
        "# SECTION 3: FEATURE ENGINEERING & BASELINE CLASSIFIERS\n",
        "################################################################################\n",
        "\n",
        "def extract_time_domain_features(epochs):\n",
        "    n_epochs = epochs.shape[0]\n",
        "    features = epochs.reshape(n_epochs, -1)\n",
        "    return features\n",
        "    \"\"\"Extract time-domain features: simply flatten the epochs\n",
        "    Shape: (n_epochs, n_samples * n_channels)\n",
        "    \"\"\"\n",
        "\n",
        "def extract_pca_features(train_epochs, n_components=20):\n",
        "  #flattening sicne pca requires 2D input:(n_epochs,n_samples*n_channels=n_features)\n",
        "  epochs_transformed=np.transpose(train_epochs,axes=(1,0,2))\n",
        "  x,y,z= epochs_transformed.shape\n",
        "  epochs_transformed=epochs_transformed.reshape(y,x*z)\n",
        "  scaler=StandardScaler() #transforms features so they all have a mean = 0 and standard deviation = 1 which helps PCA to treat all features equally.\n",
        "  epochs_transformed=scaler.fit_transform(epochs_transformed)\n",
        "  pca=PCA(n_components=n_components,random_state=42)\n",
        "  epochs_transformed=pca.fit_transform(epochs_transformed)\n",
        "  return epochs_transformed,pca\n",
        "  \"\"\"\n",
        "  Extract PCA features for dimensionality reduction\n",
        "  Reduces (n_samples * n_channels) to n_components\n",
        "  https://www.geeksforgeeks.org/machine-learning/implementing-pca-in-python-with-scikit-learn/\n",
        "  \"\"\"\n",
        "def extract_csp_features(epochs, labels, n_components=6):\n",
        "    \"\"\"\n",
        "    Common Spatial Patterns (CSP) for discriminative spatial filters\n",
        "    Finds spatial filters that maximize variance ratio between classes\n",
        "    \"\"\"\n",
        "    target_epochs = epochs[labels == 1]\n",
        "    non_target_epochs = epochs[labels == 0]\n",
        "\n",
        "\n",
        "    # Compute covariance matrices\n",
        "    def compute_cov(epochs):\n",
        "      epochs = epochs - np.mean(epochs, axis=(0, 1), keepdims=True)\n",
        "      n_trials, n_times, n_channels = epochs.shape\n",
        "      covs = []\n",
        "      for trial in epochs:\n",
        "        # Covariance per trial: (channels, channels)\n",
        "        cov = np.cov(trial)\n",
        "        covs.append(cov)\n",
        "      cov=np.mean(covs, axis=0)  # Average across trials\n",
        "      \"\"\"What happens here:\n",
        "         Trial 1: [ch1(t1),ch1(t2),...,ch1(t250)]  →  np.cov(trial) → Cov1 (22×22)\n",
        "         [ch2(t1),ch2(t2),...,ch2(t250)]  ↑\n",
        "         [ch22(t1),ch22(t2),...,ch22(t250)]\n",
        "\n",
        "         Trial 2: Same → Cov2 (22×22)\n",
        "         ...\n",
        "         Trial 50: Same → Cov50 (22×22)\n",
        "\n",
        "         Result: covs = [Cov1, Cov2, ..., Cov50]  # List of 50 matrices\"\"\"\n",
        "      return cov\n",
        "    cov_target=compute_cov(target_epochs)\n",
        "    cov_non_target=compute_cov(non_target_epochs)\n",
        "    cov_total=cov_target+cov_non_target\n",
        "\n",
        "    # Solve generalized eigenvalue problem\n",
        "    evals, evecs = eigh(cov_target, cov_total)\n",
        "    # Select most discriminative components (extreme eigenvalues)\n",
        "    filters = evecs[:, -n_components//2:].real  # Last n/2 for non-target maximizing; .real is necessary since eigh uses complex mathematical funcs and might generate small garbage imaginary numbers.\n",
        "    filters = np.hstack([evecs[:, :n_components//2].real, filters])  # First n/2 + last n/2\n",
        "\n",
        "    # Extract CSP features (log variance)\n",
        "    def get_features(epochs, filters):\n",
        "          projected = np.array([np.dot(epoch, filters) for epoch in epochs])  # Apply filters\n",
        "          variances = (projected ** 2).mean(-1)  # Power (squared) averaged over time\n",
        "          return np.log(variances)  # log of the variances are fetaures;taking logs provides better stability for ML models\n",
        "\n",
        "    target_features = get_features(target_epochs, filters)\n",
        "    non_target_features = get_features(non_target_epochs, filters)\n",
        "    features = np.vstack([non_target_features, target_features])\n",
        "    return features,filters\n",
        "\n",
        "\n",
        "def extract_features(epoch_data, method='pca', n_components=20,labels=None):\n",
        "  if method == 'time_domain':\n",
        "       extract_time_domain_features(epoch_data)\n",
        "       return epoch_data\n",
        "  elif method=='pca':\n",
        "    return extract_pca_features(epoch_data,n_components=20)\n",
        "  elif method=='csp':\n",
        "   # Handle CSP label issues\n",
        "   if method == 'csp':\n",
        "        unique_labels = np.unique(labels)\n",
        "        if len(unique_labels) < 2:\n",
        "            print(\"❌ ERROR: Need at least 2 classes for CSP\")\n",
        "            return None, None\n",
        "        label_map = {unique_labels[0]: 0, unique_labels[1]: 1}\n",
        "        binary_labels = np.array([label_map[label] for label in labels])\n",
        "        if np.sum(binary_labels == 1) == 0 or np.sum(binary_labels == 0) == 0:\n",
        "            print(\"❌ ERROR: No samples in one class\")\n",
        "            return None, None\n",
        "        csp = CSP(n_components=min(n_components, epoch_data.shape[1]), reg=None, log=True, norm_trace=False)#reg=None means no regularization applied.\n",
        "\n",
        "\n",
        "\n",
        "        X_csp = csp.fit_transform(epoch_data, binary_labels)\n",
        "        return X_csp, csp\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Feature extraction wrapper supporting multiple methods:\n",
        "  - time_domain: Raw time-domain samples (flattened)\n",
        "  - pca: Principal Component Analysis\n",
        "  - csp: Common Spatial Patterns\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "def train_lda_classifier(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Linear Discriminant Analysis with balanced priors\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
        "    \"\"\"\n",
        "    lda = LDA(priors=None, solver='svd')\n",
        "    lda.fit(X_train, y_train)\n",
        "\n",
        "    return lda\n",
        "\n",
        "def train_logistic_regression(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Logistic Regression - baseline classifier\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "    \"\"\"\n",
        "    model = LogisticRegression()  # Creates the model object\n",
        "    model.fit(X_train, y_train)   # Trains it on data\n",
        "    return model\n",
        "\n",
        "def evaluate_classifier(model, X_test, y_test, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Comprehensive classifier evaluation\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' for multi-class\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    results=pd.DataFrame([['accuracy',accuracy],['precision ',precision],['recall',recall],['f1',f1]],columns=['Metric',['Value']])\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"\\nConfusion Matrix for {model_name}:\")\n",
        "    print(cm)\n",
        "    # Optional: Visualize it\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for ROC AUC\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    results.loc[len(results)] = ['ROC AUC', roc_auc]  # Append to DataFrame\n",
        "    results.loc[len(results)] = ['accuracy', accuracy]  # Append to DataFrame\n",
        "    print(results.round(4))\n",
        "    return results\n",
        "\n",
        "class CSPTransformer:\n",
        "    \"\"\"\n",
        "    Wrapper for CSP filters to enable transform() method\n",
        "    \"\"\"\n",
        "    def __init__(self, filters=None):\n",
        "     self.filters=filters\n",
        "    def transform(self, X):\n",
        "     if self.filters is None:\n",
        "            raise ValueError(\"Fit filters first!\")\n",
        "     return np.dot(X, self.filters.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UTnYtWcDZ-F6"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# SECTION 4: CLASSICAL MACHINE LEARNING MODELS\n",
        "################################################################################\n",
        "\n",
        "def train_svm_classifier(X_train, y_train, kernel='rbf', C=1.0):\n",
        "    \"\"\"\n",
        "    Support Vector Machine with RBF kernel\n",
        "    Good for non-linear decision boundaries\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "    \"\"\"\n",
        "    model = Pipeline([(\"scaler\", StandardScaler()), (\"svc\", SVC(kernel=kernel, C=C, probability=True))])\n",
        "    #Pipeline is a trained model that first scales the data, then applies SVM.(Scaling is necessary for SVM)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    # Fit (train) the model on the training data\n",
        "    svm_A = model.named_steps['svc']      # Fitted SVM\n",
        "    scaler_A = model.named_steps['scaler'] # Fitted scaler\n",
        "    return svm_A,scaler_A\n",
        "\n",
        "def train_random_forest(X_train, y_train, n_estimators=100):\n",
        "    \"\"\"\n",
        "    Random Forest Classifier\n",
        "    Ensemble method, robust to overfitting\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "    \"\"\"\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def train_gradient_boosting(X_train, y_train, n_estimators=100):\n",
        "    \"\"\"\n",
        "    Gradient Boosting Classifier with manual sample weighting\n",
        "    (GradientBoosting doesn't support class_weight parameter)\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "    \"\"\"\n",
        "    print(f\"\\n  Training Gradient Boosting (n_estimators={n_estimators})...\")\n",
        "\n",
        "    # Calculate sample weights manually\n",
        "\n",
        "    classes, counts = np.unique(y_train, return_counts=True)\n",
        "    total_samples = len(y_train)\n",
        "    n_classes = len(classes)\n",
        "    class_weights = total_samples / (n_classes * counts)\n",
        "    model = GradientBoostingClassifier(n_estimators=n_estimators,  random_state=42,subsample=1.0)#subsample=1 means use full dataset\n",
        "    sample_weights=np.zeros_like(y_train)\n",
        "    for i,cls in enumerate(classes):\n",
        "      sample_weights[y_train==cls]=class_weights[i]\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)#sample_weight parameter tells each tree: \"When calculating split quality (e.g., Gini impurity), multiply errors by these weights.\"\n",
        "    return model\n",
        "def compare_all_classical_models(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train and compare all classical ML models\n",
        "    Returns performance comparison\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Calculate sample weights once for methods that need it.This prevents majority class bias.\n",
        "    sample_weights = None  # Default if no imbalance\n",
        "    if len(set(y_train)) > 1:\n",
        "     sample_weights = compute_sample_weight('balanced', y_train)\n",
        "\n",
        "    # Define models to train\n",
        "    models = {'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "   'SVM': SVC(random_state=42, probability=True),\n",
        "   'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "   'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100)}\n",
        "\n",
        "        # Training\n",
        "    trained_models = {}\n",
        "    for name, model in models.items():\n",
        "     model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "     trained_models[name] = model\n",
        "\n",
        "        # Inference\n",
        "\n",
        "\n",
        "        # Metrics\n",
        "    results = {}\n",
        "    for name, model in trained_models.items():\n",
        "     y_pred = model.predict(X_test)\n",
        "     results[name] = {\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred, average='weighted'),\n",
        "        'Classification Report': classification_report(y_test, y_pred)\n",
        "     }\n",
        "    # Summary table\n",
        "    summary_data = [{'Model': name, **metrics} for name, metrics in results.items()]#creating list of dictionaries,one corresponding to each model,from nested disctionaries. This makes data ready for pandas dataframe.\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_df = summary_df.sort_values('F1-Score', ascending=False).round(4).reset_index(drop=True)\n",
        "\n",
        "    return {'trained_models': trained_models,'results': results,'summary_table': summary_df}\n",
        "def save_model(model, filepath):\n",
        "    \"\"\"Save model to pickle file\"\"\"\n",
        "    with open(filepath, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"\\n  Model saved to: {filepath}\")\n",
        "\n",
        "def load_model(filepath):\n",
        "    \"\"\"Load model from pickle file\"\"\"\n",
        "    with open(filepath, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    print(f\"\\n  Model loaded from: {filepath}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3PZGrw1akxd",
        "outputId": "9dbe7e6b-b12b-4092-8ead-7b5bb00e8127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 1: LOADING DATA\n",
            "======================================================================\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 1: LOAD DATA\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 1: LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    train_data_A = load_data('/content/drive/MyDrive/Subject_A_Train.mat')\n",
        "    test_data_A = load_data('/content/drive/MyDrive/Subject_A_Test.mat')\n",
        "    train_data_B = load_data('/content/drive/MyDrive/Subject_B_Train.mat')\n",
        "    test_data_B = load_data('/content/drive/MyDrive/Subject_B_Test.mat')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXlBcbxjbg1h",
        "outputId": "46c19548-fb10-4b58-f350-1cb6c5683353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 2: PREPROCESSING\n",
            "======================================================================\n",
            "\n",
            "--- Subject A ---\n",
            "\n",
            "--- Subject B ---\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 2: PREPROCESSING\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 2: PREPROCESSING\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n--- Subject A ---\")\n",
        "    train_signal_A=extract_signal(train_data_A)\n",
        "    test_signal_A=extract_signal(test_data_A)\n",
        "    train_proc_A = preprocess_pipeline(train_signal_A)\n",
        "    test_proc_A = preprocess_pipeline(test_signal_A)\n",
        "\n",
        "    print(\"\\n--- Subject B ---\")\n",
        "    train_signal_B=extract_signal(train_data_B)\n",
        "    test_signal_B=extract_signal(test_data_B)\n",
        "    train_proc_B = preprocess_pipeline(train_signal_B)\n",
        "    test_proc_B = preprocess_pipeline(test_signal_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc3tgXm9bikE",
        "outputId": "b1e61a0f-7c9d-43d9-fb8b-c6b8b7329f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 3: EPOCH EXTRACTION\n",
            "======================================================================\n",
            "\n",
            "--- Subject A ---\n",
            "\n",
            "--- Subject B ---\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 3: EPOCH EXTRACTION\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 3: EPOCH EXTRACTION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n--- Subject A ---\")\n",
        "    train_epochs_A = extract_epochs(train_data_A, epoch_length_ms=800, fs=60)\n",
        "    test_epochs_A = extract_epochs(test_data_A, epoch_length_ms=800, fs=60)\n",
        "\n",
        "    print(\"\\n--- Subject B ---\")\n",
        "    train_epochs_B = extract_epochs(train_data_B, epoch_length_ms=800, fs=60)\n",
        "    test_epochs_B = extract_epochs(test_data_B, epoch_length_ms=800, fs=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "yEhmzHasbmAB",
        "outputId": "f68da4c5-4287-4e05-ad15-b007d2aadcf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 4: VISUALIZING ERP RESPONSES\n",
            "======================================================================\n",
            "\n",
            "--- Subject A ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 4: VISUALIZE ERP\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 4: VISUALIZING ERP RESPONSES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n--- Subject A ---\")\n",
        "    plot_erp_responses(train_epochs_A.get('epochs'), channel_idx=31)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "EqhlqSbyrEg5",
        "outputId": "309a895a-aa7e-4d99-858b-2f09fa056972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 5: FEATURE EXTRACTION\n",
            "======================================================================\n",
            "\n",
            "--- Subject A: Feature Comparison ---\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 7.2e+02 (2.2e-16 eps * 48 dim * 6.8e+16  max singular value)\n",
            "    Estimated rank (data): 48\n",
            "    data: rank 48 computed from 48 data channels with 0 projectors\n",
            "Reducing data rank from 48 -> 48\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3798510306.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0macc_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epochs_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mf1_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epochs_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;31m# ========================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    412\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 5: FEATURE EXTRACTION\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 5: FEATURE EXTRACTION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ========================================================================\n",
        "    # Subject A: Compare PCA vs CSP vs Time-Domain\n",
        "    # ========================================================================\n",
        "    print(\"\\n--- Subject A: Feature Comparison ---\")\n",
        "\n",
        "    # Try PCA (20 components)\n",
        "    X_train_pca20, pca20_A = extract_features(train_epochs_A.get('epochs'), method='pca', n_components=20)\n",
        "    X_test_pca20 = pca20_A.transform(test_epochs_A['epochs'].reshape(test_epochs_A['epochs'].shape[0], -1))#reshaping from (n_epochs,n_samples,n_channels) to (n_epochs,n_samples*n_channels) since pca requires 2D input\n",
        "\n",
        "    # Try PCA (50 components)\n",
        "    X_train_pca50, pca50_A = extract_features(train_epochs_A.get('epochs'), method='pca', n_components=50)\n",
        "    X_test_pca50 = pca50_A.transform(test_epochs_A['epochs'].reshape(test_epochs_A['epochs'].shape[0], -1))\n",
        "\n",
        "    # Try CSP\n",
        "    X_train_csp, csp_A = extract_features(train_epochs_A.get('epochs'), 'csp',6,train_epochs_A.get('labels'))\n",
        "    X_test_csp = csp_A.transform(test_epochs_A.get('epochs'))\n",
        "    # Try Raw Time-Domain Features\n",
        "    X_train_time=extract_time_domain_features(train_epochs_A.get('epochs'))\n",
        "    X_test_time=extract_time_domain_features(test_epochs_A.get('epochs'))\n",
        "\n",
        "\n",
        "\n",
        "    # Quick comparison with BALANCED LDA\n",
        "    lda=LDA()\n",
        "\n",
        "    # PCA-20 test\n",
        "    acc_pca20=cross_val_score(lda, X_train_pca20, train_epochs_A['labels'], cv=3, scoring='accuracy',n_jobs=-1).mean()#cv=5 means training will be done cv times on (cv-1)/cv data and then testing on 1/cv data and then mean of the accuarcy from cv trainings will be taken.\n",
        "    f1_pca20 = cross_val_score(lda, X_train_pca20, train_epochs_A['labels'], cv=3, scoring='f1_weighted',n_jobs=-1).mean()\n",
        "\n",
        "    # PCA-50 test\n",
        "    acc_pca50=cross_val_score(lda, X_train_pca50, train_epochs_A['labels'], cv=3, scoring='accuracy',n_jobs=-1).mean()\n",
        "    f1_pca50 = cross_val_score(lda, X_train_pca50, train_epochs_A['labels'], cv=3, scoring='f1_weighted',n_jobs=-1).mean()\n",
        "\n",
        "    # CSP test\n",
        "    acc_csp = cross_val_score(lda, X_train_csp, train_epochs_A['labels'], cv=3, scoring='accuracy',n_jobs=-1).mean()\n",
        "    f1_csp = cross_val_score(lda, X_train_csp, train_epochs_A['labels'], cv=3, scoring='f1_weighted',n_jobs=-1).mean()\n",
        "\n",
        "    # Time-Domain test\n",
        "\n",
        "    # Use LinearSVC (faster than SVM for high-dimensional data)\n",
        "    svc = LinearSVC(random_state=42, max_iter=1000)\n",
        "    acc_time = cross_val_score(svc, X_train_time, train_epochs_A['labels'], cv=3, scoring='accuracy',n_jobs=-1).mean()\n",
        "    f1_time = cross_val_score(svc, X_train_time, train_epochs_A['labels'], cv=3, scoring='f1_weighted',n_jobs=-1).mean()\n",
        "    # ========================================================================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FEATURE COMPARISON (Balanced Classifiers)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"PCA (20 comp):      Accuracy={acc_pca20:.4f}, F1={f1_pca20:.4f}\")\n",
        "    print(f\"PCA (50 comp):      Accuracy={acc_pca50:.4f}, F1={f1_pca50:.4f}\")\n",
        "    print(f\"CSP (20 comp):       Accuracy={acc_csp:.4f}, F1={f1_csp:.4f}\")\n",
        "    print(f\"Time-Domain (3072): Accuracy={acc_time:.4f}, F1={f1_time:.4f}\")\n",
        "\n",
        "    # Select best method based on F1-score\n",
        "    methods = ['pca20', 'pca50', 'csp', 'time']\n",
        "    feature_objs=[pca20_A,pca50_A,csp_A,None]\n",
        "    f1_scores = [f1_pca20, f1_pca50, f1_csp, f1_time]\n",
        "    best_idx = f1_scores.index(max(f1_scores))\n",
        "    feature_obj_A=feature_objs[best_idx]\n",
        "    feature_method_A = methods[best_idx]\n",
        "    n_components_A = 20 if feature_method_A == 'pca20' else 50 if feature_method_A == 'pca50' else 6\n",
        "    print(f\"\\nBest method selected: {feature_method_A.upper()} (F1={max(f1_scores):.4f})\")\n",
        "\n",
        "    X_train_full_A = {'pca20': X_train_pca20, 'pca50': X_train_pca50, 'csp': X_train_csp, 'time': X_train_time}[feature_method_A]#X_train_full_A contains the feature matrix corresponding to the best method\n",
        "\n",
        "  # ========================================================================\n",
        "# Subject A: Create final train/validation split for later steps\n",
        "# ========================================================================\n",
        "    X_train_A, X_val_A, y_train_A, y_val_A = train_test_split(X_train_full_A, train_epochs_A['labels'], test_size=0.2, random_state=42, stratify=train_epochs_A['labels'])#stratify ensures that the split mirrors original data w.r.t. labels thereby enhancing accuracy\n",
        "    print(f\"\\nSubject A splits: Training={len(X_train_A)}, Validation={len(X_val_A)}\")\n",
        "\n",
        "# Transform test data\n",
        "    if feature_method_A == 'time':\n",
        "     X_test_A = extract_time_domain_features(test_epochs_A.get('epochs'))\n",
        "    elif feature_method_A == 'pca20' or feature_method_A == 'pca50':\n",
        "     X_test_A = feature_obj_A.transform(test_epochs_A['epochs'].reshape(test_epochs_A['epochs'].shape[0], -1))\n",
        "    else:  # CSP\n",
        "     X_test_A = feature_obj_A.transform(test_epochs_A['epochs'])\n",
        "\n",
        "    print(f\"Test features: {X_test_A.shape}\")\n",
        "\n",
        "# ========================================================================\n",
        "# Subject B: Use same method as Subject A\n",
        "# ========================================================================\n",
        "    print(\"\\n--- Subject B: Feature Extraction ---\")\n",
        "    print(f\"\\nUsing {feature_method_A.upper()} (same as Subject A)...\")\n",
        "\n",
        "    if feature_method_A == 'time':\n",
        "     X_train_full_B = extract_time_domain_features(train_epochs_B.get('epochs'))\n",
        "     X_test_B =extract_time_domain_features(test_epochs_B.get('epochs'))\n",
        "    elif feature_method_A == 'pca20' or feature_method_A == 'pca50':\n",
        "     X_train_full_B, pca_B = extract_features(train_epochs_B.get('epochs'), method='pca', n_components=n_components_A)\n",
        "     X_test_B = pca_B.transform(test_epochs_B['epochs'].reshape(test_epochs_B['epochs'].shape[0], -1))\n",
        "    else:  # CSP\n",
        "     X_train_full_B, csp_B = extract_features(train_epochs_B.get('epochs'), 'csp', 6,train_epochs_B.get('labels'))\n",
        "     X_test_B = csp_B.transform(test_epochs_B['epochs'])\n",
        "\n",
        "    X_train_B, X_val_B, y_train_B, y_val_B = train_test_split(X_train_full_B, train_epochs_B['labels'], test_size=0.2, random_state=42, stratify=train_epochs_B['labels'])\n",
        "\n",
        "    print(f\"\\nSubject B splits: Training={len(X_train_B)}, Validation={len(X_val_B)}\")\n",
        "    print(f\"Test features: {X_test_B.shape}\")\n",
        "\n",
        "    # Store feature objects for later use\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GauEiGE1bqhr"
      },
      "outputs": [],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 6: BASELINE CLASSIFIERS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 6: BASELINE CLASSIFIERS (Subject A)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    lda_A = train_lda_classifier(X_train_A, y_train_A)\n",
        "    acc_lda = evaluate_classifier(lda_A, X_val_A, y_val_A, \"LDA\")\n",
        "\n",
        "    lr_A = train_logistic_regression(X_train_A, y_train_A)\n",
        "    acc_lr = evaluate_classifier(lr_A, X_val_A, y_val_A, \"Logistic Regression\")\n",
        "\n",
        "    result_list=[['LDA',acc_lda],['Logistic regression',acc_lr]]\n",
        "    df=pd.DataFrame(result_list,columns=['Method','Accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbYQtMibbsah"
      },
      "outputs": [],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 7: CLASSICAL ML MODELS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 7: CLASSICAL MACHINE LEARNING (Subject A)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    models_A,results_classical_A,summary_classical_A= compare_all_classical_models(\n",
        "        X_train_A, y_train_A, X_val_A, y_val_A\n",
        "    )\n",
        "    print(results_classical_A)\n",
        "\n",
        "    # Train SVM for both subjects (best model)\n",
        "    svm_A, scaler_A = train_svm_classifier(X_train_A, y_train_A)\n",
        "    svm_B, scaler_B = train_svm_classifier(X_train_B, y_train_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRtmndiQbua4"
      },
      "outputs": [],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 8: EXPORT MODELS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 8: EXPORTING MODELS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    import os\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "\n",
        "    # Save pickle\n",
        "    save_model({\n",
        "        'model': svm_A,\n",
        "        'scaler': scaler_A,\n",
        "        'pca': feature_method_A\n",
        "    }, 'models/subject_A_svm.pkl')\n",
        "\n",
        "    save_model({\n",
        "        'model': svm_B,\n",
        "        'scaler': scaler_B,\n",
        "        'pca': pca_B\n",
        "    }, 'models/subject_B_svm.pkl')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}