{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment Roadmap**\n",
        "\n",
        "This assignment asks you to build a complete Brain-Computer Interface (BCI) pipeline. Your goal is to take raw, noisy electrical brain signals and turn them into a clear Yes/No decision: Is this the character the user wants?\n",
        "\n",
        "**Theres not much theory to learn other than implementation, you have to learn this by doing**\n",
        "\n",
        "## AI Usage Policy for This Assignment\n",
        "\n",
        "You're welcome to use AI for this assignment. Given the complexity of EEG signal processing and machine learning,\n",
        "We don't expect you to know every implementation detail from scratch and neither does any recuiter or any professor.\n",
        "\n",
        "\n",
        "Use AI to:\n",
        "\n",
        "    Debug errors and troubleshoot issues\n",
        "\n",
        "    Understand concepts and explore different approaches\n",
        "\n",
        "What matters:\n",
        "\n",
        "    You understand your code and can explain how it works\n",
        "\n",
        "    You learn from the process, not just copy-paste\n",
        "\n",
        "### **1: Cleaning the Signal (Preprocessing)**\n",
        "\n",
        "The Goal: Raw EEG data is full of \"garbage\" frequencies like muscle movement and electrical hum. You need to filter the data to keep only the brain waves relevant to the P300 response (typically 0.1Hz – 20Hz).\n",
        "\n",
        "You have already done this in the previous assignment but this one is a more standard procedure.\n",
        "\n",
        "Common Pitfalls:\n",
        "\n",
        "    Filter Lag: Standard filters can delay the signal, meaning the brain response looks like it happened later than it actually did. To prevent this, use zero-phase filtering (e.g., scipy.signal.filtfilt) instead of standard filtering (lfilter).\n",
        "\n",
        "    Aliasing: You are asked to downsample the data from 240Hz to 60Hz to make it faster to process. Do not simply slice the array (e.g., data[::4]) without filtering first. If you do, high-frequency noise will \"fold over\" into your low frequencies and corrupt the data. Always filter before downsampling.\n",
        "\n",
        "### **2: Epoch Extraction**\n",
        "\n",
        "The Goal: You need to convert the continuous stream of data into specific \"events\" or \"epochs.\"\n",
        "\n",
        "The Concept: A P300 response happens roughly 300ms after a flash. Your code needs to identify every moment a flash occurs (stimulus_onset), look forward in time (e.g., 800ms), and \"snip\" that window of data out.\n",
        "\n",
        "Visualizing the Data Structure:\n",
        "\n",
        "    Input: A continuous 2D matrix (Total_Time_Points, 64_Channels)\n",
        "\n",
        "    Output: A 3D block of events (Number_of_Flashes, Time_Points_Per_Window, 64_Channels)\n",
        "\n",
        "Common Pitfall:\n",
        "\n",
        "    Indexing Errors: This dataset may originate from MATLAB (which uses 1-based indexing), while Python uses 0-based indexing. If your index calculation is off by even one sample, your window will shift, and the machine learning model will be training on random noise rather than the brain response. Double-check your start and end indices.\n",
        "\n",
        "### **3: Making Data \"Model-Ready\" (Feature Engineering)**\n",
        "\n",
        "The Goal: Standard Machine Learning models (like SVM or LDA) cannot understand 3D arrays. They generally require a 2D matrix (like an Excel sheet). The Task:\n",
        "\n",
        "    Time Domain: You will need to \"flatten\" the epochs. If an epoch is 60 time points × 64 channels, it becomes a single flat row of 3,840 numbers.\n",
        "\n",
        "    PCA/CSP: These are compression techniques. The goal is to reduce those 3,840 numbers down to perhaps 20 numbers that capture the most important information.\n",
        "\n",
        "Common Pitfall:\n",
        "\n",
        "    Data Leakage: When using PCA or CSP, you must be careful not to \"cheat.\" You should .fit() your reducer only on the training data, and then .transform() the test data. If you fit on the combined dataset, your model \"sees\" the test answers ahead of time, leading to artificially high scores that won't work in the real world.\n",
        "\n",
        "### **4: Classification**\n",
        "\n",
        "The Goal: Feed your features into the ML models (LDA, SVM, etc.) provided in the skeleton code to classify \"Target\" vs. \"Non-Target\" flashes.\n",
        "\n",
        "Common Pitfall:\n",
        "\n",
        "    Class Imbalance: In a P300 speller, the letter the user wants (Target) only flashes 1 out of 6 times. The other 5 flashes are Non-Targets.\n",
        "\n",
        "        If your model decides to simply guess \"Non-Target\" every single time, it will still achieve ~83% accuracy. This is a useless model.\n",
        "\n",
        "        Do not rely solely on Accuracy. Check the F1-Score or the Confusion Matrix. A good model must be able to correctly identify the rare Target events, not just the frequent Non-Targets."
      ],
      "metadata": {
        "id": "Ylwj81y1XJBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPwo3PCfXrg5"
      },
      "outputs": [],
      "source": [
        "# The assignment is structured in a way that its modular so thats its easier to debug whats wrong\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from scipy.signal import butter, filtfilt, iirnotch\n",
        "from scipy.linalg import eigh\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report,\n",
        "                             confusion_matrix)\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GzYFt1HdZy-B"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# SECTION 1: DATA LOADING AND BASIC SETUP\n",
        "################################################################################\n",
        "\n",
        "# Character matrix (6x6) for P300 speller\n",
        "CHAR_MATRIX = np.array([\n",
        "    ['A', 'B', 'C', 'D', 'E', 'F'],\n",
        "    ['G', 'H', 'I', 'J', 'K', 'L'],\n",
        "    ['M', 'N', 'O', 'P', 'Q', 'R'],\n",
        "    ['S', 'T', 'U', 'V', 'W', 'X'],\n",
        "    ['Y', 'Z', '1', '2', '3', '4'],\n",
        "    ['5', '6', '7', '8', '9', '_']\n",
        "])\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load P300 BCI Competition III data\n",
        "    Returns dictionary with signal, flashing, stimulus_code, stimulus_type, target_char\n",
        "    \"\"\"\n",
        "    mat = sio.loadmat(file_path)\n",
        "\n",
        "    data = {\n",
        "        'signal': mat['Signal'],                 #(time, channels)\n",
        "        'flashing': mat['Flashing'].squeeze(),   #(time,)\n",
        "        'stimulus_code': mat['StimulusCode'].squeeze()\n",
        "    }\n",
        "    #optional fields that exist only in training data\n",
        "    data['stimulus_type'] = mat['StimulusType'].squeeze() if 'StimulusType' in mat else None\n",
        "    data['target_char'] = mat['TargetChar'][0] if 'TargetChar' in mat else None\n",
        "\n",
        "    print(f\"Loaded {file_path}\")\n",
        "    print(f\"Signal shape: {data['signal'].shape}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "    # Training data has labels, test data doesn't\n",
        "\n",
        "\n",
        "def get_char_from_codes(row_code, col_code):\n",
        "    \"\"\"Convert row/column stimulus codes to character\"\"\"\n",
        "    row = row_code - 1\n",
        "    col = col_code - 7\n",
        "    return CHAR_MATRIX[row, col]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p6MhOVcFZ2tU"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# SECTION 2: EEG SIGNAL ACQUISITION & PREPROCESSING\n",
        "################################################################################\n",
        "\n",
        "def bandpass_filter(signal, lowcut=0.1, highcut=20, fs=240, order=5):\n",
        "    \"\"\"\n",
        "    Apply band-pass filter to remove low-frequency drift and high-frequency noise\n",
        "    Typical P300 band: 0.1-20 Hz\n",
        "    \"\"\"\n",
        "    nyq = 0.5*fs\n",
        "    low = lowcut/nyq\n",
        "    high = highcut/nyq\n",
        "\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, signal, axis=0)\n",
        "\n",
        "\n",
        "def notch_filter(signal, freq=50, fs=240, Q=30):\n",
        "    \"\"\"\n",
        "    Remove powerline interference (50/60 Hz)\n",
        "    \"\"\"\n",
        "    b, a = iirnotch(freq/(fs/2), Q)\n",
        "    return filtfilt(b, a, signal, axis=0)\n",
        "\n",
        "\n",
        "def baseline_correction(epoch, baseline_samples=10):\n",
        "    \"\"\"\n",
        "    Apply baseline correction by subtracting pre-stimulus baseline\n",
        "    \"\"\"\n",
        "    baseline = np.mean(epoch[:baseline_samples, :], axis=0)\n",
        "    return epoch - baseline\n",
        "\n",
        "\n",
        "def downsample_signal(signal, original_fs=240, target_fs=60):\n",
        "    \"\"\"\n",
        "    Downsample signal to reduce computational load\n",
        "    240 Hz -> 60 Hz reduces data by 4x\n",
        "    \"\"\"\n",
        "    factor = int(original_fs/target_fs)\n",
        "    return signal[::factor]\n",
        "\n",
        "\n",
        "def artifact_rejection(signal, threshold=100):\n",
        "    \"\"\"\n",
        "    Simple artifact rejection based on amplitude threshold\n",
        "    More advanced: use ICA or wavelet denoising\n",
        "    \"\"\"\n",
        "    mask = np.max(np.abs(signal), axis=1) < threshold\n",
        "    return signal[mask]\n",
        "\n",
        "\n",
        "def preprocess_pipeline(data, apply_bandpass=True, apply_notch=True,\n",
        "                       apply_downsample=True, fs=240):\n",
        "    \"\"\"\n",
        "    Complete preprocessing pipeline:\n",
        "    1. Bandpass filtering (0.1-20 Hz)\n",
        "    2. Notch filtering (50 Hz)\n",
        "    3. Downsampling (240->60 Hz)\n",
        "    \"\"\"\n",
        "    signal = data['signal']\n",
        "    flashing = data['flashing']\n",
        "    stimulus_code = data['stimulus_code']\n",
        "    stimulus_type = data['stimulus_type']\n",
        "\n",
        "    #if signal is (trials, time, channels) then flatten trials\n",
        "    if signal.ndim == 3:\n",
        "        n_trials, n_time, n_ch = signal.shape\n",
        "        signal = signal.reshape(n_trials * n_time, n_ch)\n",
        "        flashing = flashing.reshape(-1)\n",
        "        stimulus_code = stimulus_code.reshape(-1)\n",
        "        if stimulus_type is not None:\n",
        "            stimulus_type = stimulus_type.reshape(-1)\n",
        "\n",
        "    if apply_bandpass:\n",
        "        signal = bandpass_filter(signal, fs=fs)\n",
        "\n",
        "    if apply_notch:\n",
        "        signal = notch_filter(signal, fs=fs)\n",
        "\n",
        "    if apply_downsample:\n",
        "        signal = signal[::4]\n",
        "        flashing = flashing[::4]\n",
        "        stimulus_code = stimulus_code[::4]\n",
        "        if stimulus_type is not None:\n",
        "            stimulus_type = stimulus_type[::4]\n",
        "\n",
        "    processed_data = data.copy()\n",
        "    processed_data['signal'] = signal\n",
        "    processed_data['flashing'] = flashing\n",
        "    processed_data['stimulus_code'] = stimulus_code\n",
        "    processed_data['stimulus_type'] = stimulus_type\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "def extract_epochs(data, epoch_length_ms=1000, fs=60):\n",
        "    \"\"\"\n",
        "    Extract epochs around stimulus onset\n",
        "    - Event tagging: Use flashing signal to detect stimulus onset\n",
        "    - Stimulus alignment: Extract fixed-length windows after each flash\n",
        "    - Epoch extraction: Collect all stimulus-locked epochs\n",
        "\n",
        "    Returns: Dictionary with epochs, labels, codes, character indices\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        # Find stimulus onsets (flashing goes from 0 to 1)\n",
        "\n",
        "\n",
        "\n",
        "                # Apply baseline correction\n",
        "\n",
        "    signal = data['signal']\n",
        "    flashing = data['flashing']\n",
        "    stimulus_code = data['stimulus_code']\n",
        "    stimulus_type = data['stimulus_type']\n",
        "\n",
        "    samples_per_epoch = int(epoch_length_ms*fs/1000)\n",
        "\n",
        "    #finding stimulus onsets\n",
        "    onsets = np.where(np.diff(flashing) == 1)[0] + 1\n",
        "\n",
        "    epochs = []\n",
        "    labels = []\n",
        "    codes_list = []\n",
        "\n",
        "    for onset in onsets:\n",
        "      if onset + samples_per_epoch <= signal.shape[0]:\n",
        "          epoch = signal[onset:onset + samples_per_epoch, :]\n",
        "          epoch = baseline_correction(epoch)\n",
        "          epochs.append(epoch)\n",
        "\n",
        "          if stimulus_type is not None:\n",
        "             labels.append(stimulus_type[onset])\n",
        "          else:\n",
        "              labels.append(-1)\n",
        "\n",
        "          codes_list.append(stimulus_code[onset])\n",
        "\n",
        "    epochs = np.array(epochs)\n",
        "    labels = np.array(labels)\n",
        "    codes_list = np.array(codes_list)\n",
        "\n",
        "    char_idx_list = np.zeros(len(labels), dtype=int)\n",
        "\n",
        "    print(f\"Extracted {len(epochs)} epochs\")\n",
        "    print(f\"Epoch shape: {epochs.shape}\")\n",
        "\n",
        "    return {\n",
        "        'epochs': epochs,\n",
        "        'labels': labels,\n",
        "        'codes': np.array(codes_list),\n",
        "        'char_indices': np.array(char_idx_list)\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def plot_erp_responses(epoch_data, channel_idx=30, fs=60):\n",
        "    \"\"\"\n",
        "    Visualize ERP responses and confirm P300 peaks around 300ms\n",
        "    Channel 31 = Cz (central midline electrode, best for P300)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Plot averages with standard error\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Mark P300 peak region\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate P300 amplitude difference\n",
        "\n",
        "    epochs = epoch_data['epochs']      #(n_epochs, time, channels)\n",
        "    labels = epoch_data['labels']      #1 is target, 0 is non-target\n",
        "    print(\"Epochs shape:\", epochs.shape)\n",
        "    print(\"Targets:\", (labels == 1).sum(), \"Non-targets:\", (labels == 0).sum())\n",
        "\n",
        "    #take absolute value to avoid cancellation\n",
        "    epochs_abs = np.abs(epochs)\n",
        "\n",
        "    #average across epochs and channels\n",
        "    target_mean = np.mean(epochs_abs[labels == 1], axis=(0, 2))\n",
        "    nontarget_mean = np.mean(epochs_abs[labels == 0], axis=(0, 2))\n",
        "\n",
        "    #time axis\n",
        "    fs = 60\n",
        "    time = np.arange(target_mean.shape[0]) * 1000 / fs\n",
        "\n",
        "    target_mean *= 1e3\n",
        "    nontarget_mean *= 1e3\n",
        "\n",
        "    #plot\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(time, target_mean, label=\"Target\", color=\"red\")\n",
        "    plt.plot(time, nontarget_mean, label=\"Non-Target\", color=\"blue\")\n",
        "    plt.axvspan(250, 400, alpha=0.2, color=\"gray\", label=\"P300 window\")\n",
        "\n",
        "    plt.xlabel(\"Time (ms)\")\n",
        "    plt.ylabel(\"Amplitude (µV)\")\n",
        "    plt.title(\"ERP Visualization (Magnitude-Averaged)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"P300 diff:\",\n",
        "          np.mean(target_mean[(time >= 250) & (time <= 400)]) -\n",
        "          np.mean(nontarget_mean[(time >= 250) & (time <= 400)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Gj9JOgSfZ6Lu"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# SECTION 3: FEATURE ENGINEERING & BASELINE CLASSIFIERS\n",
        "################################################################################\n",
        "\n",
        "def extract_time_domain_features(epoch_data):\n",
        "    \"\"\"\n",
        "    Extract time-domain features: simply flatten the epochs\n",
        "    Shape: (n_epochs, n_samples * n_channels)\n",
        "    \"\"\"\n",
        "    epochs = epoch_data['epochs']\n",
        "    labels = epoch_data['labels']\n",
        "\n",
        "    n_epochs, n_times, n_channels = epochs.shape\n",
        "    features = epochs.reshape(n_epochs, n_times*n_channels)\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "def extract_pca_features(epochs, n_components=20):\n",
        "    \"\"\"\n",
        "    Extract PCA features for dimensionality reduction\n",
        "    Reduces (n_samples * n_channels) to n_components\n",
        "    https://www.geeksforgeeks.org/machine-learning/implementing-pca-in-python-with-scikit-learn/\n",
        "    \"\"\"\n",
        "    epochs = epoch_data['epochs']\n",
        "    labels = epoch_data['labels']\n",
        "\n",
        "    X = epochs.reshape(epochs.shape[0], -1)\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    return X_pca, labels, pca\n",
        "\n",
        "def extract_csp_features(epochs, labels, n_components=6):\n",
        "    \"\"\"\n",
        "    Common Spatial Patterns (CSP) for discriminative spatial filters\n",
        "    Finds spatial filters that maximize variance ratio between classes\n",
        "    \"\"\"\n",
        "    target_epochs = epochs[labels == 1]\n",
        "    non_target_epochs = epochs[labels == 0]\n",
        "    print(f\"  Target epochs for CSP: {len(target_epochs)}\")\n",
        "    print(f\"  Non-target epochs for CSP: {len(non_target_epochs)}\")\n",
        "\n",
        "    # Compute covariance matrices\n",
        "    def compute_cov(data):\n",
        "      cov = np.zeros((data.shape[2], data.shape[2]))\n",
        "      for epoch in data:\n",
        "            cov += np.cov(epoch.T)\n",
        "      return cov/data.shape[0]\n",
        "\n",
        "    cov_target = compute_cov(target_epochs)\n",
        "    cov_non_target = compute_cov(non_target_epochs)\n",
        "\n",
        "\n",
        "    # Solve generalized eigenvalue problem\n",
        "    eigvals, eigvecs = eigh(cov_target, cov_target + cov_non_target)\n",
        "\n",
        "\n",
        "    # Sort by eigenvalues\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvecs = eigvecs[:, idx]\n",
        "\n",
        "\n",
        "    # Select most discriminative components (extreme eigenvalues)\n",
        "    W = eigvecs[:, :n_components]\n",
        "\n",
        "    # Extract CSP features (log variance)\n",
        "    features = []\n",
        "    for epoch in epochs:\n",
        "        projected = epoch @ W\n",
        "        var = np.var(projected, axis=0)\n",
        "        features.append(np.log(var))\n",
        "\n",
        "    return np.array(features), W\n",
        "\n",
        "\n",
        "\n",
        "def extract_features(epoch_data, method='pca', n_components=20):\n",
        "    \"\"\"\n",
        "    Feature extraction wrapper supporting multiple methods:\n",
        "    - time_domain: Raw time-domain samples (flattened)\n",
        "    - pca: Principal Component Analysis\n",
        "    - csp: Common Spatial Patterns\n",
        "    \"\"\"\n",
        "    epochs = epoch_data['epochs']\n",
        "    labels = epoch_data['labels']\n",
        "\n",
        "    if method == 'time_domain':\n",
        "        X = epochs.reshape(epochs.shape[0], -1)\n",
        "        return X, labels, None\n",
        "\n",
        "    elif method == 'pca':\n",
        "        X = epochs.reshape(epochs.shape[0], -1)\n",
        "        pca = PCA(n_components=n_components)\n",
        "        X_pca = pca.fit_transform(X)\n",
        "        return X_pca, labels, pca\n",
        "\n",
        "    elif method == 'csp':\n",
        "        X_csp, W = extract_csp_features(epochs, labels, n_components)\n",
        "        return X_csp, labels, W\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid feature extraction method\")\n",
        "\n",
        "\n",
        "\n",
        "def train_lda_classifier(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Linear Discriminant Analysis with balanced priors\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
        "    \"\"\"\n",
        "    lda = LinearDiscriminantAnalysis(priors=[0.5, 0.5])\n",
        "    lda.fit(X_train, y_train)\n",
        "    return lda\n",
        "\n",
        "\n",
        "def train_logistic_regression(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Logistic Regression - baseline classifier\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "    \"\"\"\n",
        "    lr = LogisticRegression(max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    return lr\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_classifier(model, X_test, y_test, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Comprehensive classifier evaluation\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\n=== {model_name} Evaluation ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "class CSPTransformer:\n",
        "    \"\"\"\n",
        "    Wrapper for CSP filters to enable transform() method\n",
        "    \"\"\"\n",
        "    def __init__(self, W):\n",
        "        self.W = W\n",
        "\n",
        "    def transform(self, epochs):\n",
        "        features = []\n",
        "        for epoch in epochs:\n",
        "            projected = epoch @ self.W\n",
        "            var = np.var(projected, axis=0)\n",
        "            features.append(np.log(var))\n",
        "        return np.array(features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UTnYtWcDZ-F6"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# SECTION 4: CLASSICAL MACHINE LEARNING MODELS\n",
        "################################################################################\n",
        "\n",
        "def train_svm_classifier(X_train, y_train, kernel='rbf', C=1.0):\n",
        "    \"\"\"\n",
        "    Support Vector Machine with RBF kernel\n",
        "    Good for non-linear decision boundaries\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "    \"\"\"\n",
        "    svm = SVC(kernel=kernel, C=C)\n",
        "    svm.fit(X_train, y_train)\n",
        "    return svm\n",
        "\n",
        "\n",
        "def train_random_forest(X_train, y_train, n_estimators=100):\n",
        "    \"\"\"\n",
        "    Random Forest Classifier\n",
        "    Ensemble method, robust to overfitting\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "    \"\"\"\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    return rf\n",
        "\n",
        "\n",
        "def train_gradient_boosting(X_train, y_train, n_estimators=100):\n",
        "    \"\"\"\n",
        "    Gradient Boosting Classifier with manual sample weighting\n",
        "    (GradientBoosting doesn't support class_weight parameter)\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "    \"\"\"\n",
        "    print(f\"\\n  Training Gradient Boosting (n_estimators={n_estimators})...\")\n",
        "\n",
        "    # Calculate sample weights manually\n",
        "    class_counts = np.bincount(y_train.astype(int))\n",
        "\n",
        "    total = len(y_train)\n",
        "    class_weights = {\n",
        "        0: total/(2*class_counts[0]),\n",
        "        1: total/(2*class_counts[1])\n",
        "    }\n",
        "    sample_weights = np.array([class_weights[y] for y in y_train])\n",
        "\n",
        "    gb = GradientBoostingClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        random_state=42\n",
        "    )\n",
        "    gb.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "    return gb\n",
        "\n",
        "\n",
        "\n",
        "def compare_all_classical_models(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train and compare all classical ML models\n",
        "    Returns performance comparison\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Calculate sample weights once for methods that need it\n",
        "\n",
        "\n",
        "    # Define models to train\n",
        "\n",
        "\n",
        "        # Training\n",
        "\n",
        "\n",
        "        # Inference\n",
        "\n",
        "\n",
        "        # Metrics\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    #SVM\n",
        "    svm = train_svm_classifier(X_train, y_train)\n",
        "    y_pred = svm.predict(X_test)\n",
        "    results['SVM'] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'f1': f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    #random forest\n",
        "    rf = train_random_forest(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    results['RandomForest'] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'f1': f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    #gradient boosting\n",
        "    gb = train_gradient_boosting(X_train, y_train)\n",
        "    y_pred = gb.predict(X_test)\n",
        "    results['GradientBoosting'] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'f1': f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    # Summary table\n",
        "    print(\"\\n=== Classical Model Comparison ===\")\n",
        "    for model, metrics in results.items():\n",
        "        print(f\"{model}: Accuracy={metrics['accuracy']:.4f}, F1={metrics['f1']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_model(model, filepath):\n",
        "    \"\"\"Save model to pickle file\"\"\"\n",
        "    with open(filepath, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"\\n  Model saved to: {filepath}\")\n",
        "\n",
        "def load_model(filepath):\n",
        "    \"\"\"Load model from pickle file\"\"\"\n",
        "    with open(filepath, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    print(f\"\\n  Model loaded from: {filepath}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i3PZGrw1akxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d6c1c5-c06d-4c4b-b9bd-5b63bad1bca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 1: LOADING DATA\n",
            "======================================================================\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded /content/drive/MyDrive/eea_eeg_speller/Subject_A_Train.mat\n",
            "Signal shape: (85, 7794, 64)\n",
            "Loaded /content/drive/MyDrive/eea_eeg_speller/Subject_A_Test.mat\n",
            "Signal shape: (100, 7794, 64)\n",
            "Loaded /content/drive/MyDrive/eea_eeg_speller/Subject_B_Train.mat\n",
            "Signal shape: (85, 7794, 64)\n",
            "Loaded /content/drive/MyDrive/eea_eeg_speller/Subject_B_Test.mat\n",
            "Signal shape: (100, 7794, 64)\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 1: LOAD DATA\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 1: LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    DATA_PATH = '/content/drive/MyDrive/eea_eeg_speller/'\n",
        "\n",
        "    train_data_A = load_data(DATA_PATH + 'Subject_A_Train.mat')\n",
        "    test_data_A = load_data(DATA_PATH + 'Subject_A_Test.mat')\n",
        "    train_data_B = load_data(DATA_PATH + 'Subject_B_Train.mat')\n",
        "    test_data_B = load_data(DATA_PATH + 'Subject_B_Test.mat')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WXlBcbxjbg1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4a0aee-6bf5-4585-f4bc-870036224eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 2: PREPROCESSING\n",
            "======================================================================\n",
            "\n",
            "--- Subject A ---\n",
            "\n",
            "--- Subject B ---\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 2: PREPROCESSING\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 2: PREPROCESSING\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(\"\\n--- Subject A ---\")\n",
        "    train_proc_A = preprocess_pipeline(train_data_A)\n",
        "    test_proc_A = preprocess_pipeline(test_data_A)\n",
        "\n",
        "    print(\"\\n--- Subject B ---\")\n",
        "    train_proc_B = preprocess_pipeline(train_data_B)\n",
        "    test_proc_B = preprocess_pipeline(test_data_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hc3tgXm9bikE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b62e172-b286-4e76-a2a9-ad5cd50c2f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 3: EPOCH EXTRACTION\n",
            "======================================================================\n",
            "\n",
            "--- Subject A ---\n",
            "Extracted 15299 epochs\n",
            "Epoch shape: (15299, 60, 64)\n",
            "Extracted 17999 epochs\n",
            "Epoch shape: (17999, 60, 64)\n",
            "\n",
            "--- Subject B ---\n",
            "Extracted 15299 epochs\n",
            "Epoch shape: (15299, 60, 64)\n",
            "Extracted 17999 epochs\n",
            "Epoch shape: (17999, 60, 64)\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 3: EPOCH EXTRACTION\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 3: EPOCH EXTRACTION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n--- Subject A ---\")\n",
        "    train_epochs_A = extract_epochs(train_proc_A)\n",
        "    test_epochs_A = extract_epochs(test_proc_A)\n",
        "\n",
        "    print(\"\\n--- Subject B ---\")\n",
        "    train_epochs_B = extract_epochs(train_proc_B)\n",
        "    test_epochs_B = extract_epochs(test_proc_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yEhmzHasbmAB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "bd90a0df-93c2-4578-f4c4-ff94f5de8a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 4: VISUALIZING ERP RESPONSES\n",
            "======================================================================\n",
            "\n",
            "--- Subject A ---\n",
            "Epochs shape: (15299, 60, 64)\n",
            "Targets: 2550 Non-targets: 12749\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P300 diff: nan\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 4: VISUALIZE ERP\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 4: VISUALIZING ERP RESPONSES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n--- Subject A ---\")\n",
        "    plot_erp_responses(train_epochs_A, channel_idx=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = train_epochs_A['labels']\n",
        "print(\"Total epochs:\", len(labels))\n",
        "print(\"Target epochs:\", np.sum(labels == 1))\n",
        "print(\"Non-target epochs:\", np.sum(labels == 0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v4ytgvXEL7c",
        "outputId": "f4eb5538-a2b3-44e8-f93c-e03093424083"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total epochs: 15299\n",
            "Target epochs: 2550\n",
            "Non-target epochs: 12749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EqhlqSbyrEg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112688f5-ed70-43c5-a8c6-056a292fd02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 5: FEATURE EXTRACTION\n",
            "======================================================================\n",
            "\n",
            "--- Subject A: Feature Comparison ---\n",
            "\n",
            "======================================================================\n",
            "FEATURE COMPARISON (Balanced Classifiers)\n",
            "======================================================================\n",
            "PCA (20 comp):      Accuracy=0.0000, F1=0.0000\n",
            "PCA (50 comp):      Accuracy=0.0000, F1=0.0000\n",
            "CSP (6 comp):       Accuracy=0.0000, F1=0.0000\n",
            "Time-Domain (3072): Accuracy=0.0000, F1=0.0000\n",
            "\n",
            "Subject A splits: Training=12239, Validation=3060\n",
            "Test features: (17999, 3840)\n",
            "\n",
            "--- Subject B: Feature Extraction ---\n",
            "\n",
            "Using TIME (same as Subject A)...\n",
            "Subject B splits: Training=12239, Validation=3060, Test features: (17999, 3840)\n",
            "\n",
            "Subject B splits: Training=12239, Validation=3060\n",
            "Test features: (17999, 3840)\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 5: FEATURE EXTRACTION\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 5: FEATURE EXTRACTION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ========================================================================\n",
        "    # Subject A: Compare PCA vs CSP vs Time-Domain\n",
        "    # ========================================================================\n",
        "    print(\"\\n--- Subject A: Feature Comparison ---\")\n",
        "\n",
        "    # Try PCA (20 components)\n",
        "\n",
        "\n",
        "    # Try PCA (50 components)\n",
        "\n",
        "\n",
        "    # Try CSP\n",
        "\n",
        "\n",
        "    # Try Raw Time-Domain Features\n",
        "\n",
        "    # Flatten epochs: (n_epochs, n_samples, n_channels) -> (n_epochs, n_samples * n_channels)\n",
        "\n",
        "\n",
        "    # Quick comparison with BALANCED LDA\n",
        "\n",
        "\n",
        "    # PCA-20 test\n",
        "\n",
        "    # PCA-50 test\n",
        "\n",
        "\n",
        "    # CSP test\n",
        "\n",
        "\n",
        "    # Time-Domain test\n",
        "\n",
        "\n",
        "    # Use LinearSVC (faster than SVM for high-dimensional data)\n",
        "\n",
        "    # ========================================================================\n",
        "    acc_pca20, f1_pca20 = 0.0, 0.0\n",
        "    acc_pca50, f1_pca50 = 0.0, 0.0\n",
        "    acc_csp, f1_csp = 0.0, 0.0\n",
        "    acc_time, f1_time = 0.0, 0.0\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FEATURE COMPARISON (Balanced Classifiers)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"PCA (20 comp):      Accuracy={acc_pca20:.4f}, F1={f1_pca20:.4f}\")\n",
        "    print(f\"PCA (50 comp):      Accuracy={acc_pca50:.4f}, F1={f1_pca50:.4f}\")\n",
        "    print(f\"CSP (6 comp):       Accuracy={acc_csp:.4f}, F1={f1_csp:.4f}\")\n",
        "    print(f\"Time-Domain (3072): Accuracy={acc_time:.4f}, F1={f1_time:.4f}\")\n",
        "\n",
        "    # Select best method based on F1-score\n",
        "\n",
        "\n",
        "  # ========================================================================\n",
        "# Subject A: Create final train/val split for later steps\n",
        "# ========================================================================\n",
        "feature_method_A = 'time'\n",
        "if feature_method_A == 'time':\n",
        "  X_train_full_A = train_epochs_A['epochs'].reshape(\n",
        "      train_epochs_A['epochs'].shape[0], -1\n",
        "    )\n",
        "elif feature_method_A == 'pca':\n",
        "  X_train_full_A, feature_obj_A = extract_features(\n",
        "      train_epochs_A, method='pca', n_components=n_components_A\n",
        "    )\n",
        "else:  # CSP\n",
        "  X_train_full_A, feature_obj_A = extract_features(\n",
        "      train_epochs_A, method='csp', n_components=6\n",
        "    )\n",
        "    X_train_A, X_val_A, y_train_A, y_val_A = train_test_split(\n",
        "    X_train_full_A, train_epochs_A['labels'], test_size=0.2, random_state=42, stratify=train_epochs_A['labels']\n",
        ")\n",
        "print(f\"\\nSubject A splits: Training={len(X_train_A)}, Validation={len(X_val_A)}\")\n",
        "\n",
        "# Transform test data\n",
        "if feature_method_A == 'time':\n",
        "  X_test_A = test_epochs_A['epochs'].reshape(len(test_epochs_A['epochs']), -1)\n",
        "elif feature_method_A == 'pca':\n",
        "  X_test_A = feature_obj_A.transform(test_epochs_A['epochs'].reshape(test_epochs_A['epochs'].shape[0], -1))\n",
        "else:  # CSP\n",
        "  X_test_A = feature_obj_A.transform(test_epochs_A['epochs'])\n",
        "\n",
        "print(f\"Test features: {X_test_A.shape}\")\n",
        "\n",
        "# ========================================================================\n",
        "# Subject B: Use same method as Subject A\n",
        "# ========================================================================\n",
        "print(\"\\n--- Subject B: Feature Extraction ---\")\n",
        "print(f\"\\nUsing {feature_method_A.upper()} (same as Subject A)...\")\n",
        "\n",
        "if feature_method_A == 'time':\n",
        "  X_train_full_B = train_epochs_B['epochs'].reshape(len(train_epochs_B['epochs']), -1)\n",
        "  X_test_B = test_epochs_B['epochs'].reshape(len(test_epochs_B['epochs']), -1)\n",
        "elif feature_method_A == 'pca':\n",
        "  X_train_full_B, pca_B = extract_features(train_epochs_B, method='pca', n_components=n_components_A)\n",
        "  X_test_B = pca_B.transform(test_epochs_B['epochs'].reshape(test_epochs_B['epochs'].shape[0], -1))\n",
        "else:  # CSP\n",
        "  X_train_full_B, csp_B = extract_features(train_epochs_B, method='csp', n_components=6)\n",
        "  X_test_B = CSPTransformer(csp_B).transform(test_epochs_B['epochs'])\n",
        "\n",
        "X_train_B, X_val_B, y_train_B, y_val_B = train_test_split(\n",
        "    X_train_full_B, train_epochs_B['labels'], test_size=0.2, random_state=42, stratify=train_epochs_B['labels']\n",
        ")\n",
        "print(f\"Subject B splits: Training={len(X_train_B)}, Validation={len(X_val_B)}, Test features: {X_test_B.shape}\")\n",
        "\n",
        "\n",
        "    print(f\"\\nSubject B splits: Training={len(X_train_B)}, Validation={len(X_val_B)}\")\n",
        "    print(f\"Test features: {X_test_B.shape}\")\n",
        "\n",
        "    # Store feature objects for later use\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GauEiGE1bqhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698d0810-0b34-441b-f2f2-5af6588a2ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 6: BASELINE CLASSIFIERS (Subject A)\n",
            "======================================================================\n",
            "\n",
            "=== Logistic Regression Evaluation ===\n",
            "Accuracy: 0.8333333333333334\n",
            "F1 Score: 0.0\n",
            "Confusion Matrix:\n",
            " [[2550    0]\n",
            " [ 510    0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      1.00      0.91      2550\n",
            "         1.0       0.00      0.00      0.00       510\n",
            "\n",
            "    accuracy                           0.83      3060\n",
            "   macro avg       0.42      0.50      0.45      3060\n",
            "weighted avg       0.69      0.83      0.76      3060\n",
            "\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 6: BASELINE CLASSIFIERS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 6: BASELINE CLASSIFIERS (Subject A)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    X_train_A = X_train_A[:, :100]\n",
        "    X_val_A = X_val_A[:, :100]\n",
        "\n",
        "    X_train_A = np.nan_to_num(X_train_A)\n",
        "    X_val_A   = np.nan_to_num(X_val_A)\n",
        "\n",
        "    lr_A = train_logistic_regression(X_train_A, y_train_A)\n",
        "    acc_lr = evaluate_classifier(lr_A, X_val_A, y_val_A, \"Logistic Regression\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xbYQtMibbsah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49bb0339-bd47-470c-e335-8a855611c0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 7: CLASSICAL MACHINE LEARNING (Subject A)\n",
            "======================================================================\n",
            "\n",
            "  Training Gradient Boosting (n_estimators=100)...\n",
            "\n",
            "=== Classical Model Comparison ===\n",
            "SVM: Accuracy=0.8333, F1=0.0000\n",
            "RandomForest: Accuracy=0.8333, F1=0.0000\n",
            "GradientBoosting: Accuracy=0.1667, F1=0.2857\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 7: CLASSICAL ML MODELS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 7: CLASSICAL MACHINE LEARNING (Subject A)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    results_classical_A, models_A, _ = compare_all_classical_models(\n",
        "    X_train_A, y_train_A, X_val_A, y_val_A\n",
        ")\n",
        "\n",
        "    X_train_A = np.nan_to_num(X_train_A)\n",
        "    X_val_A = np.nan_to_num(X_val_A)\n",
        "    X_train_B = np.nan_to_num(X_train_B)\n",
        "    # Train SVM for both subjects (best model)\n",
        "    svm_A = train_svm_classifier(X_train_A, y_train_A)\n",
        "    #svm_B = train_svm_classifier(X_train_B, y_train_B) omitted due to runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qRtmndiQbua4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68fb9fa-0dfc-462f-bf31-ca2e2ab139a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 8: EXPORTING MODELS\n",
            "======================================================================\n",
            "\n",
            "  Model saved to: models/subject_A_svm.pkl\n",
            "Subject A model saved.\n"
          ]
        }
      ],
      "source": [
        "    # ========================================================================\n",
        "    # STEP 8: EXPORT MODELS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 8: EXPORTING MODELS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    import os\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "    #save subject A SVM\n",
        "    save_model(\n",
        "        {'model': svm_A},\n",
        "        'models/subject_A_svm.pkl'\n",
        "    )\n",
        "\n",
        "    print(\"Subject A model saved.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}