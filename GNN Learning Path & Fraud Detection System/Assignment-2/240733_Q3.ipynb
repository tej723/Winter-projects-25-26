{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziAaW0QJyDtU",
        "outputId": "1b1e6930-efd0-4e3c-ae81-a4ad31f61301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     (0, 0)      |   0\n",
            "     (0, 1)      |   1\n",
            "     (1, 0)      |   1\n",
            "     (1, 1)      |   0\n",
            "Epoch 10000/100000, Loss: 0.00183757\n",
            "Epoch 20000/100000, Loss: 0.00068545\n",
            "Epoch 30000/100000, Loss: 0.00041439\n",
            "Epoch 40000/100000, Loss: 0.00029530\n",
            "Epoch 50000/100000, Loss: 0.00022875\n",
            "Epoch 60000/100000, Loss: 0.00018639\n",
            "Epoch 70000/100000, Loss: 0.00015710\n",
            "Epoch 80000/100000, Loss: 0.00013568\n",
            "Epoch 90000/100000, Loss: 0.00011934\n",
            "Epoch 100000/100000, Loss: 0.00010647\n",
            "\n",
            "Predictions:\n",
            "Input (x1, x2) | True | Predicted | Probability\n",
            "---------------|------|-----------|------------\n",
            "     (0, 0)      |  0   |     0     |   0.011507\n",
            "     (0, 1)      |  1   |     1     |   0.990192\n",
            "     (1, 0)      |  1   |     1     |   0.990204\n",
            "     (1, 1)      |  0   |     0     |   0.010063\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Final Loss: 0.00010647\n",
            "Learned Parameters\n",
            "\n",
            "W1 (Hidden Layer Weights):\n",
            "[[4.91402841 4.9093086 ]\n",
            " [6.79552241 6.77644088]]\n",
            "\n",
            "b1 (Hidden Layer Bias):\n",
            "[[-7.53343801]\n",
            " [-3.05907952]]\n",
            "\n",
            "W2 (Output Layer Weights):\n",
            "[[-11.24804024  10.54506854]]\n",
            "\n",
            "b2 (Output Layer Bias):\n",
            "[[-4.91987396]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_size=2, hidden_size=2, output_size=1, learning_rate=0.5):\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        np.random.seed(42)\n",
        "        self.W1 = np.random.randn(hidden_size, input_size)\n",
        "        self.b1 = np.zeros((hidden_size, 1))\n",
        "        self.W2 = np.random.randn(output_size, hidden_size)\n",
        "        self.b2 = np.zeros((output_size, 1))\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(self.W1, X) + self.b1\n",
        "        self.a1 = self.sigmoid(self.z1)\n",
        "        self.z2 = np.dot(self.W2, self.a1) + self.b2\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        return self.a2\n",
        "\n",
        "    def backward(self, X, y):\n",
        "        m = X.shape[1]\n",
        "\n",
        "        delta2 = (self.a2 - y) * (self.a2 * (1 - self.a2))\n",
        "        dW2 = np.dot(delta2, self.a1.T) / m\n",
        "        db2 = np.sum(delta2, axis=1, keepdims=True) / m\n",
        "\n",
        "        delta1 = np.dot(self.W2.T, delta2) * (self.a1 * (1 - self.a1))\n",
        "        dW1 = np.dot(delta1, X.T) / m\n",
        "        db1 = np.sum(delta1, axis=1, keepdims=True) / m\n",
        "\n",
        "        self.W2 -= self.learning_rate * dW2\n",
        "        self.b2 -= self.learning_rate * db2\n",
        "        self.W1 -= self.learning_rate * dW1\n",
        "        self.b1 -= self.learning_rate * db1\n",
        "\n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "    def train(self, X, y, epochs=100000):\n",
        "        losses = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            loss = self.compute_loss(y, output)\n",
        "            losses.append(loss)\n",
        "            self.backward(X, y)\n",
        "\n",
        "            if (epoch + 1) % 10000 == 0:\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.8f}\")\n",
        "\n",
        "        return losses\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        output = self.forward(X)\n",
        "        return (output >= threshold).astype(int)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    X = np.array([[0, 0, 1, 1],\n",
        "                  [0, 1, 0, 1]])\n",
        "\n",
        "    y = np.array([[0, 1, 1, 0]])\n",
        "\n",
        "    for i in range(X.shape[1]):\n",
        "        print(f\"     ({X[0,i]}, {X[1,i]})      |   {y[0,i]}\")\n",
        "\n",
        "\n",
        "    mlp = MLP(input_size=2, hidden_size=2, output_size=1, learning_rate=0.5)\n",
        "    losses = mlp.train(X, y, epochs=100000)\n",
        "\n",
        "    predictions_prob = mlp.forward(X)\n",
        "    predictions = mlp.predict(X)\n",
        "\n",
        "    print(\"\\nPredictions:\")\n",
        "    print(\"Input (x1, x2) | True | Predicted | Probability\")\n",
        "    print(\"---------------|------|-----------|------------\")\n",
        "    for i in range(X.shape[1]):\n",
        "        print(f\"     ({X[0,i]}, {X[1,i]})      |  {y[0,i]}   |     {predictions[0,i]}     |   {predictions_prob[0,i]:.6f}\")\n",
        "\n",
        "    accuracy = np.mean(predictions == y) * 100\n",
        "    print(f\"\\nAccuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Final Loss: {losses[-1]:.8f}\")\n",
        "\n",
        "    print(\"Learned Parameters\")\n",
        "    print(f\"\\nW1 (Hidden Layer Weights):\\n{mlp.W1}\")\n",
        "    print(f\"\\nb1 (Hidden Layer Bias):\\n{mlp.b1}\")\n",
        "    print(f\"\\nW2 (Output Layer Weights):\\n{mlp.W2}\")\n",
        "    print(f\"\\nb2 (Output Layer Bias):\\n{mlp.b2}\")"
      ]
    }
  ]
}