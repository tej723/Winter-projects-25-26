{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Theoretical Questions\n"
      ],
      "metadata": {
        "id": "YDiHv663Ky4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computational Graphs And Gradients"
      ],
      "metadata": {
        "id": "D6yorLNwK7Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we call loss.backward() it calculates gradients and add them to.grad() attribute of leaf tensors. It does not overwrite the previous values.\n",
        "\n",
        "Since Pytorch accumulates gradients they needs to be cleared otherwise the gradients will be added from previous batch to the current batch. This created massive problem because your gradient value depends on the average of previous terms. That is an important step."
      ],
      "metadata": {
        "id": "Sqg4MiQsR0_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors View Vs Reshape"
      ],
      "metadata": {
        "id": "eSR40a82PPHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".view() is a operation that only works if the tensor is stored contiguously in memory. It simply changes how the underlying data is interpreted without moving it. .reshape() works if the tensor is non-contiguous, it will create a copy of the data in a new memory block to satisfy the shape request.\n",
        "\n",
        ".reshape() is the safer fallback because it handles both contiguous and non-contiguous tensors automatically"
      ],
      "metadata": {
        "id": "Sj2XP5lzJni7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Device Management"
      ],
      "metadata": {
        "id": "7E7vWsHRPUo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you try to perform an operation like addition between a tensor on the CPU and one on cuda:0, PyTorch will raise a RuntimeError because Tensors must be on the same physical device memory to interact. PyTorch does not automatically move data between the host CPU and the device.\n",
        "\n",
        " When you move a model to the GPU using model.to('cuda'), only the existing parameters and buffers are moved.\n",
        " Any new tensors created from scratch inside the forward method do not automatically inherit the GPU device.\n",
        " You must manually assign them to the correct device, typically by using device=x.device to match the incoming data"
      ],
      "metadata": {
        "id": "YZ9YHI2XPafW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Programming Challenges"
      ],
      "metadata": {
        "id": "bNRjxo_2UMNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "imwx_r6gQiZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def process_image_batch(images):\n",
        "\n",
        "    return torch.where(images >= 0.5, 1.0, 0.0)\n",
        "\n",
        "\n",
        "images = torch.rand(4, 28, 28)\n",
        "processed = process_image_batch(images)"
      ],
      "metadata": {
        "id": "P_ECEnmeV0mm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5"
      ],
      "metadata": {
        "id": "Fye_AXo9QkXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_gradients():\n",
        "    x = torch.tensor(4.0, requires_grad=True)\n",
        "\n",
        "    y = x**3 + 2*x\n",
        "\n",
        "    y.backward()\n",
        "\n",
        "    calc_grad = x.grad.item()\n",
        "    print(f\"PyTorch Gradient: {calc_grad}\")\n",
        "\n",
        "    manual_grad = 3 * (4**2) + 2\n",
        "    if calc_grad != manual_grad:\n",
        "        raise ValueError(f\"Mismatch! Expected {manual_grad}, got {calc_grad}\")\n",
        "    else:\n",
        "        print(\"Gradients match perfectly.\")\n",
        "\n",
        "check_gradients()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN-pVAvMV7pP",
        "outputId": "9cdc8b37-0dcf-4b74-ba95-fcaefaad0ec7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Gradient: 50.0\n",
            "Gradients match perfectly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6"
      ],
      "metadata": {
        "id": "bW1Y6MZfQm0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NumberDataset(Dataset):\n",
        "    def __init__(self, data_list):\n",
        "        self.data = data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        num = self.data[idx]\n",
        "\n",
        "        input_tensor = torch.tensor(float(num))\n",
        "        target_tensor = torch.tensor(float(num * 2))\n",
        "        return input_tensor, target_tensor"
      ],
      "metadata": {
        "id": "NsbBGSk7WZJe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7"
      ],
      "metadata": {
        "id": "WMPzIYGkQpBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(10, 5)\n",
        "        self.layer2 = nn.Linear(5, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "r_BOkosKZGm-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8"
      ],
      "metadata": {
        "id": "GxJ2kNOyQrRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, inputs, targets, optimizer, criterion):\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    loss = criterion(predictions, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "model = SimpleClassifier()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "dummy_input = torch.randn(1, 10)\n",
        "dummy_target = torch.tensor([[1.0]])\n",
        "\n",
        "loss_val = train_step(model, dummy_input, dummy_target, optimizer, criterion)\n",
        "print(f\"Initial Loss: {loss_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiGx8G5yZNnw",
        "outputId": "92b43b75-f2b7-4d33-a207-a974ca58004e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Loss: 0.5009077191352844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EJc85UsAYsMx"
      }
    }
  ]
}