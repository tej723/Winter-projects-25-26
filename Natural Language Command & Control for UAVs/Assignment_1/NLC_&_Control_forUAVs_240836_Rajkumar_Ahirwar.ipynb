{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qiPk_4QboELr4BUB0XyDZCkg4qvagbWK","timestamp":1766715521081}],"authorship_tag":"ABX9TyP6lQwtn0GSG/pBTdR7uxvQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **ASSIGNMENT 2**"],"metadata":{"id":"ieLFNB04cBpt"}},{"cell_type":"markdown","source":["#**PART** **1**"],"metadata":{"id":"N5JvPOQ9qAcx"}},{"cell_type":"markdown","source":["**Question 1**: **computational graphs and gradients**"],"metadata":{"id":"rdrdg5yDqCZP"}},{"cell_type":"markdown","source":["**Ans**.:Calling loss.backward() triggers PyTorch's automatic differentiation engine, Autograd.\n","As PyTorch build  computational graph dynamically as operations are performed  during forward pass. the backward call initiates a traversal backward through this graph, starting from the loss tensor itself. Using the chain rule of calculas,  AUTOGRAD efficiently calculates the gradient of the loss with respect to each tensor in the graph that has its requires_grad attribute set to True.\n","No, it doesnot overwrite the old gradient."],"metadata":{"id":"ETT_NVUAqJLB"}},{"cell_type":"markdown","source":["when we call loss.backward() , the newly computed gradients are added to whatever value is already present in the .grad() attribute of the parameters.\n","As they do not overwrite the previous values.\n","\n","this acumulation is intentional and useful in certain scenarios, such as simulating larger batch sizes or training RNNs. However in a standard training loop where you process one batch at a time, we typically want to calculate the gradient of the current batch only.\n","\n","This is why it is necessary to zero out the gradients at the beginning of each training iteration, usually before the forward pass or just before calling the loss.backward().\n","to do this we need an optimizer, optimizer.zero_grad().\n","<!-- after calculating the  gradient we need to use this to update models parameters, which is handled by the optimizers step method. -->"],"metadata":{"id":"vZtr8HFWtYPj"}},{"cell_type":"markdown","source":["**Que 2**: **Tensors: view vs reshape**"],"metadata":{"id":"gPt4qE93wikB"}},{"cell_type":"code","source":["import torch\n","\n","x = torch.arange(6)\n","y = x.view(2, 3)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68suxVPOyVkJ","executionInfo":{"status":"ok","timestamp":1766715463019,"user_tz":-330,"elapsed":3515,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"68cbb7d1-11ca-460a-c5ff-22ca6f272adf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 1, 2],\n","        [3, 4, 5]])\n"]}]},{"cell_type":"markdown","source":[".view() is used when tensor is contiguous in memory. if it is not contiguous then we must call .contiguous() before .view()."],"metadata":{"id":"TxicFUGfykhR"}},{"cell_type":"code","source":["x = torch.arange(6)\n","y = x.reshape(2, 3)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1S4a2oWwyYu1","executionInfo":{"status":"ok","timestamp":1766715463020,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"d81bcb7a-5a16-41c8-b644-0af22f51f747"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 1, 2],\n","        [3, 4, 5]])\n"]}]},{"cell_type":"markdown","source":[".reshape() can be used even if tensor is not contiguous."],"metadata":{"id":"Hn0d_RU_zGVu"}},{"cell_type":"markdown","source":["if we are not sure about the memory stride then its is preferable to choose .reshape()"],"metadata":{"id":"Ww3zYGQ2JC5w"}},{"cell_type":"markdown","source":["**Question 3 :**\n"],"metadata":{"id":"zunkj5R21oVv"}},{"cell_type":"markdown","source":["**Ans :**"],"metadata":{"id":"WV_ihY3eINZ1"}},{"cell_type":"markdown","source":["while peforming an operation in a tensor located on cpu and a tensor located on cuda:0, we will get runtime error, because all tensors need to be present on a same device. (The gpu memory can't directly access cpu memory).   to fix this we need to move one tensor to match the device of the other."],"metadata":{"id":"LTkF6JJaIOVl"}},{"cell_type":"markdown","source":["No, they do not automatically inherit the models's device. they must be manually assigned to the correct device.\n","\n","\n","\n","\n","model.to('cuda') does:\n","*   moves all model parameters (weights, biases) to the gpu.\n","*   doesn't affect new tensors created in forward().\n","\n","\n","\n","\n","\n"],"metadata":{"id":"HlvgsR1kIKFZ"}},{"cell_type":"markdown","source":["**Que 4:** Tensor manipulation\n","\n","\n","\n","Solution:"],"metadata":{"id":"3MK1VflbOOrF"}},{"cell_type":"code","source":["import torch\n","images = torch.rand(4, 28, 28)\n","print(images)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UqkbBhHOmOi","executionInfo":{"status":"ok","timestamp":1766715463129,"user_tz":-330,"elapsed":111,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"cd560006-1136-4d78-f0cc-858c92db27f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[1.5773e-02, 4.8750e-01, 3.5320e-01,  ..., 8.0440e-01,\n","          5.6666e-01, 5.8423e-01],\n","         [6.6705e-01, 6.4571e-01, 3.2476e-01,  ..., 8.6029e-01,\n","          6.5129e-01, 7.1146e-01],\n","         [5.3158e-01, 5.9746e-01, 5.9832e-02,  ..., 1.0987e-01,\n","          6.3854e-01, 1.3000e-01],\n","         ...,\n","         [2.5745e-01, 4.6752e-01, 4.9091e-01,  ..., 9.2901e-01,\n","          7.6525e-01, 3.3919e-01],\n","         [4.0543e-02, 7.3344e-01, 5.8648e-01,  ..., 1.9162e-01,\n","          4.0643e-01, 6.6662e-02],\n","         [8.6355e-02, 7.3089e-01, 5.4563e-01,  ..., 2.7718e-03,\n","          5.9419e-01, 3.4917e-01]],\n","\n","        [[4.4576e-01, 1.8396e-01, 5.1665e-01,  ..., 1.2431e-02,\n","          8.0266e-01, 2.7098e-01],\n","         [6.3421e-01, 7.0266e-01, 8.5732e-01,  ..., 9.5510e-01,\n","          7.9920e-01, 1.2969e-01],\n","         [6.7174e-01, 5.0182e-01, 8.3014e-01,  ..., 3.8783e-01,\n","          3.2351e-01, 2.3745e-01],\n","         ...,\n","         [5.3634e-01, 4.1765e-01, 2.3927e-01,  ..., 6.3125e-01,\n","          5.7378e-01, 2.0193e-01],\n","         [9.6979e-01, 2.9642e-01, 9.4725e-01,  ..., 9.5845e-01,\n","          4.0417e-01, 2.9918e-01],\n","         [9.9933e-01, 3.8380e-01, 1.5747e-01,  ..., 4.6210e-01,\n","          2.1228e-01, 6.0894e-01]],\n","\n","        [[8.2025e-01, 3.5368e-01, 4.8527e-01,  ..., 9.4924e-01,\n","          5.1244e-01, 6.3187e-01],\n","         [7.5471e-01, 1.0720e-01, 3.6893e-01,  ..., 5.8040e-01,\n","          7.3784e-01, 8.2469e-01],\n","         [4.7875e-01, 3.2719e-01, 4.3001e-01,  ..., 9.5392e-01,\n","          1.6791e-01, 1.6496e-01],\n","         ...,\n","         [8.9963e-01, 8.0010e-01, 6.4096e-01,  ..., 6.8633e-01,\n","          9.4058e-01, 2.3069e-01],\n","         [9.1470e-02, 9.4445e-02, 8.1623e-01,  ..., 7.2974e-01,\n","          6.1001e-01, 6.4501e-01],\n","         [1.7174e-01, 1.7823e-01, 7.5973e-01,  ..., 8.7789e-01,\n","          6.4968e-01, 7.9668e-04]],\n","\n","        [[7.4615e-01, 5.8074e-01, 4.0008e-01,  ..., 8.4092e-01,\n","          4.8754e-01, 3.3414e-01],\n","         [2.1580e-01, 7.7082e-01, 1.1735e-01,  ..., 4.7401e-01,\n","          2.2801e-01, 5.7185e-01],\n","         [5.8685e-01, 6.6552e-01, 8.1484e-01,  ..., 4.5768e-01,\n","          1.8322e-01, 1.3174e-01],\n","         ...,\n","         [1.9336e-01, 8.1243e-02, 2.9128e-01,  ..., 4.6561e-01,\n","          6.2218e-01, 5.2095e-01],\n","         [1.1320e-01, 1.5218e-01, 1.3966e-01,  ..., 2.7680e-01,\n","          1.1636e-02, 4.4387e-01],\n","         [7.1223e-01, 6.6798e-01, 7.7185e-02,  ..., 4.9054e-01,\n","          1.2134e-01, 7.1008e-01]]])\n"]}]},{"cell_type":"code","source":["import torch\n","\n","def binarize_images(images):\n","    return (images >= 0.5).float()\n","\n","\n","images = torch.rand(4, 28, 28)\n","binarized = binarize_images(images)\n","print(f\"\\nSample of original values:\\n{images[0, :3, :3]}\")\n","print(f\"\\nSample of binarized values:\\n{binarized[0, :3, :3]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsMiHr9ZRnwC","executionInfo":{"status":"ok","timestamp":1766715463183,"user_tz":-330,"elapsed":55,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"6c414cfe-1219-4448-aa0d-2e6f9b068818"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sample of original values:\n","tensor([[0.0587, 0.0941, 0.6641],\n","        [0.7601, 0.6015, 0.2351],\n","        [0.8402, 0.7471, 0.1350]])\n","\n","Sample of binarized values:\n","tensor([[0., 0., 1.],\n","        [1., 1., 0.],\n","        [1., 1., 0.]])\n"]}]},{"cell_type":"code","source":["x = torch.tensor(4.0, requires_grad = True)\n","y = x**3 + 2*x\n","y.backward()\n","dy_dx = 3 * x**2 + 2\n","if(dy_dx == x.grad):\n","  print(dy_dx)\n","  print(f\"Gradient dy/dx at x={x.item()} is {x.grad}\")\n","else:\n","  raise ValueError(\"calculated gradients do not match\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gktkJiZhUErW","executionInfo":{"status":"ok","timestamp":1766715463198,"user_tz":-330,"elapsed":13,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"d89aa51f-9c26-4b87-dfc1-cae582cd57fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(50., grad_fn=<AddBackward0>)\n","Gradient dy/dx at x=4.0 is 50.0\n"]}]},{"cell_type":"markdown","source":["**Question 6:**"],"metadata":{"id":"KK9fpTKbW8sa"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class NumberDataset(Dataset):\n","    def __init__(self, numbers):\n","        self.numbers = numbers\n","\n","    def __len__(self):\n","        return len(self.numbers)\n","\n","    def __getitem__(self, idx):\n","        num = float(self.numbers[idx])\n","        input_tensor = torch.tensor(num, dtype = torch.float32)\n","        target_tensor = torch.tensor(num*2, dtype = torch.float32)\n","\n","        return input_tensor, target_tensor\n","\n","\n","\n"],"metadata":{"id":"t9mgEN67XDwE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ND = NumberDataset([1,2,3,4,5,874, 847, 877, 84, 84, 874, 74, 78, 874, 874, 874, 874, 8674, 763, 76743, 76764, 76764])\n","ND.__len__()\n","ND.__getitem__(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GwrM9N8Z7dz","executionInfo":{"status":"ok","timestamp":1766715463282,"user_tz":-330,"elapsed":48,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"9d7d6a83-ac22-4547-9da1-a13c0ce336ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(4.), tensor(8.))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**Question 7:**\n","\n","**Solution:**"],"metadata":{"id":"CfCe48JXeRBZ"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","class SimpleClassifier(nn.Module):\n","  def __init__(self):\n","    super(SimpleClassifier, self).__init__()\n","    self.layer1 = nn.Linear(10,5)\n","    self.layer2 = nn.Linear(5,1)\n","\n","  def forward(self, x):\n","     x = self.layer1(x)\n","     x = torch.relu(x)\n","     x = self.layer2(x)\n","     x = torch.sigmoid(x)\n","     return x\n","\n","\n","model = SimpleClassifier()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L7s8Y-CfeY4U","executionInfo":{"status":"ok","timestamp":1766715463367,"user_tz":-330,"elapsed":80,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"7bb65138-fad8-4522-d237-cf39b2e6601d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleClassifier(\n","  (layer1): Linear(in_features=10, out_features=5, bias=True)\n","  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["sample = torch.randn(1, 10)  # Batch size 1, input size 10\n","output = model(sample)\n","print(f\"\\nInput shape: {sample.shape}\")\n","print(f\"Output shape: {output.shape}\")\n","print(f\"Output value: {output.item():.4f}\")\n","print(f\"\\nNumber of parameters: {sum(p.numel() for p in model.parameters())}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5kYKhqPircQ","executionInfo":{"status":"ok","timestamp":1766715463421,"user_tz":-330,"elapsed":52,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"50995c85-f37f-43ef-9db2-9651e35830c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Input shape: torch.Size([1, 10])\n","Output shape: torch.Size([1, 1])\n","Output value: 0.5166\n","\n","Number of parameters: 61\n"]}]},{"cell_type":"code","source":["def train_step(model, inputs, targets, optimizer, criterion):\n","    optimizer.zero_grad()\n","    output = model(inputs)\n","    loss = criterion(output, targets)\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()\n"],"metadata":{"id":"8LX2SnbAlC0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create optimizer (SGD with learning rate 0.01)\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Create loss function (Binary Cross Entropy Loss)\n","criterion = nn.BCELoss()\n","\n","# Create dummy data\n","batch_size = 4\n","inputs = torch.randn(batch_size, 10)  # 4 samples, 10 features each\n","targets = torch.randint(0, 2, (batch_size, 1)).float()  # Binary targets (0 or 1)\n","print(inputs)\n","print(targets)\n","\n","for step in range(10):\n","    loss_value = train_step(model, inputs, targets, optimizer, criterion)\n","    print(f\"Step {step + 1:2d} | Loss: {loss_value:.6f}\")\n","\n","# Show predictions vs targets after training\n","with torch.no_grad():\n","    final_predictions = model(inputs)\n","    print(final_predictions)\n","    print(\"\\nFinal Predictions vs Targets:\")\n","    for i in range(batch_size):\n","        print(f\"  Sample {i+1}: Pred = {final_predictions[i].item():.4f}, Target = {targets[i].item():.0f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1l99OEThmmxg","executionInfo":{"status":"ok","timestamp":1766715472686,"user_tz":-330,"elapsed":9238,"user":{"displayName":"Rajkumar Ahirwar","userId":"06821941713704576995"}},"outputId":"9cf36f0d-23a6-4dae-e8e2-4694aa3d667b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 3.8004e-01,  5.5599e-01, -7.7038e-01, -6.4283e-01,  2.1728e+00,\n","          1.4544e-01,  1.6612e-01, -6.4306e-01, -2.6290e-01,  2.1560e-01],\n","        [ 2.1588e-01,  5.5082e-01, -4.5050e-01, -1.0578e+00,  8.0949e-01,\n","          1.3987e+00,  1.0361e+00, -1.3550e+00,  2.6925e-04,  2.9427e-02],\n","        [ 1.6844e+00,  1.1382e+00,  1.1477e+00,  1.1013e+00, -9.7366e-01,\n","         -1.2689e-02,  3.4809e-01, -5.3250e-01,  1.0044e-01, -1.0728e+00],\n","        [-2.7681e+00,  3.8551e-01,  2.2705e-01,  9.0160e-02, -1.1718e+00,\n","          2.6335e-01, -1.0512e+00, -3.7259e-01,  1.2236e+00,  8.5343e-01]])\n","tensor([[0.],\n","        [0.],\n","        [0.],\n","        [0.]])\n","Step  1 | Loss: 0.691049\n","Step  2 | Loss: 0.687328\n","Step  3 | Loss: 0.683632\n","Step  4 | Loss: 0.679963\n","Step  5 | Loss: 0.676320\n","Step  6 | Loss: 0.672702\n","Step  7 | Loss: 0.669109\n","Step  8 | Loss: 0.665541\n","Step  9 | Loss: 0.661998\n","Step 10 | Loss: 0.658480\n","tensor([[0.5178],\n","        [0.4482],\n","        [0.5149],\n","        [0.4359]])\n","\n","Final Predictions vs Targets:\n","  Sample 1: Pred = 0.5178, Target = 0\n","  Sample 2: Pred = 0.4482, Target = 0\n","  Sample 3: Pred = 0.5149, Target = 0\n","  Sample 4: Pred = 0.4359, Target = 0\n"]}]}]}